{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zTvMB3asiVt"
   },
   "source": [
    "# Giriş\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "Bu çalışmada [Heart Disease UCI](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) veri kümesi inceleyeceğiz. \n",
    "Bu veri kümesi içerisindeki değişkenler üzerinden hastada kalp hastalığı olup olmadığı tahmin etmeye çalışan bir model oluşturacağız.\n",
    "\n",
    "Kalp hastalığı ile ilgili risk faktörlerine baktığımızda\n",
    "* **Değiştirilemeyen başlıca faktörler:**\n",
    "    * artan yaş\n",
    "    * cinsiyet\n",
    "    * kalıtım. \n",
    "    > Bu veri kümesi değişkenlerden biri olan **talaseminin**(thal) kalıtım olduğuna dikkat edin.\n",
    "* **Değiştirilebilecek ana faktörler şunlardır:**\n",
    "    * Sigara içmek\n",
    "    * Yüksek kolesterol\n",
    "    * Yüksek tansiyon\n",
    "    * Fiziksel hareketsizlik\n",
    "    * Fazla kilolu olmak\n",
    "    * Şeker hastası olmak\n",
    "* **Diğer faktörler arasında stres, alkol ve zayıf diyet / beslenme sayılabilir.**\n",
    "\n",
    ">Yukarıdaki veriler göz önüne alındığında, modelimiz tahminde bulunabiliyorsa, yukarıdaki faktörlerin önemli olduğunu göreceğiz.\n",
    " \n",
    "\n",
    "\n",
    "**Hedefimiz**, hastada kalp hastalığının varlığını tespit etmektir.\n",
    "\n",
    "Bu doğrultuda,\n",
    "* [Logistic Regression](#Logistic-Regression), \n",
    "* [K-Nearest Neighbour (KNN) Classification](#K-Nearest-Neighbour-(KNN)-Classification), \n",
    "* [Support Vector Machine (SVM) Algorithm](#Support-Vector-Machine-(SVM)-Algorithm), \n",
    "* [Naive Bayes Algorithm](#Naive-Bayes-Algorithm), \n",
    "* [Decision Tree Algorithm](#Decision-Tree-Algorithm), \n",
    "* [Random Forest Classification](#Random-Forest-Classification) \n",
    "algoritmalarını kullanacağız.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "yz7AZSDzsiVy"
   },
   "source": [
    "## Kütüphanelerin Yüklenmesi\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "Kullandığımız kütüphanelerin yüklenmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y2hEms7EsiVy"
   },
   "outputs": [],
   "source": [
    "# Temel Kütüphaneler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Görselleştirme\n",
    "import seaborn as sns #for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Kurma\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qcQf3sQosiV0"
   },
   "source": [
    "## Veri kümesini yükleme\n",
    "<a id=\"toc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFrJcfXxthNk"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeF_qn5dtmQW"
   },
   "outputs": [],
   "source": [
    "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day4-ProbabilityStatistics/notebooks\"\n",
    "ROOT_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART1/Day4-ProbabilityStatistics/notebooks/\"\n",
    "DATASET_PATH = ROOT_DIR + \"/datasets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xS_89XKhsiV0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH + \"heart.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mrOWhdqsiV1"
   },
   "outputs": [],
   "source": [
    "# Verimize bakalım.\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tYEOY5L3siV2"
   },
   "source": [
    "## Değişkenler\n",
    "<a id=\"toc\"></a>\n",
    "\n",
    "Verimize yakından baktığımızda oldukça temiz bir yapısı olduğunu görüyoruz. Eksik değerlerin kontrolü ve boyutlarına bakmadan önce değişkenlerin kısaltmalarını açıklayalım.\n",
    "\n",
    "1. **age:** The person's age in years\n",
    "2. **sex:** The person's sex (1 = male, 0 = female)\n",
    "* **cp:** The chest pain experienced (Value 1: typical angina, Value 2: atypical angina, Value 3: non-anginal pain, Value 4: asymptomatic)\n",
    "* **trestbps:** The person's resting blood pressure (mm Hg on admission to the hospital)\n",
    "* **chol:** The person's cholesterol measurement in mg/dl\n",
    "* **fbs:** The person's fasting blood sugar (> 120 mg/dl, 1 = true; 0 = false)\n",
    "* **restecg:** Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes' criteria)\n",
    "* **thalach:** The person's maximum heart rate achieved\n",
    "* **exang:** Exercise induced angina (1 = yes; 0 = no)\n",
    "* **oldpeak:** ST depression induced by exercise relative to rest ('ST' relates to positions on the ECG plot. See more here)\n",
    "* **slope:** the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping)\n",
    "* **ca:** The number of major vessels (0-3)\n",
    "* **thal:** A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "* **target: Heart disease (0 = no, 1 = yes)**\n",
    "\n",
    "\n",
    "### Türkçeleri\n",
    "<a id=\"toc\"></a>\n",
    "1. Yaş\n",
    "2. Cinsiyet\n",
    "3. Göğüs ağrısı tipi (4 değer)\n",
    "4. Dinlenme kan basıncı\n",
    "5. Serum kolestrolü (mg / dl)\n",
    "6. Açlık kan şekeri (>120 mg / dl)\n",
    "7. Elektrokardiyografik sonuçların dinlenmesi (değerler 0,1,2)\n",
    "8. Elde edilen maksimum kalp atış hızı\n",
    "9. Egzersize bağlı Anjin (Anjin, kalbe kan akışının azalmasından kaynaklanan bir tür göğüs ağrısıdır.)\n",
    "10. Eski tepe noktası = istirahate bağlı egzersiz ile indüklenen ST depresyonu\n",
    "11. Tepe egzersizi ST segmentinin eğimi\n",
    "12. floroskopi ile renklendirilmiş ana damarların sayısı (0-3)\n",
    "13. thal: \n",
    "    * 3 = normal\n",
    "    * 6 = sabit hata\n",
    "    * 7 = tersinir defekt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQN4VIcdsiV3"
   },
   "source": [
    "# Keşifçi Veri Analizi ve Veri Görselleştirme\n",
    "<a id=\"toc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwW1ngyAsiV3"
   },
   "source": [
    "Bu bölümde değişkenlere ait değerleri ve değişkenlerin kendi içerisindeki karşılaştırmalarına bakacağız. Ardından değişken içerisindeki değerlerin karşılaştırmalı grafiğini çizdireceğiz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE42nOcvsiV4"
   },
   "source": [
    "## Hasta olanlar ve olmayanların dağılımı\n",
    "Burada **1** ile gösterilenler kalp hastalığı olanları, **0** ile gösterilenler ise kalp rahatsızlığı olmayanları verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WspuXvSgsiV4"
   },
   "outputs": [],
   "source": [
    "# seaborn\n",
    "color = [\"#58a3bc\",\"#666666\"]\n",
    "plt.figure(figsize=(12,7))\n",
    "sns.set()\n",
    "sns.countplot(x=\"target\",\n",
    "              data=df,\n",
    "              palette=color)\n",
    "plt.ylabel(\"Kişi Sayısı\")\n",
    "plt.xlabel(\"Target (0 = hasta olmayan, 1= hasta olan)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbwk2X5jsiV4"
   },
   "source": [
    "## Hasta olanlar ve olmayanların yüzdelik dağılımları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Uju25f0siV5"
   },
   "outputs": [],
   "source": [
    "countNoDisease = len(df[df.target == 0]) # hastalığı olmayanların sayısı\n",
    "countHaveDisease = len(df[df.target == 1]) # hastalığı olanların sayısı\n",
    "\n",
    "print(\"Kalp Rahatsızlığı olmayan hastaların yüzdesi: {:.2f}%\".format((countNoDisease / (len(df.target))*100)))\n",
    "print(\"Kalp Rahatsızlığı olan hastaların yüzdesi: {:.2f}%\".format((countHaveDisease / (len(df.target))*100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hlXqsYP3siV5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "color = [\"#58a3bc\",\"#666666\"]\n",
    "plt.pie([countNoDisease,countHaveDisease],\n",
    "        labels=[\"Hasta Olmayan Kişiler\",\"Hasta Olan Kişiler\"],\n",
    "        colors=color,\n",
    "        autopct='%1.2f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAX-oNGfsiV5"
   },
   "source": [
    "## Veri setimizdeki cinsiyet dağılımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vPARnlSYsiV5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.set()\n",
    "sns.countplot(x='sex', data=df, palette=color)\n",
    "plt.xlabel(\"Cinsiyet (0 = kadın, 1= erkek)\")\n",
    "plt.ylabel(\"Kişi Sayısı\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8UzL6zwQsiV6"
   },
   "outputs": [],
   "source": [
    "countFemale = len(df[df.sex == 0]) # kadınların sayısı\n",
    "countMale = len(df[df.sex == 1]) # erkeklerin sayısı\n",
    "print(\"Kadın hastaların yüzdesi: {:.2f}%\".format((countFemale / (len(df.sex))*100)))\n",
    "print(\"Erkek hastaların yüzdesi: {:.2f}%\".format((countMale / (len(df.sex))*100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCNcF7UksiV6"
   },
   "source": [
    "## Hastalık durumuna göre diğer değişkenlerin ortalama değerleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwiLUA4fsiV6"
   },
   "source": [
    "Hastalık durumuna göre bir gruplandırma işlemi yapılmıştır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5XiRt4zvsiV8"
   },
   "outputs": [],
   "source": [
    "df.groupby('target').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQqN7HSxsiV8"
   },
   "source": [
    "## Yaşlara göre Kalp Rahatsızlığı olup olmaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBg4K6lYsiV8"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.age,df.target).plot(kind=\"bar\",figsize=(20,9),color=color)\n",
    "plt.title('Yaşlara Göre Kalp Rahatsızlığı')\n",
    "plt.xlabel('Yaş')\n",
    "plt.ylabel('Sıklık')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "43A2Lfc9siV9"
   },
   "source": [
    "## Cinsiyete göre Kalp rahatsızlığı olup olmaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9v8_nbpMsiV9"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.sex,df.target).plot(kind=\"bar\",figsize=(15,6),color=color)\n",
    "plt.title('Cinsiyete Göre Kalp Hastalığı Sıklığı')\n",
    "plt.xlabel('Cinsiyet (0 = Kadın, 1 = Erkek)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"Hasta Olmayanlar\", \"Hasta Olanlar\"])\n",
    "plt.ylabel('Sıklık')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smwkHXCTsiV9"
   },
   "source": [
    "## Maksimum Kalp Atış Hızı ve Yaş Arasında Hastalık Dağılımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwNAOlXMsiV9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c=\"red\")\n",
    "plt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)])\n",
    "plt.legend([\"Hasta\", \"Hasta Değil\"])\n",
    "plt.xlabel(\"Yaş\")\n",
    "plt.ylabel(\"Maksimum Kalp Atış Hızı\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9h2L2RosiV-"
   },
   "source": [
    "## Slope Değişkenine Göre Hastalık Sıklığı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xPyruNzsiV-"
   },
   "outputs": [],
   "source": [
    "color = [\"#58a3bc\",\"#666666\"]\n",
    "pd.crosstab(df.slope,df.target).plot(kind=\"bar\",figsize=(15,6),color=color)\n",
    "plt.title('Slope Değişkenine Göre Hastalık Sıklığı')\n",
    "plt.xlabel('The Slope of The Peak Exercise ST Segment')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend([\"Hasta Olmayanlar\", \"Hasta Olanlar\"])\n",
    "plt.ylabel('Sıklık')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOo_aUDlsiV_"
   },
   "source": [
    "## Açlık Kan Şekerine Göre Kalp Hastalığı Sıklığı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbuU3MCbsiV_"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.fbs,df.target).plot(kind=\"bar\",figsize=(15,6),color=color)\n",
    "plt.title('Açlık Kan Şekerine Göre Kalp Hastalığı Sıklığı')\n",
    "plt.xlabel('FBS - (Açlık Kan Şekeri > 120 mg/dl) (1 = true; 0 = false)')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.legend([\"Hasta Değil\", \"Hasta\"])\n",
    "plt.ylabel('Hasta veya Hasta Olmayanların Sıklığı')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhMjViY3siV_"
   },
   "source": [
    "## Göğüs Ağrısı Tipine Göre Halp Hastalığı Sıklığı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFrOBKqtsiWA"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(df.cp,df.target).plot(kind=\"bar\",figsize=(15,6),color=color)\n",
    "plt.title('Göğüs Ağrısı Tipine Göre Halp Hastalığı Sıklığı')\n",
    "plt.xlabel('Göğüs Ağrısı Tipi (4 Değer)')\n",
    "plt.xticks(rotation = 0)\n",
    "plt.ylabel('Hasta veya Hasta Olmayanların Sıklığı')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9TJJkdcsiWA"
   },
   "source": [
    "# Kategorik Değişkenlerin Dönüştürülmesi\n",
    "\n",
    "Makine öğrenmesi kısmına geçmeden önce veri setimiz içerisinde bulunan kategorik değişkenlerin dönüştürülmesi gerekmektedir.\n",
    "\n",
    "Bunun için hangi değişkenlerin kategorik olduğunu ve ölçek türlerini saptamalıyız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DV9bFlzbsiWA"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RfQviLNrsiWA"
   },
   "source": [
    "İlk bakışta **sex, cp, fbs, testecg, exang, slope, ca ve thal** değişkenlerinin kategorik olduklarını görüyoruz. \n",
    "\n",
    "Şimdi bu değişkenlerin değerlerine **.uniqe()** metodu yardımıyla bakalım. Eğer **0 - 1** haricinde değerler almışlarsa onları **Nominal ve Ordinal** olarak ayıralım. **Nominal** ölçek türüne sahip değişkenleri **get_dummies() metoduyla** tekrardan şekillendirelim. \n",
    "\n",
    "Çünkü örneğin **0 ve 1** makine için bir ast-üst oluşturmazken içerisinde **0, 1, 2** değerlerini almış bir nominal değişken makinede, **2** değerinin **1** değerinin iki katı gibi bir intiba bırakabilir. Oysa burada **0, 1 ve 2** ile anlatılmak istenen hepsinin ayrı birer **kategorik değişken** olduğudur yani bizim için bunlar arasında bir *ast-üst* ilişkisi yoktur. \n",
    "\n",
    "**Bu sebeple eğer dönüştürme işlemini yapmazsak modelimizin yanlış eğitilmesi söz konusu olacaktır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlcaYe78siWB"
   },
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "Sex değişkeni eşsiz değerleri: {}\n",
    "Cp değişkeni eşsiz değerleri: {}\n",
    "Fbs değişkeni eşsiz değerleri: {}\n",
    "Restecg değişkeni eşsiz değerleri: {}\n",
    "Exang değişkeni eşsiz değerleri: {}\n",
    "Slope değişkeni eşsiz değerleri: {}\n",
    "Ca değişkeni eşsiz değerleri: {}\n",
    "Thal değişkeni eşsiz değerleri: {}\n",
    "\"\"\".format(df.sex.unique(),\n",
    "           df.cp.unique(),\n",
    "           df.fbs.unique(),\n",
    "           df.restecg.unique(),\n",
    "           df.exang.unique(),\n",
    "           df.slope.unique(),\n",
    "           df.ca.unique(),\n",
    "           df.thal.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YlG2kjvXsiWC"
   },
   "source": [
    "Burada **cp, restecg, slope, ca ve thal** değişkenlerinin **0 - 1** haricinde değerlere sahip olduklarını görüyoruz. Bu değişkenlere **get_dummies()** metodunu uygulamadan önce *tiplerine* bakalım. **get_dummies()** metodu obje yada categorik tipleri dönüştürdüğü için içerisinde numerik tipe sahip değişkenlerin dönüşümlerini gerçekleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tyjtemFrsiWC"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tEe5xDKRsiWC"
   },
   "source": [
    "Değişkenlerin Kategorik tiplere dönüştürülmesi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXmUfMshsiWC"
   },
   "outputs": [],
   "source": [
    "df.cp = pd.Categorical(df.cp)\n",
    "df.restecg = pd.Categorical(df.restecg)\n",
    "df.slope = pd.Categorical(df.slope)\n",
    "df.ca = pd.Categorical(df.ca)\n",
    "df.thal = pd.Categorical(df.thal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1_Pto5GsiWC"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiX5vQ1LsiWC"
   },
   "source": [
    "Artık **get_dummies()** metodunu kullanabiliriz. \n",
    "\n",
    "> `drop_first=True` paremetresi dönüştürülen değişkenlerin çıkartılması işini üstlenecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxQVKlZmsiWD"
   },
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zC8b2gynsiWD"
   },
   "outputs": [],
   "source": [
    "df = df[['age', 'sex', 'trestbps', 'chol', 'fbs', 'thalach', 'exang', 'oldpeak',\n",
    "         'cp_1', 'cp_2', 'cp_3', 'restecg_1', 'restecg_2', 'slope_1',\n",
    "         'slope_2', 'ca_1', 'ca_2', 'ca_3', 'ca_4', 'thal_1', 'thal_2',\n",
    "         'thal_3','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xz4V7G7SsiWD"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhW1bKqIsiWE"
   },
   "source": [
    "# Modelin Uygulanması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNIutXTRsiWE"
   },
   "source": [
    "Makine öğrenmesi kısmına geldik. Bu kısımda `sklearn` kütüphanesi içerisindeki çeşitli sınıflandırma modellerini uygulayacağız ve bunlar arasında bir karşılaştırma yapıcaz.\n",
    "\n",
    "Modellerin uygulanmasından önce veri setimizi **train ve test** olarak ayıralım.\n",
    "\n",
    "Bu aşamada %80 eğitim ve %20 test olarak veri setimizi rassal olarak ayırıyoruz.\n",
    "\n",
    "> Aynı rassal değişkenleri yakalamak için bir `random_state` atıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Eyz2SXhsiWE"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCaF7TNIsiWF"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                   df.drop('target', axis=1), # target hariç veri setinin tamamı X\n",
    "                                   df['target'], # target Y\n",
    "                                   test_size = .2, # %80 train %20 test olmak üzere ayırdık.\n",
    "                                   random_state=1905)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(\"Test Accuracy {:.2f}%\".format(lr.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-mpBlnEYx5fu"
   },
   "source": [
    "Test verisi ile prediction ve Confusion Matrix değerlerini elde etme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ri6lrY_Zx340"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_lr = lr.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_head_lr)\n",
    "cm_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnUo4gZasiWF"
   },
   "source": [
    "#### Modelimin doğruluğu **88.52%** olarak görülüyor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMge8kVPsiWF"
   },
   "source": [
    "## Normelleştirme\n",
    "\n",
    "Bir de değişkenlerimi normalleştirerek sonuçları görelim.\n",
    "\n",
    "> Normalleştirme her bir değişkenin maksimum ve minimum değerlerini **0-1** arasında gösterir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OpYp1H2ksiWG"
   },
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1) # X\n",
    "y = df.target # y\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "X_normalized = pd.DataFrame(np_scaled)\n",
    "X_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X16eIjTKsiWH"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                   X_normalized, # target hariç veri setinin tamamı (X)\n",
    "                                   y, # target (Y)\n",
    "                                   test_size = .2, # %80 train %20 test olmak üzere ayırdık.\n",
    "                                   random_state=1905)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "lr_score = lr.score(X_test,y_test)\n",
    "print(\"Test Accuracy {:.2f}%\".format(lr_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z1-biyZayJqS"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_lr = lr.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_head_lr)\n",
    "cm_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pgvGQAJsiWH"
   },
   "source": [
    "#### Normelleştirme sonrasında **88.52%** olan sonucum **90.16%** yükseldi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fw_jEGi5siWH"
   },
   "source": [
    "## K-Nearest Neighbour (KNN) Classification\n",
    "\n",
    "Tahminlerin gözlem benzerliğine göre yapılmasıdır.\n",
    "\n",
    "> **\"Bana arkadaşını söyle sana kim olduğunu söyleyeyim.\"** yaklaşımıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYDsOmNJsiWI"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                   X_normalized, # target hariç veri setinin tamamı (X)\n",
    "                                   y, # target (Y)\n",
    "                                   test_size = .2, # %80 train %20 test olmak üzere ayırdık.\n",
    "                                   random_state=1905)\n",
    "# KNN Model\n",
    "knn = KNeighborsClassifier(n_neighbors = 2)  # n_neighbors means k\n",
    "knn.fit(X_train, y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(\"{} NN Score: {:.2f}%\".format(knn.n_neighbors, knn_score*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hcmLQzVLsiWI"
   },
   "source": [
    "### `n_neighbors = 2` olduğunda skorum: 81.97%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhUn8Hp9y7-v"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_knn = knn.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_knn = confusion_matrix(y_test, y_head_knn)\n",
    "cm_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jypQcwGnsiWI"
   },
   "source": [
    "### En iyi n_neighbors değerini bulma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7xVACFtusiWI"
   },
   "outputs": [],
   "source": [
    "scoreList = []\n",
    "for i in range(1,20):\n",
    "    knn2 = KNeighborsClassifier(n_neighbors = i)  # n_neighbors means k\n",
    "    knn2.fit(X_train, y_train)\n",
    "    scoreList.append(knn2.score(X_test, y_test))\n",
    "\n",
    "sns.set()    \n",
    "plt.plot(range(1,20), scoreList)\n",
    "plt.xticks(np.arange(1,20,1))\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Skor\")\n",
    "plt.show()\n",
    "\n",
    "knn_score = max(scoreList)\n",
    "print(\"Maximum KNN Score is {:.2f}%\".format((max(scoreList))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgwQiIvNsiWJ"
   },
   "source": [
    "### Maksimum KNN skorum 86.89% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTOZybzqsiWJ"
   },
   "source": [
    "## Support Vector Machine (SVM) Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RbnYCOfDsiWK"
   },
   "outputs": [],
   "source": [
    "svm = SVC(random_state = 1)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_score = svm.score(X_test,y_test)\n",
    "print(\"Test Accuracy of SVM Algorithm: {:.2f}%\".format(svm_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8x_GEhtzHC2"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_svm = svm.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_svm = confusion_matrix(y_test, y_head_svm)\n",
    "cm_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WiFko8ksiWK"
   },
   "source": [
    "## Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6sYHWuWlsiWK"
   },
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "nb_score = nb.score(X_test,y_test)\n",
    "print(\"Accuracy of Naive Bayes: {:.2f}%\".format(nb_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zJSQbr2szcdz"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_nb = nb.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_nb = confusion_matrix(y_test, y_head_nb)\n",
    "cm_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mr-I9hlesiWK"
   },
   "source": [
    "## Decision Tree Algorithm\n",
    "\n",
    "Normalleştirilmemiş veri setiyle daha yüksek skor yakalandı."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P4wMv-VsiWK"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), # target hariç veri setinin tamamı (X)\n",
    "                                   y, # target (Y)\n",
    "                                   test_size = .2, # %80 train %20 test olmak üzere ayırdık.\n",
    "                                   random_state=1905)\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "dtc_score = dtc.score(X_test, y_test)\n",
    "print(\"Decision Tree Test Accuracy {:.2f}%\".format(dtc_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1yQF9hHzj7A"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_dtc = dtc.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_dtc = confusion_matrix(y_test, y_head_dtc)\n",
    "cm_dtc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I22K2yZTsiWK"
   },
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eGp1WPxsiWL"
   },
   "outputs": [],
   "source": [
    "# Random Forest Classification\n",
    "rf = RandomForestClassifier(n_estimators = 1000, random_state = 1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_score = rf.score(X_test, y_test)\n",
    "print(\"Random Forest Algorithm Accuracy Score : {:.2f}%\".format(rf_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hDBdAD2zs3r"
   },
   "outputs": [],
   "source": [
    "#prediction\n",
    "y_head_rf = rf.predict(X_test)\n",
    "\n",
    "#confusion matrix\n",
    "cm_rf = confusion_matrix(y_test, y_head_rf)\n",
    "cm_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAsPAVetzuV0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDzgjo0msiWL"
   },
   "outputs": [],
   "source": [
    "methods_accuracy = {\n",
    "    \"Logistic Regression\":lr_score,\n",
    "    \"KNN\" : knn_score,\n",
    "    \"SVM\" : svm_score,\n",
    "    \"Naive Bayes\" : nb_score,\n",
    "    \"Decision Tree\" : dtc_score,\n",
    "    \"Random Forest\" : rf_score\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b9rG_i5xsiWL"
   },
   "outputs": [],
   "source": [
    "methods = [\"Logistic Regression\",\"Naive Bayes\", \"KNN\", \"SVM\", \"Decision Tree\", \"Random Forest\"]\n",
    "accuracy = [lr_score, nb_score, knn_score, svm_score, dtc_score, rf_score]\n",
    "\n",
    "sns.set()\n",
    "plt.figure(figsize=(14,6))\n",
    "plt.ylabel(\"Başarı %\")\n",
    "plt.xlabel(\"Algoritmalar\")\n",
    "sns.barplot(x=methods, y=accuracy, palette=\"deep\")\n",
    "\n",
    "# Kırılımlar Üzerine Değerlerini Yazmak\n",
    "for line in range(len(methods)):\n",
    "     plt.text(line-0.15, # x\n",
    "              0.70, # y\n",
    "             \"{:.2f}%\".format(accuracy[line]*100), # yazdırılacak değer\n",
    "             horizontalalignment='left',\n",
    "              size='large',\n",
    "             color=\"white\",\n",
    "             )\n",
    "\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XENXyMnz1Fe"
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FkJ18jRxsiWM"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,12))\n",
    "\n",
    "plt.suptitle(\"Confusion Matrixes\",fontsize=24)\n",
    "plt.subplots_adjust(wspace = 0.4, hspace= 0.4)\n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.title(\"Logistic Regression Confusion Matrix\")\n",
    "sns.heatmap(cm_lr,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 14})\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.title(\"K Nearest Neighbors Confusion Matrix\")\n",
    "sns.heatmap(cm_knn,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 14})\n",
    "\n",
    "plt.subplot(2,3,3)\n",
    "plt.title(\"Support Vector Machine Confusion Matrix\")\n",
    "sns.heatmap(cm_svm,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 14})\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.title(\"Naive Bayes Confusion Matrix\")\n",
    "sns.heatmap(cm_nb,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 14})\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.title(\"Decision Tree Classifier Confusion Matrix\")\n",
    "sns.heatmap(cm_dtc,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 14})\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.title(\"Random Forest Confusion Matrix\")\n",
    "sns.heatmap(cm_rf,annot=True,cmap=\"Blues\",fmt=\"d\",cbar=False, annot_kws={\"size\": 14})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AzjPPsEdsiWM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LcNtZGAsiWM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JQN4VIcdsiV3",
    "X9TJJkdcsiWA",
    "5Eyz2SXhsiWE",
    "ZnUo4gZasiWF",
    "wMge8kVPsiWF",
    "Fw_jEGi5siWH",
    "bTOZybzqsiWJ",
    "3WiFko8ksiWK",
    "mr-I9hlesiWK",
    "I22K2yZTsiWK",
    "3XENXyMnz1Fe"
   ],
   "name": "Day4-ProbabilityStatistics-Demo2-Discriminative Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
