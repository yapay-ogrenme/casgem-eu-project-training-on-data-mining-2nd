{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b92c0af57d3a181c7b72fce0a2e5b20164bd518b",
    "id": "BO7RaY3Ysc_5"
   },
   "source": [
    "## **0. Giriş**\n",
    "\n",
    "**Titanic: Machine Learning from Disaster**, Kaggle'daki veri bilimi yarışmalarından popüler olanlarındandır.\n",
    "\n",
    "Bu notebook'da ise bu veri kümesi üzerinden, **Keşfedici Veri Analizi** ve **Özellik Mühendisliği** konularına odaklanan başlangıç ​​düzeyinde ama bütüncül bir çalışma gerçekleştirilecektir.\n",
    "\n",
    "Titanik veri seti, ön işleme ihtiyaç duyan ve Titanik batarken yolcuların hayatta kalmasını etkileyen bazı gizli faktörlerin bulmunmasına ihtiyaç duyulan bir veri kümesidir. Dolayısıyla feature engineering ile keşfedilmeyi bekleyen bir çok gizli özellik vardır.\n",
    "\n",
    "Bu notebook temelde **3** ana bölümden oluşur; **Keşfedici Veri Analizi**, **Özellik Mühendisliği** ve **Model**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "id": "2fOvbT8TsdAA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBSQEqfkN9nm"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t1P8HOPLOAyK"
   },
   "outputs": [],
   "source": [
    "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day3-FeatureSelection/notebooks\"\n",
    "ROOT_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART1/Day3-FeatureSelection/notebooks\"\n",
    "DATASET_PATH = ROOT_DIR + \"/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7dc1cb7b8813f315a8b30fd636b3d46b4270496",
    "id": "AlkPszXZsdAC"
   },
   "source": [
    "* Eğitim setinde **891** satır ve test setinde **418** satır vardır\n",
    "* Eğitim setinin **12** özelliği ve test setinin **11** özelliği vardır\n",
    "* Eğitim setindeki ekstra bir özellik, hedef değişken olan `Survived` özelliğidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "467443fda7135a8ce89c4d537da3f3a8546e2384",
    "id": "h4daj7PTsdAD"
   },
   "outputs": [],
   "source": [
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data):\n",
    "    # Returns divided dfs of training and test set\n",
    "    return all_data.loc[:890], all_data.loc[891:].drop(['Survived'], axis=1)\n",
    "\n",
    "df_train = pd.read_csv(DATASET_PATH + '/titanic/train.csv')\n",
    "df_test = pd.read_csv(DATASET_PATH + '/titanic/test.csv')\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "df_train.name = 'Training Set'\n",
    "df_test.name = 'Test Set'\n",
    "df_all.name = 'All Set' \n",
    "\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "print('Number of Training Examples = {}'.format(df_train.shape[0]))\n",
    "print('Number of Test Examples = {}\\n'.format(df_test.shape[0]))\n",
    "print('Training X Shape = {}'.format(df_train.shape))\n",
    "print('Training y Shape = {}\\n'.format(df_train['Survived'].shape[0]))\n",
    "print('Test X Shape = {}'.format(df_test.shape))\n",
    "print('Test y Shape = {}\\n'.format(df_test.shape[0]))\n",
    "print(df_train.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfabd70ff1cbd50e3107727e5bb630aa59110d83",
    "id": "RPFRzPm3sdAE"
   },
   "source": [
    "## **1. Keşfedici Veri Analizi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ff42f5c4bad84e23f78fa56b9e1a72abf577942d",
    "id": "HY99STlrsdAF"
   },
   "source": [
    "### **1.1 Genel Bakış**\n",
    "* `PassengerId` satırın benzersiz kimliğidir ve hedef üzerinde herhangi bir etkisi yoktur\n",
    "* `Survived`, tahmin etmeye çalıştığımız hedef değişkendir (**0** veya **1**):\n",
    "     - **1 = Survived (Hayatta Kaldı)**\n",
    "     - **0 = Not Survived (Hayatta Kalamadı)**\n",
    "* `Pclass` (Yolcu Sınıfı), yolcunun sosyo-ekonomik durumudur ve **3** benzersiz değere (**1**, **2** or **3**): sahip kategorik bir sıralama özelliğidir.:\n",
    "     - **1 = Upper Class (Üst Sınıf)**\n",
    "     - **2 = Middle Class (Orta Sınıf)**\n",
    "     - **3 = Alt Sınıf (Lower Class)**\n",
    "* `Name` (İsim), `Sex`(Cinsiyet) ve `Age` (Yaş) açıklayıcıdır\n",
    "* `SibSp` yolcuların kardeş ve eşlerinin toplam sayısıdır.\n",
    "* `Parch`, yolcuların ebeveyn ve çocuklarının toplam sayısıdır.\n",
    "* `Ticket`(Bilet) yolcunun bilet numarasıdır.\n",
    "* `Fare` (Ücret) yolcu ücretidir\n",
    "* `Cabin`(Kabin) yolcunun kabin numarasıdır.\n",
    "* `Embarked` (Yüklendi), biniş limanıdır ve **3** benzersiz değere (**C**, **Q** veya **S**) sahip kategorik bir özelliktir:\n",
    "     - **C = Cherbourg**\n",
    "     - **Q = Queenstown**\n",
    "     - **S = Southampton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "f02f321f8fd8b8c7c2a4aedb36ebe868ae51004e",
    "id": "200tLaS6sdAG"
   },
   "outputs": [],
   "source": [
    "print(df_train.info())\n",
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_uuid": "851ccf74127831d31ea0d7273b686f9a7cf20eee",
    "id": "UiytVbNrsdAH"
   },
   "outputs": [],
   "source": [
    "print(df_test.info())\n",
    "df_test.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3db8a853b0b33256f1b08f77d7edf0e9d1737d62",
    "id": "wzV-V5XvsdAH"
   },
   "source": [
    "### **1.2 Eksik Değerler (Missing Values)**\n",
    "\n",
    "Aşağıdan görüldüğü gibi, bazı sütunlarda eksik değerler var. display_missing işlevi, hem eğitim hem de test kümesindeki her sütundaki eksik değerlerin sayısını gösterir.\n",
    "\n",
    "* Eğitim setinin `Age`, `Cabin` ve `Embarked` (Yaş, Kabin ve Biniş) sütunlarında eksik değerler var.\n",
    "\n",
    "* Test setinde `Age`, `Cabin` ve `Fare` (Yaş, Kabin ve Ücret) sütunlarında eksik değerler var.\n",
    "\n",
    "Eksik değerlerle uğraşırken birleştirilmiş eğitim ve test seti üzerinde çalışmak uygundur, aksi takdirde doldurulan veriler eğitim veya test seti örneklerinde overfit olabilir. `Age`, `Embarked` ve `Fare` (Yaş, Biniş ve Ücret) sütunlarındaki eksik değerlerin sayısı toplama kıyasla daha küçüktür, ancak `Cabin` sütununun (Kabin) kabaca **80%**'i eksiktir. `Age`, `Embarked` ve `Fare` (Yaş, Biniş ve Ücret) sütunlarındaki eksik değerler, tanımlayıcı istatistiksel ölçülerle doldurulabilir ancak bu, `Cabin` (Kabin) için işe yaramaz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "d4e8f7b72e2bd165cafa71d67c95f008e7c6101d",
    "id": "HXYt86hasdAI"
   },
   "outputs": [],
   "source": [
    "def display_missing(df):    \n",
    "    for col in df.columns.tolist():          \n",
    "        print('{} column missing values: {}'.format(col, df[col].isnull().sum()))\n",
    "    print('\\n')\n",
    "    \n",
    "for df in dfs:\n",
    "    print('{}'.format(df.name))\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCHdDdMwsdAJ"
   },
   "source": [
    "#### **1.2.1 Age (Yaş)**\n",
    "\n",
    "`Age`(Yaş) sütunundaki eksik değerler ortanca (median) yaşla doldurulur, ancak tüm veri kümesinin ortanca yaşının kullanılması iyi bir seçim değildir. `Pclass` gruplarının medyan yaşı, `Age` **(0.408106)** ve `Survived` **(0.338481)** ile yüksek korelasyonu nedeniyle en iyi seçimdir. Ayrıca yaşları diğer özellikler yerine yolcu sınıflarına göre gruplandırmak daha mantıklı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "_yeU0cewsdAJ"
   },
   "outputs": [],
   "source": [
    "df_all_corr = df_all.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_all_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_all_corr[df_all_corr['Feature 1'] == 'Age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJRZFOZvsdAK"
   },
   "source": [
    "Daha doğru olması için, eksik `Age`(Yaş) değerleri doldurulurken `groupby`ın ikinci seviyesi olarak `Sex` özelliği kullanılır. Aşağıdan görüldüğü gibi, `Pclass` ve `Sex` gruplarının farklı `Age` medyan değerleri vardır. Yolcu sınıfı arttığında hem erkek hem de kadınlar için ortanca yaş da artmaktadır. Bununla birlikte, dişiler erkeklerden biraz daha düşük medyan `Age`a sahip olma eğilimindedir. Aşağıdaki ortanca yaşlar, `Age` özelliğindeki eksik değerleri doldurmak için kullanılır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFMbm-IqsdAK"
   },
   "outputs": [],
   "source": [
    "age_by_pclass_sex = df_all.groupby(['Sex', 'Pclass']).median()['Age']\n",
    "\n",
    "for pclass in range(1, 4):\n",
    "    for sex in ['female', 'male']:\n",
    "        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\n",
    "        \n",
    "print('Median age of all passengers: {}'.format(df_all['Age'].median()))\n",
    "\n",
    "# Filling the missing values in Age with the medians of Sex and Pclass groups\n",
    "df_all['Age'] = df_all.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmluvhZesdAL"
   },
   "source": [
    "#### **1.2.2 Embarked (Biniş)**\n",
    "\n",
    "`Embarked` (Biniş) kategorik bir özelliktir ve tüm veri setinde yalnızca **2** eksik değer vardır. Bu yolcuların ikisi de kadın, üst sınıf ve aynı bilet numarasına sahip. Bu, birbirlerini tanıdıkları ve aynı limandan birlikte yola çıktıkları anlamına gelir. Üst sınıf bir kadın yolcu için `Embarked` modunun değeri **C (Cherbourg)**'dur, ancak bu onların o limandan bindikleri anlamına gelmez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "uTpcHwb_sdAL"
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Embarked'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DlFR5Y5sdAM"
   },
   "source": [
    "Google'da **Stone, Mrs. George Nelson (Martha Evelyn)**'i aradığımda, bu sayfada hizmetçisi **Amelie Icard** ile **S (Southampton)**'dan yola çıktığını gördüm [Martha Evelyn Stone: Titanic Survivor](https://www.encyclopedia-titanica.org/titanic-survivor/martha-evelyn-stone.html).\n",
    "\n",
    "> *Mrs Stone, 10 Nisan 1912'de Southampton'da Titanik'e bindi ve hizmetçisi Amelie Icard ile birinci sınıfta seyahat ediyordu. B-28 kabinini işgal etti.*\n",
    "\n",
    "`Embarked` bölümündeki eksik değerler bu bilgilerle **S** ile doldurulur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2LF59hisdAM"
   },
   "outputs": [],
   "source": [
    "# Filling the missing values in Embarked with S\n",
    "df_all['Embarked'] = df_all['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z9GhTv8psdAN"
   },
   "source": [
    "#### **1.2.3 Fare (Ücret)**\n",
    "`Fare`(Ücret) değeri eksik olan yalnızca bir yolcu var. Ücret'in aile büyüklüğü (`Parch` ve `SibSp`) ve `Pclass` özellikleri ile ilgili olduğunu varsayabiliriz. Üçüncü sınıf bileti olan ve ailesi olmayan bir erkeğin medyan `Fare` (Ücret) değeri, eksik değeri doldurmak için mantıklı bir seçimdir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "yN5oHKV2sdAN"
   },
   "outputs": [],
   "source": [
    "df_all[df_all['Fare'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "g7NVfBwTsdAO"
   },
   "outputs": [],
   "source": [
    "med_fare = df_all.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\n",
    "df_all['Fare'] = df_all['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_TeDYeqsdAO"
   },
   "source": [
    "#### **1.2.4 Cabin (Kabin)**\n",
    "`Cabin` biraz zor ve daha fazla araştırmaya ihtiyacı olan bir özellik. `Cabin` özelliğinin büyük bir kısmı eksik ve bu özelliğin kendisi tamamen göz ardı edilemez çünkü bazı kabinlerin hayatta kalma oranları daha yüksek olabilir. `Cabin` değerlerinin ilk harfinin kabinlerin bulunduğu güverte olduğu biliniyor. Bu güverteler esas olarak bir yolcu sınıfı için ayrılmıştı, ancak bazıları birden fazla yolcu sınıfı tarafından da kullanılıyordu.\n",
    "![alt text](https://vignette.wikia.nocookie.net/titanic/images/f/f9/Titanic_side_plan.png/revision/latest?cb=20180322183733)\n",
    "\n",
    "* Tekne Güvertesinde **T, U, W, X, Y, Z** olarak etiketlenmiş **6** oda vardı ancak veri setinde sadece **T** kabini de mevcut\n",
    "* **A**, **B** ve **C** güverteleri sadece 1. sınıf yolcular içindi\n",
    "* **D** ve **E** desteleri tüm sınıflar içindi\n",
    "* **F** ve **G** güverteleri hem 2. hem de 3. sınıf yolcular içindi\n",
    "* **A**'dan **G**'ye giderken, hayatta kalma faktörü olabilecek merdivenlere olan mesafe artar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "pl5Kj8CJsdAP"
   },
   "outputs": [],
   "source": [
    "# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\n",
    "df_all['Deck'] = df_all['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "df_all_decks = df_all.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n",
    "                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "def get_pclass_dist(df):\n",
    "    \n",
    "    # Creating a dictionary for every passenger class count in every deck\n",
    "    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n",
    "    decks = df.columns.levels[0]    \n",
    "    \n",
    "    for deck in decks:\n",
    "        for pclass in range(1, 4):\n",
    "            try:\n",
    "                count = df[deck][pclass][0]\n",
    "                deck_counts[deck][pclass] = count \n",
    "            except KeyError:\n",
    "                deck_counts[deck][pclass] = 0\n",
    "                \n",
    "    df_decks = pd.DataFrame(deck_counts)    \n",
    "    deck_percentages = {}\n",
    "\n",
    "    # Creating a dictionary for every passenger class percentage in every deck\n",
    "    for col in df_decks.columns:\n",
    "        deck_percentages[col] = [(count / df_decks[col].sum()) * 100 for count in df_decks[col]]\n",
    "        \n",
    "    return deck_counts, deck_percentages\n",
    "\n",
    "def display_pclass_dist(percentages):\n",
    "    \n",
    "    df_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n",
    "    bar_count = np.arange(len(deck_names))  \n",
    "    bar_width = 0.85\n",
    "    \n",
    "    pclass1 = df_percentages[0]\n",
    "    pclass2 = df_percentages[1]\n",
    "    pclass3 = df_percentages[2]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n",
    "    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n",
    "    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n",
    "\n",
    "    plt.xlabel('Deck', size=15, labelpad=20)\n",
    "    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n",
    "    plt.xticks(bar_count, deck_names)    \n",
    "    plt.tick_params(axis='x', labelsize=15)\n",
    "    plt.tick_params(axis='y', labelsize=15)\n",
    "    \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
    "    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n",
    "    \n",
    "    plt.show()    \n",
    "\n",
    "all_deck_count, all_deck_per = get_pclass_dist(df_all_decks)\n",
    "display_pclass_dist(all_deck_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mGF74pcsdAQ"
   },
   "source": [
    "* **A**, **B** ve **C** güvertelerinin **%100**'ü 1. sınıf yolcudur\n",
    "* Güverte **D**'nin **%87**'si 1. sınıf ve **%13**'ü 2. sınıf yolculara aittir.\n",
    "* Güverte **E**'nin **%83**'ü 1. sınıf, **%10**'u 2. sınıf ve **%7**'si 3. sınıf yolculara aittir.\n",
    "* Güverte **F**'nin **%62**'i 2. sınıf ve **%38**'i 3. sınıf yolculara aittir.\n",
    "* **G** güvertesinin %100**'ü 3. sınıf yolculardır.\n",
    "* **T** kabininde tekne güvertesinde 1 kişi olup 1. sınıf yolcudur. **T** kabin yolcusu **A** güverte yolcularına en yakın benzerliğe sahip olduğundan **A** güvertesi ile gruplandırılmıştır.\n",
    "* **M** olarak etiketlenen yolcular, `Cabin` özelliğinde eksik olan değerlerdir. Bu yolcuların gerçek `Deck`(Güverte)sini bulmanın mümkün değildir, bu yüzden **M**'yi güverte gibi kullanabiliriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxzDyO7FsdAQ"
   },
   "outputs": [],
   "source": [
    "# Passenger in the T deck is changed to A\n",
    "idx = df_all[df_all['Deck'] == 'T'].index\n",
    "df_all.loc[idx, 'Deck'] = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "89wDhNCSsdAR"
   },
   "outputs": [],
   "source": [
    "df_all_decks_survived = df_all.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare', \n",
    "                                                                                   'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name':'Count'}).transpose()\n",
    "\n",
    "def get_survived_dist(df):\n",
    "    \n",
    "    # Creating a dictionary for every survival count in every deck\n",
    "    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n",
    "    decks = df.columns.levels[0]    \n",
    "\n",
    "    for deck in decks:\n",
    "        for survive in range(0, 2):\n",
    "            surv_counts[deck][survive] = df[deck][survive][0]\n",
    "            \n",
    "    df_surv = pd.DataFrame(surv_counts)\n",
    "    surv_percentages = {}\n",
    "\n",
    "    for col in df_surv.columns:\n",
    "        surv_percentages[col] = [(count / df_surv[col].sum()) * 100 for count in df_surv[col]]\n",
    "        \n",
    "    return surv_counts, surv_percentages\n",
    "\n",
    "def display_surv_dist(percentages):\n",
    "    \n",
    "    df_survived_percentages = pd.DataFrame(percentages).transpose()\n",
    "    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n",
    "    bar_count = np.arange(len(deck_names))  \n",
    "    bar_width = 0.85    \n",
    "\n",
    "    not_survived = df_survived_percentages[0]\n",
    "    survived = df_survived_percentages[1]\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n",
    "    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n",
    " \n",
    "    plt.xlabel('Deck', size=15, labelpad=20)\n",
    "    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n",
    "    plt.xticks(bar_count, deck_names)    \n",
    "    plt.tick_params(axis='x', labelsize=15)\n",
    "    plt.tick_params(axis='y', labelsize=15)\n",
    "    \n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n",
    "    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "all_surv_count, all_surv_per = get_survived_dist(df_all_decks_survived)\n",
    "display_surv_dist(all_surv_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6G0QMtIsdAR"
   },
   "source": [
    "Daha önceden öngördüğümüz gibi, her güvertenin farklı hayatta kalma oranları var ve bu bilgi atılamayacak kadar değerli.\n",
    "\n",
    "Güverte **B**, **C**, **D** ve **E** en yüksek hayatta kalma oranlarına sahiptir. Bu güvertelerde çoğunlukla 1. sınıf yolcular bulunuyor. \n",
    "\n",
    "**M**, çoğunlukla 2. ve 3. sınıf yolcuların bulunduğu güvertedir ve en düşük hayatta kalma oranına sahiptir.\n",
    "\n",
    "Sonuç olarak, 1. sınıf yolcuların kullandığı kabinler, 2. ve 3. sınıf yolcuların kullandığı kabinlere göre daha yüksek hayatta kalma oranlarına sahiptir.\n",
    "\n",
    "Bana göre **M** (Eksik `Kabin` değerleri) olarak etiketlenmiş kişiler kabin verileri alınamadığı için en düşük hayatta kalma oranına sahip. Bu nedenle, bu grubu **M** olarak etiketlemenin, eksik verileri ele almanın makul bir yolu olduğuna inanıyoruz. Ortak özelliklere sahip benzersiz bir gruptur.\n",
    "\n",
    "`Deck` (Güverte) özelliği şu anda yüksek kardinaliteye sahip olduğundan, bazı değerler benzerliklerine göre gruplandırılmıştır.\n",
    "\n",
    "* **A**, **B** ve **C** güverteleri **ABC** olarak etiketlenmiştir çünkü hepsinde sadece 1. sınıf yolcu vardır **D** ve **E** güverteleri **DE** olarak etiketlenmiştir çünkü her ikisi de benzer yolcu sınıfı dağılımına ve aynı hayatta kalma oranına sahiptir. **F** ve **G** güverteleri yukarıdaki aynı nedenden dolayı **FG** olarak etiketlenmiştir. **M** güvertesi diğerlerinden çok farklı olduğu ve hayatta kalma oranı en düşük olduğu için diğer güvertelerle gruplandırılmasına gerek yoktur.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2H8T2qIKsdAR"
   },
   "outputs": [],
   "source": [
    "df_all['Deck'] = df_all['Deck'].replace(['A', 'B', 'C'], 'ABC')\n",
    "df_all['Deck'] = df_all['Deck'].replace(['D', 'E'], 'DE')\n",
    "df_all['Deck'] = df_all['Deck'].replace(['F', 'G'], 'FG')\n",
    "\n",
    "df_all['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JBGNvuSsdAT"
   },
   "source": [
    "`Age`, `Embarked`, `Fare` ve `Deck` (Yaş,Biniş,Ücret ve Güverte) özelliklerindeki eksik değerler doldurulduktan sonra hem eğitim hem de test setinde eksik değer kalmaz. `Cabin` yerine `Deck` özelliği kullanıldığı için, `Cabin` özelliği atılır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "mdKJaSQ2sdAT"
   },
   "outputs": [],
   "source": [
    "# Dropping the Cabin feature\n",
    "df_all.drop(['Cabin'], inplace=True, axis=1)\n",
    "\n",
    "df_train, df_test = divide_df(df_all)\n",
    "dfs = [df_train, df_test]\n",
    "\n",
    "for df in dfs:\n",
    "    display_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "83ed6dacdc116214381364c2b456a97253e708ef",
    "id": "2zRtcdb-sdAT"
   },
   "source": [
    "### **1.3 Hedef Dağılımı**\n",
    "* **%38,38** (342/891) eğitim seti **Sınıf 1**\n",
    "* **%61,62** (549/891) eğitim seti **Sınıf 0**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "c70aa13b7a552beb976574d52c1cd3da1cc1ee5c",
    "id": "2j6KJdeLsdAU"
   },
   "outputs": [],
   "source": [
    "survived = df_train['Survived'].value_counts()[1]\n",
    "not_survived = df_train['Survived'].value_counts()[0]\n",
    "survived_per = survived / df_train.shape[0] * 100\n",
    "not_survived_per = not_survived / df_train.shape[0] * 100\n",
    "\n",
    "print('{} of {} passengers survived and it is the {:.2f}% of the training set.'.format(survived, df_train.shape[0], survived_per))\n",
    "print('{} of {} passengers didnt survive and it is the {:.2f}% of the training set.'.format(not_survived, df_train.shape[0], not_survived_per))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.countplot(df_train['Survived'])\n",
    "\n",
    "plt.xlabel('Survival', size=15, labelpad=15)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=15)\n",
    "plt.xticks((0, 1), ['Not Survived ({0:.2f}%)'.format(not_survived_per), 'Survived ({0:.2f}%)'.format(survived_per)])\n",
    "plt.tick_params(axis='x', labelsize=13)\n",
    "plt.tick_params(axis='y', labelsize=13)\n",
    "\n",
    "plt.title('Training Set Survival Distribution', size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEtB7SLGsdAU"
   },
   "source": [
    "### **1.4 Korelasyon**\n",
    "\n",
    "Özellikler birbirleriyle yüksek oranda ilişkilidir ve birbirlerine bağımlıdır. Özellikler arasındaki en yüksek korelasyon, eğitim setinde **0.549500** ve test setinde **0.577147**'dir ( `Fare` ve `Pclass`'(Ücret ve Pclass) arasında). Diğer özellikler de oldukça ilişkilidir. Eğitim setinde **9** ve test setinde **0,1**'den yüksek **6** korelasyon vardır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "yLdKWAQ6sdAU"
   },
   "outputs": [],
   "source": [
    "df_train_corr = df_train.drop(['PassengerId'], axis=1).corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_train_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_train_corr.drop(df_train_corr.iloc[1::2].index, inplace=True)\n",
    "df_train_corr_nd = df_train_corr.drop(df_train_corr[df_train_corr['Correlation Coefficient'] == 1.0].index)\n",
    "\n",
    "df_test_corr = df_test.corr().abs().unstack().sort_values(kind=\"quicksort\", ascending=False).reset_index()\n",
    "df_test_corr.rename(columns={\"level_0\": \"Feature 1\", \"level_1\": \"Feature 2\", 0: 'Correlation Coefficient'}, inplace=True)\n",
    "df_test_corr.drop(df_test_corr.iloc[1::2].index, inplace=True)\n",
    "df_test_corr_nd = df_test_corr.drop(df_test_corr[df_test_corr['Correlation Coefficient'] == 1.0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "yID4fA8FsdAU"
   },
   "outputs": [],
   "source": [
    "# Training set high correlations\n",
    "corr = df_train_corr_nd['Correlation Coefficient'] > 0.1\n",
    "df_train_corr_nd[corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lTBdpWaSsdAV"
   },
   "outputs": [],
   "source": [
    "# Test set high correlations\n",
    "corr = df_test_corr_nd['Correlation Coefficient'] > 0.1\n",
    "df_test_corr_nd[corr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "eD2wHbkpsdAV"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "\n",
    "sns.heatmap(df_train.drop(['PassengerId'], axis=1).corr(), ax=axs[0], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "sns.heatmap(df_test.drop(['PassengerId'], axis=1).corr(), ax=axs[1], annot=True, square=True, cmap='coolwarm', annot_kws={'size': 14})\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='x', labelsize=14)\n",
    "    axs[i].tick_params(axis='y', labelsize=14)\n",
    "    \n",
    "axs[0].set_title('Training Set Correlations', size=15)\n",
    "axs[1].set_title('Test Set Correlations', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "he6k0GwasdAV"
   },
   "source": [
    "### **1.5 Özelliklerde Hedef Dağılımı**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQwWrK-HsdAV"
   },
   "source": [
    "#### **1.5.1 Continuous Features (Sürekli Özellikler)**\n",
    "\n",
    "Sürekli özelliklerin her ikisi de (`Age` ve `Fare`(Yaş ve Ücret)), bir karar ağacının öğrenmesi için iyi bölünme noktalarına ve sivri uçlara sahiptir. Her iki özellik için olası bir sorun, dağılımın eğitim setinde daha fazla ani ve tümseklere sahip olması, ancak test setinde daha düzgün olmasıdır. Bu nedenle model test setine genelleme yapamayabilir.\n",
    "\n",
    "* `Age`(Yaş) özelliğinin dağılımı, 15 yaşından küçük çocukların diğer yaş gruplarından herhangi birine göre daha yüksek bir hayatta kalma oranına sahip olduğunu açıkça göstermektedir.\n",
    "* `Fare` özelliğinin dağılımında, dağıtım kuyruklarında hayatta kalma oranı daha yüksektir. Aşırı büyük aykırı değerler nedeniyle dağılım da pozitif çarpıklığa sahiptir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "y_8RYugfsdAV"
   },
   "outputs": [],
   "source": [
    "cont_features = ['Age', 'Fare']\n",
    "surv = df_train['Survived'] == 1\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "for i, feature in enumerate(cont_features):    \n",
    "    # Distribution of survival in feature\n",
    "    sns.distplot(df_train[~surv][feature], label='Not Survived', hist=True, color='#e74c3c', ax=axs[0][i])\n",
    "    sns.distplot(df_train[surv][feature], label='Survived', hist=True, color='#2ecc71', ax=axs[0][i])\n",
    "    \n",
    "    # Distribution of feature in dataset\n",
    "    sns.distplot(df_train[feature], label='Training Set', hist=False, color='#e74c3c', ax=axs[1][i])\n",
    "    sns.distplot(df_test[feature], label='Test Set', hist=False, color='#2ecc71', ax=axs[1][i])\n",
    "    \n",
    "    axs[0][i].set_xlabel('')\n",
    "    axs[1][i].set_xlabel('')\n",
    "    \n",
    "    for j in range(2):        \n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "    \n",
    "    axs[0][i].legend(loc='upper right', prop={'size': 20})\n",
    "    axs[1][i].legend(loc='upper right', prop={'size': 20})\n",
    "    axs[0][i].set_title('Distribution of Survival in {}'.format(feature), size=20, y=1.05)\n",
    "\n",
    "axs[1][0].set_title('Distribution of {} Feature'.format('Age'), size=20, y=1.05)\n",
    "axs[1][1].set_title('Distribution of {} Feature'.format('Fare'), size=20, y=1.05)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXR0N71AsdAW"
   },
   "source": [
    "#### **1.5.2 Categorical Features (Kategorik Özellikler)**\n",
    "\n",
    "Her kategorik özellik, yüksek ölüm oranına sahip en az bir sınıfa sahiptir. Bu sınıflar, yolcunun hayatta kalan mı yoksa mağdur mu olduğunu tahmin etmek için çok faydalıdır. En iyi kategorik özellikler, en homojen dağılımlara sahip oldukları için `Pclass` ve `Sex`tir.\n",
    "\n",
    "* **Southampton**'dan uçağa binen yolcular, diğer limanlardan farklı olarak daha düşük bir hayatta kalma oranına sahiptir. **Cherbourg**'dan kalkan yolcuların yarısından fazlası hayatta kaldı. Bu gözlem `Pclass` özelliği ile ilgili olabilir.\n",
    "* `Parch` ve `SibSp` özellikleri, sadece bir aile üyesi olan yolcuların hayatta kalma oranının daha yüksek olduğunu gösteriyor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "6t1Pb2UrsdAW"
   },
   "outputs": [],
   "source": [
    "cat_features = ['Embarked', 'Parch', 'Pclass', 'Sex', 'SibSp', 'Deck']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=3, figsize=(20, 20))\n",
    "plt.subplots_adjust(right=1.5, top=1.25)\n",
    "\n",
    "for i, feature in enumerate(cat_features, 1):    \n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.countplot(x=feature, hue='Survived', data=df_train)\n",
    "    \n",
    "    plt.xlabel('{}'.format(feature), size=20, labelpad=15)\n",
    "    plt.ylabel('Passenger Count', size=20, labelpad=15)    \n",
    "    plt.tick_params(axis='x', labelsize=20)\n",
    "    plt.tick_params(axis='y', labelsize=20)\n",
    "    \n",
    "    plt.legend(['Not Survived', 'Survived'], loc='upper center', prop={'size': 18})\n",
    "    plt.title('Count of Survival in {} Feature'.format(feature), size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPfa94BNsdAW"
   },
   "source": [
    "### **1.6 Sonuç**\n",
    "\n",
    "Özelliklerin çoğu birbiriyle ilişkilidir. Bu ilişki, özellik dönüşümü ve özellik etkileşimi ile yeni özellikler oluşturmak için kullanılabilir. `Survived` özelliği ile yüksek korelasyonlar nedeniyle hedef kodlama da çok yararlı olabilir.\n",
    "\n",
    "Bölünmüş noktalar ve sivri uçlar, sürekli özelliklerde görülebilir. Bir karar ağacı modeli ile kolayca yakalanabilirler, ancak doğrusal modeller onları tespit edemeyebilir.\n",
    "\n",
    "Kategorik özellikler, farklı hayatta kalma oranları ile çok farklı dağılımlara sahiptir. Bu özellikler one-hot olarak kodlanabilir. Bu özelliklerden bazıları, yeni özellikler oluşturmak için birbirleriyle birleştirilebilir.\n",
    "\n",
    "`Deck`(Güverte) adında yeni bir özellik oluşturuldu ve **Keşifsel Veri Analizi** bölümünde `Cabin` özelliği kaldırıldı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "uLfzlJ1rsdAW"
   },
   "outputs": [],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e14506a365afef0af44894e46642acf27ac2545f",
    "id": "JVKYAH5XsdAW"
   },
   "source": [
    "## **2. Feature Engineering (Özellik Mühendisliği)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69v5aoDZsdAX"
   },
   "source": [
    "### **2.1 Binning Continuous Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsE8MrfUsdAX"
   },
   "source": [
    "#### **2.1.1 Fare (Ücret)**\n",
    "\n",
    "`Fare` özelliği olumlu bir şekilde çarpıktır ve sağ uçta hayatta kalma oranı son derece yüksektir. `Fare` özelliği için **13** nicel tabanlı binler kullanılır. Binler çok fazla olmasına rağmen, yeterli miktarda bilgi kazancı sağlarlar. Grafiğin sol tarafındaki gruplar en düşük hayatta kalma oranına ve grafiğin sağ tarafındaki gruplar en yüksek hayatta kalma oranına sahiptir. Bu yüksek hayatta kalma oranı dağılım grafiğinde görünmüyordu. Ortada da bu süreçte yakalanan, hayatta kalma oranı yüksek, sıra dışı bir grup **(15.742, 23.25]** var.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOFA0tOksdAX"
   },
   "outputs": [],
   "source": [
    "df_all['Fare'] = pd.qcut(df_all['Fare'], 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "S70xqsalsdAX"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(22, 9))\n",
    "sns.countplot(x='Fare', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Fare', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=10)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of Survival in {} Feature'.format('Fare'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCz20lObsdAX"
   },
   "source": [
    "#### **2.1.2 Age (Yaş)**\n",
    "`Age` özelliği, bazı ani yükselmeler ve tümsekler ile normal bir dağılıma sahiptir ve `Age` için **10** nicel tabanlı kutular kullanılır. İlk kutu en yüksek hayatta kalma oranına ve 4. kutu en düşük hayatta kalma oranına sahiptir. Bunlar dağıtımdaki en büyük artışlardı. Bu süreçte yakalanan, yüksek hayatta kalma oranına sahip alışılmadık bir **(34.0, 40.0]** grubu da var.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hX6QW132sdAX"
   },
   "outputs": [],
   "source": [
    "df_all['Age'] = pd.qcut(df_all['Age'], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "RUd0dbAUsdAY"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(22, 9))\n",
    "sns.countplot(x='Age', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Age', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Survival Counts in {} Feature'.format('Age'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tz0FgoMLsdAY"
   },
   "source": [
    "### **2.2 Frequency Encoding (Frekans Kodlama)**\n",
    "\n",
    "`Family_Size`, `SibSp`, `Parch` and **1** eklenerek oluşturulur. `SibSp` kardeşlerin ve eşlerin sayısıdır ve `Parch` ebeveynlerin ve çocukların sayısıdır. Ailelerin toplam büyüklüğünü bulmak için bu sütunlar eklenir.\n",
    "\n",
    "Sonuna **1** eklenmesi mevcut yolcudan dolayıdır. Grafikler, farklı değerlerin farklı hayatta kalma oranlarına sahip olması nedeniyle, aile boyutunun hayatta kalmanın bir göstergesi olduğunu açıkça göstermiştir.\n",
    "\n",
    "* Aile Boyutu **1** ise **Alone** (Yalnız) olarak etiketlenmiştir.\n",
    "* Aile Boyutu **2**, **3** ve **4** ise **Small** (Küçük) olarak etiketlenmiştir.\n",
    "* Aile Büyüklüğü **5** ve **6** ise **Medium** (Orta) olarak etiketlenmiştir.\n",
    "* Aile Boyu **7**, **8** ve **11** ise **Large** (Büyük) olarak etiketlenmiştir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "A9E7mLGjsdAY"
   },
   "outputs": [],
   "source": [
    "df_all['Family_Size'] = df_all['SibSp'] + df_all['Parch'] + 1\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(20, 20), ncols=2, nrows=2)\n",
    "plt.subplots_adjust(right=1.5)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size'].value_counts().index, y=df_all['Family_Size'].value_counts().values, ax=axs[0][0])\n",
    "sns.countplot(x='Family_Size', hue='Survived', data=df_all, ax=axs[0][1])\n",
    "\n",
    "axs[0][0].set_title('Family Size Feature Value Counts', size=20, y=1.05)\n",
    "axs[0][1].set_title('Survival Counts in Family Size ', size=20, y=1.05)\n",
    "\n",
    "family_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\n",
    "df_all['Family_Size_Grouped'] = df_all['Family_Size'].map(family_map)\n",
    "\n",
    "sns.barplot(x=df_all['Family_Size_Grouped'].value_counts().index, y=df_all['Family_Size_Grouped'].value_counts().values, ax=axs[1][0])\n",
    "sns.countplot(x='Family_Size_Grouped', hue='Survived', data=df_all, ax=axs[1][1])\n",
    "\n",
    "axs[1][0].set_title('Family Size Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "axs[1][1].set_title('Survival Counts in Family Size After Grouping', size=20, y=1.05)\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i][1].legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 20})\n",
    "    for j in range(2):\n",
    "        axs[i][j].tick_params(axis='x', labelsize=20)\n",
    "        axs[i][j].tick_params(axis='y', labelsize=20)\n",
    "        axs[i][j].set_xlabel('')\n",
    "        axs[i][j].set_ylabel('')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoWuQR02sdAY"
   },
   "source": [
    "Analiz edilecek çok fazla benzersiz `Ticket` değeri olduğundan, bunları frekanslarına göre gruplandırmak işleri kolaylaştırır.\n",
    "\n",
    "**Bu özelliğin `Family_Size` dan farkı nedir?** Birçok yolcu gruplar halinde seyahat etti. Bu gruplar arkadaş, dadı, hizmetçi vb. kişilerden oluşur. Aileden sayılmazlar ama aynı bileti kullanırlardı.\n",
    "\n",
    "**Biletleri neden öneklerine göre gruplandırmıyorsunuz?** Eğer `Ticket` özelliğindeki öneklerin bir anlamı varsa, o zaman zaten `Pclass` veya `Embarked` özelliklerinde yakalanmıştır çünkü bu, `Ticket` özelliğinden türetilebilecek tek mantıksal bilgi olabilir. .\n",
    "\n",
    "Aşağıdaki grafiğe göre **2**,**3** ve **4** üyeli grupların hayatta kalma oranları daha yüksekti. Yalnız seyahat eden yolcular en düşük hayatta kalma oranına sahiptir. **4** grup üyesinden sonra hayatta kalma oranı önemli ölçüde azalır. Bu model, `Family_Size` özelliğine çok benzer, ancak küçük farklılıklar vardır. `Ticket_Frequency` değerleri `Family_Size` gibi gruplandırılmaz çünkü bu temelde aynı özelliği mükemmel bir korelasyonla yaratacaktır. Bu tür bir özellik herhangi bir ek bilgi kazancı sağlamayacaktır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vZxhVrLrsdAY"
   },
   "outputs": [],
   "source": [
    "df_all['Ticket_Frequency'] = df_all.groupby('Ticket')['Ticket'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "QTG9Ow7ssdAY"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 9))\n",
    "sns.countplot(x='Ticket_Frequency', hue='Survived', data=df_all)\n",
    "\n",
    "plt.xlabel('Ticket Frequency', size=15, labelpad=20)\n",
    "plt.ylabel('Passenger Count', size=15, labelpad=20)\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "\n",
    "plt.legend(['Not Survived', 'Survived'], loc='upper right', prop={'size': 15})\n",
    "plt.title('Count of Survival in {} Feature'.format('Ticket Frequency'), size=15, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNbVChihsdAZ"
   },
   "source": [
    "### **2.3 Title & Is Married (Ünvan ve Evlilik Durumu)**\n",
    "\n",
    "`Title`, `Name` özelliğinden önceki önek çıkarılarak oluşturulur. Aşağıdaki grafiğe göre, çok az kez ortaya çıkan birçok ünvan (title) var. Bu başlıklardan bazıları doğru görünmüyor ve değiştirilmeleri gerekiyor. **Miss**, **Mrs**, **Ms**, **Mlle**, **Lady**, **Mme**, **the Countess**, **Dona** unvanları hepsi kadın olduğu için **Miss/Mrs/Ms** ile değiştirildi. **Mlle**, **Mme** ve **Dona** gibi değerler aslında yolcuların adıdır, ancak `Name` özelliği virgülle ayrıldığı için ünvan olarak sınıflandırılırlar. **Dr**, **Col**, **Major**, **Jonkheer**, **Capt**, **Sir**, **Don** ve **Rev** unvanları **Dr/Military/Noble/Clergy** ile değiştirilmiştir. Çünkü bu yolcular benzer özelliklere sahiptir. **Master** benzersiz bir unvandır. **26** yaşından küçük erkek yolculara verilir. Tüm erkekler arasında en yüksek hayatta kalma oranına sahiptirler.\n",
    "\n",
    "`Is_Married`, **Mrs** ünvanına dayalı bir ikili özelliktir. **Mrs** unvanı, diğer kadın unvanları arasında en yüksek hayatta kalma oranına sahiptir. Bu ünvanın bir özellik olması gerekiyor çünkü tüm kadın ünvanlar birbiriyle gruplandırılıyor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4tk2Z5GsdAZ"
   },
   "outputs": [],
   "source": [
    "df_all['Title'] = df_all['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "df_all['Is_Married'] = 0\n",
    "df_all['Is_Married'].loc[df_all['Title'] == 'Mrs'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "RbZfOgqvsdAZ"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, figsize=(20, 20))\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[0])\n",
    "\n",
    "axs[0].tick_params(axis='x', labelsize=10)\n",
    "axs[1].tick_params(axis='x', labelsize=15)\n",
    "\n",
    "for i in range(2):    \n",
    "    axs[i].tick_params(axis='y', labelsize=15)\n",
    "\n",
    "axs[0].set_title('Title Feature Value Counts', size=20, y=1.05)\n",
    "\n",
    "df_all['Title'] = df_all['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "df_all['Title'] = df_all['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n",
    "\n",
    "sns.barplot(x=df_all['Title'].value_counts().index, y=df_all['Title'].value_counts().values, ax=axs[1])\n",
    "axs[1].set_title('Title Feature Value Counts After Grouping', size=20, y=1.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIRBmEIHsdAZ"
   },
   "source": [
    "### **2.4 Target Encoding (Hedef Kodlama)**\n",
    "Yolcuların soyadlarını `Name` özelliğinden çıkarmak için `extract_surname` işlevi kullanılır. Çıkarılan soyadı ile `Family` özelliği oluşturulur. Bu, aynı ailedeki yolcuları gruplamak için gereklidir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnTeGVj6sdAZ"
   },
   "outputs": [],
   "source": [
    "def extract_surname(data):    \n",
    "    \n",
    "    families = []\n",
    "    \n",
    "    for i in range(len(data)):        \n",
    "        name = data.iloc[i]\n",
    "\n",
    "        if '(' in name:\n",
    "            name_no_bracket = name.split('(')[0] \n",
    "        else:\n",
    "            name_no_bracket = name\n",
    "            \n",
    "        family = name_no_bracket.split(',')[0]\n",
    "        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n",
    "        \n",
    "        for c in string.punctuation:\n",
    "            family = family.replace(c, '').strip()\n",
    "            \n",
    "        families.append(family)\n",
    "            \n",
    "    return families\n",
    "\n",
    "df_all['Family'] = extract_surname(df_all['Name'])\n",
    "df_train = df_all.loc[:890]\n",
    "df_test = df_all.loc[891:]\n",
    "dfs = [df_train, df_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k599PN-RsdAZ"
   },
   "source": [
    "Test setinde `Survived` özelliği olmadığı için eğitim setindeki ailelerden `Family_Survival_Rate`(Aile_Hayatta Kalma_Oranı) hesaplanır. Hem eğitim hem de test setinde (`un_unique_families`) meydana gelen aile adlarının bir listesi oluşturulur. O listede 1'den fazla üyesi olan aileler için hayatta kalma oranı hesaplanır ve `Family_Survival_Rate` özelliğinde saklanır.\n",
    "\n",
    "Test setine özgü aileler için ekstra bir ikili özellik `Family_Survival_Rate_NA` oluşturulur. Bu özellik aynı zamanda gereklidir çünkü bu ailelerin hayatta kalma oranlarını hesaplamanın bir yolu yoktur. Bu özellik, hayatta kalma oranlarını geri almanın bir yolu olmadığı için aile hayatta kalma oranının bu yolcular için geçerli olmadığını ima eder.\n",
    "\n",
    "`Ticket_Survival_Rate` ve `Ticket_Survival_Rate_NA` özellikleri de aynı yöntemle oluşturulur. `Ticket_Survival_Rate` ve `Family_Survival_Rate` değerlerinin ortalaması alınır ve `Survival_Rate` olur ve `Ticket_Survival_Rate_NA` ve `Family_Survival_Rate_NA` nında ortalaması alınır ve `Survival_Rate_NA` olur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lG9cLJ-dsdAa"
   },
   "outputs": [],
   "source": [
    "# Creating a list of families and tickets that are occuring in both training and test set\n",
    "non_unique_families = [x for x in df_train['Family'].unique() if x in df_test['Family'].unique()]\n",
    "non_unique_tickets = [x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()]\n",
    "\n",
    "df_family_survival_rate = df_train.groupby('Family')['Survived', 'Family','Family_Size'].median()\n",
    "df_ticket_survival_rate = df_train.groupby('Ticket')['Survived', 'Ticket','Ticket_Frequency'].median()\n",
    "\n",
    "family_rates = {}\n",
    "ticket_rates = {}\n",
    "\n",
    "for i in range(len(df_family_survival_rate)):\n",
    "    # Checking a family exists in both training and test set, and has members more than 1\n",
    "    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n",
    "        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n",
    "\n",
    "for i in range(len(df_ticket_survival_rate)):\n",
    "    # Checking a ticket exists in both training and test set, and has members more than 1\n",
    "    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n",
    "        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzQZlEutsdAa"
   },
   "outputs": [],
   "source": [
    "mean_survival_rate = np.mean(df_train['Survived'])\n",
    "\n",
    "train_family_survival_rate = []\n",
    "train_family_survival_rate_NA = []\n",
    "test_family_survival_rate = []\n",
    "test_family_survival_rate_NA = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['Family'][i] in family_rates:\n",
    "        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n",
    "        train_family_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        train_family_survival_rate.append(mean_survival_rate)\n",
    "        train_family_survival_rate_NA.append(0)\n",
    "        \n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Family'].iloc[i] in family_rates:\n",
    "        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n",
    "        test_family_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        test_family_survival_rate.append(mean_survival_rate)\n",
    "        test_family_survival_rate_NA.append(0)\n",
    "        \n",
    "df_train['Family_Survival_Rate'] = train_family_survival_rate\n",
    "df_train['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\n",
    "df_test['Family_Survival_Rate'] = test_family_survival_rate\n",
    "df_test['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n",
    "\n",
    "train_ticket_survival_rate = []\n",
    "train_ticket_survival_rate_NA = []\n",
    "test_ticket_survival_rate = []\n",
    "test_ticket_survival_rate_NA = []\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    if df_train['Ticket'][i] in ticket_rates:\n",
    "        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n",
    "        train_ticket_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        train_ticket_survival_rate.append(mean_survival_rate)\n",
    "        train_ticket_survival_rate_NA.append(0)\n",
    "        \n",
    "for i in range(len(df_test)):\n",
    "    if df_test['Ticket'].iloc[i] in ticket_rates:\n",
    "        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n",
    "        test_ticket_survival_rate_NA.append(1)\n",
    "    else:\n",
    "        test_ticket_survival_rate.append(mean_survival_rate)\n",
    "        test_ticket_survival_rate_NA.append(0)\n",
    "        \n",
    "df_train['Ticket_Survival_Rate'] = train_ticket_survival_rate\n",
    "df_train['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\n",
    "df_test['Ticket_Survival_Rate'] = test_ticket_survival_rate\n",
    "df_test['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ttNB8VVasdAa"
   },
   "outputs": [],
   "source": [
    "for df in [df_train, df_test]:\n",
    "    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) / 2\n",
    "    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) / 2    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b39a06d42b89d64f59f51a21dabdc5fe27fdcdaa",
    "id": "Qkwrzi8AsdAa"
   },
   "source": [
    "### **2.5 Feature Transformation (Özellik Dönüşümü)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9gKLXBBsdAa"
   },
   "source": [
    "#### **2.5.1 Sayısal Olmayan Özelliklerde Etiket Kodlama**\n",
    "`Embarked`, `Sex`, `Deck` , `Title` ve `Family_Size_Grouped` nesne türüdür ve `Age` ve `Fare` özellikleri kategori türüdür. `LabelEncoder` ile sayısal türe dönüştürülürler. `LabelEncoder` temel olarak **0** ile **n** arasındaki sınıfları etiketler. Bu süreç, modellerin bu özelliklerden öğrenmesi için gereklidir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tmoZWEWysdAb"
   },
   "outputs": [],
   "source": [
    "non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in non_numeric_features:        \n",
    "        df[feature] = LabelEncoder().fit_transform(df[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a98csPHusdAb"
   },
   "source": [
    "#### **2.5.2 One-Hot Encoding the Categorical Features (Kategorik Özellikleri One-Hot Kodlama)**\n",
    "\n",
    "Kategorik özellikler (`Pclass`, `Sex`, `Deck`, `Embarked`, `Title`) `OneHotEncoder` ile one-hot kodlanmış özelliklere dönüştürülür. `Age` ve`Fare` özellikleri, öncekilerden farklı olarak sıralı oldukları için dönüştürülmez.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOoe9L1wsdAb"
   },
   "outputs": [],
   "source": [
    "cat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped']\n",
    "encoded_features = []\n",
    "\n",
    "for df in dfs:\n",
    "    for feature in cat_features:\n",
    "        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n",
    "        n = df[feature].nunique()\n",
    "        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n",
    "        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n",
    "        encoded_df.index = df.index\n",
    "        encoded_features.append(encoded_df)\n",
    "\n",
    "df_train = pd.concat([df_train, *encoded_features[:6]], axis=1)\n",
    "df_test = pd.concat([df_test, *encoded_features[6:]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ietUdieKsdAb"
   },
   "source": [
    "### **2.6 Sonuç**\n",
    "`Age` ve `Fare` özellikleri gruplandırılmıştır. Binning, aykırı değerlerle başa çıkmaya yardımcı oldu ve bu özelliklerde bazı homojen grupları ortaya çıkardı. `Family_Size`, `Parch` ve `SibSp` özellikleri ve **1** eklenerek oluşturulur. `Ticket_Frequency`, `Ticket` değerlerinin oluşumu sayılarak oluşturulur.\n",
    "\n",
    "`Name` özelliği çok kullanışlıdır. İlk olarak, isimlerdeki başlık önekinden `Title` ve `Is_Married` özellikleri oluşturulur. İkinci olarak, yolcuların soyadını kodlayan hedef tarafından `Family_Survival_Rate` ve `Family_Survival_Rate_NA` özellikleri oluşturulur. `Ticket_Survival_Rate`, `Ticket` özelliğini kodlayan hedef tarafından oluşturulur. `Survival_Rate` özelliği, `Family_Survival_Rate` ve `Ticket_Survival_Rate` özelliklerinin ortalaması alınarak oluşturulur.\n",
    "\n",
    "Son olarak, sayısal olmayan türdeki özellikler etiket kodludur ve kategorik özellikler tek sıcak kodludur. **5** yeni özellik (`Family_Size`, `Title`, `Is_Married`, `Survival_Rate` ve `Survival_Rate_NA`) oluşturuldu ve kodlamadan sonra gereksiz özellikler kaldırıldı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "_8zpVGdesdAb"
   },
   "outputs": [],
   "source": [
    "df_all = concat_df(df_train, df_test)\n",
    "drop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n",
    "             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n",
    "            'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n",
    "\n",
    "df_all.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b3d47212b52113b53a3e6d0d0a4ee08aa97b02f",
    "id": "KzmKTceusdAb"
   },
   "source": [
    "## **3. Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5orcU8P5sdAc"
   },
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(df_train.drop(columns=drop_cols))\n",
    "y_train = df_train['Survived'].values\n",
    "X_test = StandardScaler().fit_transform(df_test.drop(columns=drop_cols))\n",
    "\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no4LYXx6sdAc"
   },
   "source": [
    "### **3.1 Random Forest**\n",
    "\n",
    "2 `RandomForestClassifier` oluşturuldu. Bunlardan biri tek model, diğeri ise k-fold cross validation içindir.\n",
    "\n",
    "`single_best_model`in en yüksek doğruluğu, genel liderlik tablosunda **0.82775**'tir. Ancak, k-fold cross validation da daha iyi performans göstermez. Denemeye ve hiperparametre ayarlamaya başlamak için iyi bir modeldir.\n",
    "\n",
    "`leaderboard_model`in en yüksek doğruluğu, 5-fold cross validation ile genel liderlik tablosunda **0.83732**'dir. Bu model skor tablosu puanı için oluşturulmuştur ve biraz fazla overfit şekilde ayarlanmıştır. Overfit olacak şekilde tasarlanmıştır, çünkü her folddaki \"X_test\"in tahmini olasılıkları **N**'ye (fold sayısı) bölünecektir. Bu model tek bir model olarak kullanılırsa çok sayıda örneği doğru tahmin etmek zor olacaktır.\n",
    "\n",
    "**Hangi modeli kullanmalıyım?**\n",
    "* `leaderboard_model` test setine overfit oluyor, bu nedenle gerçek hayattaki projelerde bu gibi modellerin kullanılması önerilmez.\n",
    "* `single_best_model`, karar ağaçları hakkında denemeye ve öğrenmeye başlamak için iyi bir modeldir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tgQrl26sdAc"
   },
   "outputs": [],
   "source": [
    "single_best_model = RandomForestClassifier(criterion='gini', \n",
    "                                           n_estimators=1100,\n",
    "                                           max_depth=5,\n",
    "                                           min_samples_split=4,\n",
    "                                           min_samples_leaf=5,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=SEED,\n",
    "                                           n_jobs=-1,\n",
    "                                           verbose=1)\n",
    "\n",
    "leaderboard_model = RandomForestClassifier(criterion='gini',\n",
    "                                           n_estimators=1750,\n",
    "                                           max_depth=7,\n",
    "                                           min_samples_split=6,\n",
    "                                           min_samples_leaf=6,\n",
    "                                           max_features='auto',\n",
    "                                           oob_score=True,\n",
    "                                           random_state=SEED,\n",
    "                                           n_jobs=-1,\n",
    "                                           verbose=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xC2sDRRrsdAd"
   },
   "source": [
    "`StratifiedKFold`, hedef değişkeni katmanlaştırmak için kullanılır. Kıvrımlar, hedef değişkende (`Survived`) her sınıf için örneklem yüzdesi korunarak yapılır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Doy259Z4sdAd"
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "oob = 0\n",
    "probs = pd.DataFrame(np.zeros((len(X_test), N * 2)), columns=['Fold_{}_Prob_{}'.format(i, j) for i in range(1, N + 1) for j in range(2)])\n",
    "importances = pd.DataFrame(np.zeros((X_train.shape[1], N)), columns=['Fold_{}'.format(i) for i in range(1, N + 1)], index=df_all.columns)\n",
    "fprs, tprs, scores = [], [], []\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N, random_state=N, shuffle=True)\n",
    "\n",
    "for fold, (trn_idx, val_idx) in enumerate(skf.split(X_train, y_train), 1):\n",
    "    print('Fold {}\\n'.format(fold))\n",
    "    \n",
    "    # Fitting the model\n",
    "    leaderboard_model.fit(X_train[trn_idx], y_train[trn_idx])\n",
    "    \n",
    "    # Computing Train AUC score\n",
    "    trn_fpr, trn_tpr, trn_thresholds = roc_curve(y_train[trn_idx], leaderboard_model.predict_proba(X_train[trn_idx])[:, 1])\n",
    "    trn_auc_score = auc(trn_fpr, trn_tpr)\n",
    "    # Computing Validation AUC score\n",
    "    val_fpr, val_tpr, val_thresholds = roc_curve(y_train[val_idx], leaderboard_model.predict_proba(X_train[val_idx])[:, 1])\n",
    "    val_auc_score = auc(val_fpr, val_tpr)  \n",
    "      \n",
    "    scores.append((trn_auc_score, val_auc_score))\n",
    "    fprs.append(val_fpr)\n",
    "    tprs.append(val_tpr)\n",
    "    \n",
    "    # X_test probabilities\n",
    "    probs.loc[:, 'Fold_{}_Prob_0'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 0]\n",
    "    probs.loc[:, 'Fold_{}_Prob_1'.format(fold)] = leaderboard_model.predict_proba(X_test)[:, 1]\n",
    "    importances.iloc[:, fold - 1] = leaderboard_model.feature_importances_\n",
    "        \n",
    "    oob += leaderboard_model.oob_score_ / N\n",
    "    print('Fold {} OOB Score: {}\\n'.format(fold, leaderboard_model.oob_score_))   \n",
    "    \n",
    "print('Average OOB Score: {}'.format(oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gQFRJl8sdAd"
   },
   "source": [
    "### **3.2 Feature Importance (Özelliğin Önemi)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "A116zj6DsdAd"
   },
   "outputs": [],
   "source": [
    "importances['Mean_Importance'] = importances.mean(axis=1)\n",
    "importances.sort_values(by='Mean_Importance', inplace=True, ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 20))\n",
    "sns.barplot(x='Mean_Importance', y=importances.index, data=importances)\n",
    "\n",
    "plt.xlabel('')\n",
    "plt.tick_params(axis='x', labelsize=15)\n",
    "plt.tick_params(axis='y', labelsize=15)\n",
    "plt.title('Random Forest Classifier Mean Feature Importance Between Folds', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3ctBoc2sdAe"
   },
   "source": [
    "### **3.3 ROC Curve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "id": "Ct9IEOamsdAe"
   },
   "outputs": [],
   "source": [
    "def plot_roc_curve(fprs, tprs):\n",
    "    \n",
    "    tprs_interp = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    f, ax = plt.subplots(figsize=(15, 15))\n",
    "    \n",
    "    # Plotting ROC for each fold and computing AUC scores\n",
    "    for i, (fpr, tpr) in enumerate(zip(fprs, tprs), 1):\n",
    "        tprs_interp.append(np.interp(mean_fpr, fpr, tpr))\n",
    "        tprs_interp[-1][0] = 0.0\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        aucs.append(roc_auc)\n",
    "        ax.plot(fpr, tpr, lw=1, alpha=0.3, label='ROC Fold {} (AUC = {:.3f})'.format(i, roc_auc))\n",
    "        \n",
    "    # Plotting ROC for random guessing\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', alpha=0.8, label='Random Guessing')\n",
    "    \n",
    "    mean_tpr = np.mean(tprs_interp, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    \n",
    "    # Plotting the mean ROC\n",
    "    ax.plot(mean_fpr, mean_tpr, color='b', label='Mean ROC (AUC = {:.3f} $\\pm$ {:.3f})'.format(mean_auc, std_auc), lw=2, alpha=0.8)\n",
    "    \n",
    "    # Plotting the standard deviation around the mean ROC Curve\n",
    "    std_tpr = np.std(tprs_interp, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label='$\\pm$ 1 std. dev.')\n",
    "    \n",
    "    ax.set_xlabel('False Positive Rate', size=15, labelpad=20)\n",
    "    ax.set_ylabel('True Positive Rate', size=15, labelpad=20)\n",
    "    ax.tick_params(axis='x', labelsize=15)\n",
    "    ax.tick_params(axis='y', labelsize=15)\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_ylim([-0.05, 1.05])\n",
    "\n",
    "    ax.set_title('ROC Curves of Folds', size=20, y=1.02)\n",
    "    ax.legend(loc='lower right', prop={'size': 13})\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_roc_curve(fprs, tprs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WL-IkVR1OsVE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Feature Engineering-titanic-advanced-feature-engineering-tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
