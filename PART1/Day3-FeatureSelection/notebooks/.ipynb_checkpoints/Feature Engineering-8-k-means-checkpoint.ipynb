{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uhrepf9XjL9k",
   "metadata": {
    "id": "uhrepf9XjL9k"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16LOCrUXjNPy",
   "metadata": {
    "id": "16LOCrUXjNPy"
   },
   "outputs": [],
   "source": [
    "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day3-FeatureSelection/notebooks\"\n",
    "ROOT_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART1/Day3-FeatureSelection/notebooks\"\n",
    "DATASET_PATH = ROOT_DIR + \"/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13311f",
   "metadata": {
    "id": "2f13311f",
    "papermill": {
     "duration": 0.008598,
     "end_time": "2021-10-27T20:04:24.252143",
     "exception": false,
     "start_time": "2021-10-27T20:04:24.243545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Giriş #\n",
    "\n",
    "Bu ders ve bir sonraki ders, *denetimsiz öğrenme* algoritmaları olarak bilinenlerden yararlanmaktadır. Denetimsiz algoritmalar bir hedef kullanmaz; bunun yerine amaçları, verilerin bazı özelliklerini öğrenmek, özelliklerin yapısını belirli bir şekilde temsil etmektir. Tahmin için özellik mühendisliği bağlamında, denetimsiz bir algoritmayı bir \"özellik keşfi\" tekniği olarak düşünebilirsiniz.\n",
    "\n",
    "**Kümeleme** basitçe, noktaların birbirine ne kadar benzer olduğuna bağlı olarak gruplara veri noktalarının atanması anlamına gelir. Bir kümeleme algoritması, tabiri caizse, \"tüy kuşlarının bir araya gelmesini\" sağlar.\n",
    "\n",
    "Özellik mühendisliği için kullanıldığında, örneğin bir pazar segmentini temsil eden müşteri gruplarını veya benzer hava durumu modellerini paylaşan coğrafi alanları keşfetmeye çalışabiliriz. Küme etiketlerinin bir özelliğinin eklenmesi, makine öğrenimi modellerinin karmaşık alan veya yakınlık ilişkilerini çözmesine yardımcı olabilir.\n",
    "\n",
    "# Özellik Olarak Küme Etiketleri #\n",
    "\n",
    "Tek bir gerçek değerli özelliğe uygulanan kümeleme, geleneksel bir \"bölmeleme\" veya [\"ayrıklaştırma\"] dönüşümü gibi davranır. Birden çok özellik üzerinde, \"çok boyutlu gruplama\" gibidir (bazen *vektör niceleme* olarak adlandırılır).\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/sr3pdYI.png\" width=800, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center><strong>Sol:</strong> Tek bir özelliğin kümelenmesi. <strong>Sağ:</strong> İki özellik arasında kümeleme.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Bir data frame'e eklendiğinde, küme etiketlerinin bir özelliği şöyle görünebilir:\n",
    "\n",
    "| Longitude | Latitude | Cluster |\n",
    "|-----------|----------|---------|\n",
    "| -93.619   | 42.054   | 3       |\n",
    "| -93.619   | 42.053   | 3       |\n",
    "| -93.638   | 42.060   | 1       |\n",
    "| -93.602   | 41.988   | 0       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f63b00",
   "metadata": {
    "id": "d8f63b00",
    "papermill": {
     "duration": 0.006858,
     "end_time": "2021-10-27T20:04:24.266412",
     "exception": false,
     "start_time": "2021-10-27T20:04:24.259554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Bu `Cluster`  özelliğinin kategorik olduğunu hatırlamak önemlidir. Burada, tipik bir kümeleme algoritmasının üreteceği şekilde bir etiket kodlaması (yani bir tamsayı dizisi olarak) ile gösterilmiştir; modelinize bağlı olarak, one-hot kodlama daha uygun olabilir.\n",
    "\n",
    "Küme etiketleri eklemenin motive edici fikri, kümelerin özellikler arasındaki karmaşık ilişkileri daha basit parçalara ayırmasıdır. Modelimiz daha sonra karmaşık bütünü bir kerede öğrenmek zorunda kalmak yerine daha basit parçaları tek tek öğrenebilir. Bu bir \"böl ve yönet\" stratejisidir.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/rraXFed.png\" width=800, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>YearBuilt özelliğinin kümelenmesi, bu doğrusal modelin SalePrice ile ilişkisini öğrenmesine yardımcı olur.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Şekil, kümelemenin basit bir doğrusal modeli nasıl iyileştirebileceğini göstermektedir. `YearBuilt` ve `SalePrice` arasındaki eğri ilişki bu tür bir model için fazla karmaşıktır -- *gereksizdir*. Ancak daha küçük parçalarda ilişki *neredeyse* doğrusaldır ve model kolayca öğrenebilir.\n",
    "\n",
    "# k-Means Kümeleme #\n",
    "\n",
    "Çok sayıda kümeleme algoritması vardır. Öncelikle \"benzerliği\" veya \"yakınlığı\" nasıl ölçtüklerinde ve ne tür özelliklerle çalıştıklarında farklılık gösterirler. Kullanacağımız algoritma, k-means, sezgiseldir ve bir özellik mühendisliği bağlamında uygulanması kolaydır. Uygulamanıza bağlı olarak başka bir algoritma daha uygun olabilir.\n",
    "\n",
    "**K-means**, sıradan düz çizgi mesafesini (başka bir deyişle Öklid mesafesi) kullanarak benzerliği ölçer. Özellik alanı içine **centroids** adı verilen bir dizi nokta yerleştirerek kümeler oluşturur. Veri kümesindeki her nokta, en yakın olduğu merkezin kümesine atanır. \"K-means\"deki \"k\", kaç tane centroid (yani küme) oluşturduğudur. k'yi kendin tanımlarsın.\n",
    "\n",
    "Her bir centroidin bir dizi yayılan daire boyunca noktaları yakaladığını hayal edebilirsiniz. Rakip merkezlerden gelen daire kümeleri üst üste geldiğinde bir çizgi oluştururlar. Sonuç, **Voronoi tessallation (mozaikleme)** olarak adlandırılan şeydir. Mozaikleme, gelecekteki verilerin hangi kümelere atanacağını size gösterir; mozaikleme, esasen k-means'ın eğitim verilerinden öğrendiği şeydir.\n",
    "\n",
    "Yukarıdaki [*Ames*](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) veri kümesindeki kümeleme, bir k-means kümelemesidir. Burada mozaikleme ve ağırlık merkezi ile aynı şekil gösterilmiştir.\n",
    "\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/KSoLd3o.jpg.png\" width=450, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>K-means clustering creates a Voronoi tessallation of the feature space.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "K-means algoritmasının kümeleri nasıl öğrendiğini ve bunun özellik mühendisliği için ne anlama geldiğini gözden geçirelim. scikit-learn uygulamasından üç parametreye odaklanacağız: `n_clusters`, `max_iter`, ve `n_init`.\n",
    "\n",
    "İki adımlı basit bir işlemdir. Algoritma, önceden tanımlanmış sayıda (`n_clusters`) centroids'i rastgele başlatarak başlar. Daha sonra bu iki işlemi yineler:\n",
    "1. noktaları en yakın küme merkezine atayın\n",
    "2. noktalarına olan mesafeyi en aza indirmek için her bir merkezi hareket ettirin.\n",
    "\n",
    "Merkezler artık hareket etmeyene veya maksimum sayıda yineleme geçene kadar (`max_iter`) bu iki adımı yineler.\n",
    "\n",
    "Çoğu zaman, ağırlık merkezlerinin başlangıçtaki rastgele konumu, zayıf bir kümeleme ile sonuçlanır. Bu nedenle algoritma birkaç kez tekrar eder (`n_init`) ve her nokta ile merkezi arasındaki toplam mesafenin en az olduğu kümelemeyi, yani optimal kümelemeyi döndürür.\n",
    "\n",
    "Aşağıdaki animasyon, algoritmayı çalışırken gösterir. Sonucun ilk ağırlık merkezlerine bağımlılığını ve yakınsamaya kadar yinelemenin önemini gösterir.\n",
    "\n",
    "<figure style=\"padding: 1em;\">\n",
    "<img src=\"https://i.imgur.com/tBkCqXJ.gif\" width=550, alt=\"\">\n",
    "<figcaption style=\"textalign: center; font-style: italic\"><center>NYC'deki Airbnb kiralamalarında K-means kümeleme algoritması.\n",
    "</center></figcaption>\n",
    "</figure>\n",
    "\n",
    "Çok sayıda küme için `max_iter`i veya karmaşık bir veri kümesi için `n_init`i artırmanız gerekebilir. Normalde, kendiniz seçmeniz gereken tek parametre `n_clusters` (k) olsa da. Bir dizi özellik için en iyi bölümleme, kullandığınız modele ve ne tahmin etmeye çalıştığınıza bağlıdır, bu nedenle onu herhangi bir hiperparametre gibi ayarlamak en iyisidir (örneğin cross-validation yoluyla).\n",
    "\n",
    "# Örnek - California Housing #\n",
    "\n",
    "Mekansal özellikler olarak, [*California Housing*](https://www.kaggle.com/camnugent/california-housing-prices)'in Enlem (`'Latitude'`) ve Boylam (`'Longitude'`), k-means kümelemesi için doğal adaylar oluşturur. Bu örnekte, Kaliforniya'nın farklı bölgelerinde ekonomik segmentler oluşturmak için bunları `'MedInc'` (ortanca gelir) ile kümeleyeceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93126a9",
   "metadata": {
    "_kg_hide-input": true,
    "id": "a93126a9",
    "papermill": {
     "duration": 1.645541,
     "end_time": "2021-10-27T20:04:25.919124",
     "exception": false,
     "start_time": "2021-10-27T20:04:24.273583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "df = pd.read_csv(DATASET_PATH + \"housing.csv\")\n",
    "X = df.loc[:, [\"MedInc\", \"Latitude\", \"Longitude\"]]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47ee7b",
   "metadata": {
    "id": "6f47ee7b",
    "papermill": {
     "duration": 0.007482,
     "end_time": "2021-10-27T20:04:25.935216",
     "exception": false,
     "start_time": "2021-10-27T20:04:25.927734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "k-means kümelemesi ölçeğe duyarlı olduğundan, aşırı değerlerle verileri yeniden ölçeklendirmek veya normalize etmek iyi bir fikir olabilir. Özelliklerimiz zaten kabaca aynı ölçekte, bu yüzden onları olduğu gibi bırakacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63250679",
   "metadata": {
    "id": "63250679",
    "papermill": {
     "duration": 1.504398,
     "end_time": "2021-10-27T20:04:27.449847",
     "exception": false,
     "start_time": "2021-10-27T20:04:25.945449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create cluster feature\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "X[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "X[\"Cluster\"] = X[\"Cluster\"].astype(\"category\")\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93573246",
   "metadata": {
    "id": "93573246",
    "papermill": {
     "duration": 0.009546,
     "end_time": "2021-10-27T20:04:27.469565",
     "exception": false,
     "start_time": "2021-10-27T20:04:27.460019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Şimdi bunun ne kadar etkili olduğunu görmek için birkaç olay örgüsüne bakalım. İlk olarak, kümelerin coğrafi dağılımını gösteren bir dağılım grafiği. Algoritma, kıyılardaki yüksek gelirli alanlar için ayrı bölümler oluşturmuş gibi görünüyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e721e",
   "metadata": {
    "id": "ff0e721e",
    "papermill": {
     "duration": 2.438799,
     "end_time": "2021-10-27T20:04:29.918383",
     "exception": false,
     "start_time": "2021-10-27T20:04:27.479584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    x=\"Longitude\", y=\"Latitude\", hue=\"Cluster\", data=X, height=6,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4380e680",
   "metadata": {
    "id": "4380e680",
    "papermill": {
     "duration": 0.011953,
     "end_time": "2021-10-27T20:04:29.942826",
     "exception": false,
     "start_time": "2021-10-27T20:04:29.930873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Bu veri kümesindeki hedef `MedHouseVal`dir (medyan ev değeri). Bu kutu grafikleri, hedefin her küme içindeki dağılımını gösterir. Kümeleme bilgilendirici ise, bu dağılımlar çoğunlukla `MedHouseVal` genelinde ayrılmalıdır, ki bu gerçekten gördüğümüz şeydir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9d22f",
   "metadata": {
    "id": "63e9d22f",
    "papermill": {
     "duration": 0.315812,
     "end_time": "2021-10-27T20:04:30.270748",
     "exception": false,
     "start_time": "2021-10-27T20:04:29.954936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X[\"MedHouseVal\"] = df[\"MedHouseVal\"]\n",
    "sns.catplot(x=\"MedHouseVal\", y=\"Cluster\", data=X, kind=\"boxen\", height=6);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Feature Engineering-8-k-means.ipynb",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.457103,
   "end_time": "2021-10-27T20:04:31.022607",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-10-27T20:04:14.565504",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
