{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJCMjaWsOAyC"
   },
   "source": [
    "# Day6 – Support Vector Machines - DEMO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbIFTNSyOAyG"
   },
   "source": [
    "Bu alıştırmada, bir spam sınıflandırıcısı oluşturmak için destek vektör makinelerini (SVM) kullanacağız. \n",
    "\n",
    "Nasıl çalıştıklarını görmek için bazı basit 2B veri kümelerinde SVM'lerle başlayacağız. Ardından, bir dizi ham e-posta üzerinde bazı ön işleme çalışmaları yapacağız ve spam olup olmadıklarını belirlemek için bir SVM kullanarak işlenen e-postalar üzerinde bir sınıflandırıcı oluşturacağız.\n",
    "\n",
    "Yapacağımız ilk şey, basit bir 2 boyutlu veri kümesine bakmak ve değişen C değerleri için (doğrusal/lojistik regresyondaki düzenlileştirme terimine benzer) bir doğrusal SVM'nin veri kümesi üzerinde nasıl çalıştığını görmek. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYf93yN2O-DB"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAzlBmdyO_6e"
   },
   "outputs": [],
   "source": [
    "#!ls \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day6-SupportVectorMachines/notebooks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FY86v_WPKH4"
   },
   "outputs": [],
   "source": [
    "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day6-SupportVectorMachines/notebooks\"\n",
    "ROOT_DIR = \"https://github.com/yapay-ogrenme/casgem-eu-project-training-on-data-mining/blob/main/PART1/Day6-SupportVectorMachines/notebooks\"\n",
    "DATASET_PATH = ROOT_DIR + \"/datasets/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLb1Y4V6Ort-"
   },
   "source": [
    "## Verileri yükleyelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgHoe0apOAyI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.io import loadmat\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FILE_PATH = DATASET_PATH +'ex6data1.mat?raw=true'\n",
    "DATASET_FILE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"{DATASET_FILE_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ex6data1.mat\\?raw\\=true ex6data1.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z65geE7QEJU"
   },
   "outputs": [],
   "source": [
    "raw_data = loadmat('ex6data1.mat')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5oWAFdhOAyK"
   },
   "source": [
    "Bunu, sınıf etiketinin bir sembolle gösterildiği bir dağılım grafiği olarak görselleştireceğiz (+ pozitif için, o negatif için)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JSIe6h8oOAyL"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])\n",
    "data['y'] = raw_data['y']\n",
    "\n",
    "positive = data[data['y'].isin([1])]\n",
    "negative = data[data['y'].isin([0])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(positive['X1'], positive['X2'], s=50, marker='x', label='Positive')\n",
    "ax.scatter(negative['X1'], negative['X2'], s=50, marker='o', label='Negative')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGe4paQXOAyM"
   },
   "source": [
    "Diğerlerinden ayrı duran bir aykırı pozitif örnek olduğuna dikkat edin.\n",
    "\n",
    "Sınıflar hala doğrusal olarak ayrılabilir, ancak çok sıkı bir uyum içindeler.\n",
    "\n",
    "Sınıf sınırını öğrenmek için doğrusal bir destek vektör makinesini eğiteceğiz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeN_KjuyOAyM"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svc = svm.LinearSVC(C=1, loss='hinge', max_iter=1000)\n",
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtDdYVHUOAyN"
   },
   "source": [
    "İlk deney için C=1 kullanacağız ve nasıl performans gösterdiğini göreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MZQuSRwDOAyO"
   },
   "outputs": [],
   "source": [
    "svc.fit(data[['X1', 'X2']], data['y'])\n",
    "svc.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EiWUDqXOAyP"
   },
   "source": [
    "Aykırı değeri yanlış sınıflandırdığı anlaşılıyor. Daha büyük bir C değeriyle ne olduğunu görelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sivAREilOAyP"
   },
   "outputs": [],
   "source": [
    "svc2 = svm.LinearSVC(C=100, loss='hinge', max_iter=1000)\n",
    "svc2.fit(data[['X1', 'X2']], data['y'])\n",
    "svc2.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiZFF60OOAyQ"
   },
   "source": [
    "Bu sefer eğitim verilerinin mükemmel bir sınıflandırmasını elde ettik, ancak C'nin değerini artırarak, artık veriler için doğal olarak uygun olmayan bir karar sınırı oluşturduk. Bunu, noktanın hiper düzlemden uzaklığının bir fonksiyonu olan her sınıf tahmini için güven düzeyine bakarak görselleştirebiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2ji3wKSOAyQ"
   },
   "outputs": [],
   "source": [
    "data['SVM 1 Confidence'] = svc.decision_function(data[['X1', 'X2']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM 1 Confidence'], cmap='seismic')\n",
    "ax.set_title('SVM (C=1) Decision Confidence')\n",
    "\n",
    "#\n",
    "plt.plot(data['X1'], -(svc.coef_[0][0]*data['X1']+svc.intercept_[0])/svc.coef_[0][1], c='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3-OSPzrOAyR"
   },
   "outputs": [],
   "source": [
    "data['SVM 2 Confidence'] = svc2.decision_function(data[['X1', 'X2']])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(data['X1'], data['X2'], s=50, c=data['SVM 2 Confidence'], cmap='seismic')\n",
    "ax.set_title('SVM (C=100) Decision Confidence')\n",
    "#\n",
    "plt.plot(data['X1'], -(svc2.coef_[0][0]*data['X1']+svc2.intercept_[0])/svc2.coef_[0][1], c='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThxbOjjBOAyR"
   },
   "source": [
    "Fark biraz ince ama sınıra yakın noktaların rengine bakın. \n",
    "\n",
    "Şimdi doğrusal bir SVM'den, çekirdekleri kullanarak doğrusal olmayan sınıflandırma yapabilen bir SVM'ye geçeceğiz. \n",
    "\n",
    "Önce bir gauss çekirdeği işlevi uygulamakla görevlendirildik. \n",
    "\n",
    "scikit-learn yerleşik bir gauss çekirdeğine sahip olsa da, şeffaflık için bir tanesini sıfırdan uygulayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aiks9Bq_OAyS"
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(x1, x2, sigma):\n",
    "    return np.exp(-(np.sum((x1 - x2) ** 2) / (2 * (sigma ** 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhv9ZBMhOAyS"
   },
   "outputs": [],
   "source": [
    "x1 = np.array([1.0, 2.0, 1.0])\n",
    "x2 = np.array([0.0, 4.0, -1.0])\n",
    "sigma = 2\n",
    "\n",
    "gaussian_kernel(x1, x2, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMHG0e1ZOAyT"
   },
   "source": [
    "Bu sonuç, alıştırmadan beklenen değerle eşleşiyor. \n",
    "\n",
    "Daha sonra, bu sefer doğrusal olmayan bir karar sınırına sahip başka bir veri kümesini inceleyeceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfTFTuBVOAyT"
   },
   "outputs": [],
   "source": [
    "raw_data = loadmat(DATASET_PATH+'ex6data2.mat')\n",
    "\n",
    "data = pd.DataFrame(raw_data['X'], columns=['X1', 'X2'])\n",
    "data['y'] = raw_data['y']\n",
    "\n",
    "positive = data[data['y'].isin([1])]\n",
    "negative = data[data['y'].isin([0])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(positive['X1'], positive['X2'], s=30, marker='x', label='Positive')\n",
    "ax.scatter(negative['X1'], negative['X2'], s=30, marker='o', label='Negative')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEnLzd99OAyU"
   },
   "source": [
    "Bu veri kümesi için, yerleşik RBF çekirdeğini kullanarak bir destek vektör makine sınıflandırıcısı oluşturacağız ve eğitim verileri üzerindeki doğruluğunu inceleyeceğiz. Karar sınırını görselleştirmek için, bu sefer örneğin negatif bir sınıf etiketine sahip olduğu tahmin edilen olasılığa dayalı olarak noktaları gölgeleyeceğiz. Sonuçtan çoğunu doğru yaptığını göreceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AljaQOHzOAyU"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(C=100, gamma=10, probability=True)\n",
    "svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-C-gPIiOAyV"
   },
   "outputs": [],
   "source": [
    "svc.fit(data[['X1', 'X2']], data['y'])\n",
    "svc.score(data[['X1', 'X2']], data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wb-2zPICOAyV"
   },
   "outputs": [],
   "source": [
    "data['Probability'] = svc.predict_proba(data[['X1', 'X2']])[:,0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(data['X1'], data['X2'], s=30, c=data['Probability'], cmap='Reds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOxOjXbuOAyV"
   },
   "source": [
    "Üçüncü veri kümesi için bize hem eğitim hem de doğrulama setleri verildi ve doğrulama seti performansına dayalı bir SVM modeli için optimal hiper parametreleri bulmakla görevlendirildik. Bunu oldukça kolay bir şekilde yapmak için scikit-learn'in yerleşik Grid_Search'ü kullanabilmemize rağmen, alıştırma yönergelerini izleme ruhuyla sıfırdan basit bir ızgara araması uygulayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QkLhrB5nOAyW"
   },
   "outputs": [],
   "source": [
    "raw_data = loadmat(DATASET_PATH+'ex6data3.mat')\n",
    "\n",
    "X = raw_data['X']\n",
    "Xval = raw_data['Xval']\n",
    "y = raw_data['y'].ravel()\n",
    "yval = raw_data['yval'].ravel()\n",
    "\n",
    "C_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "gamma_values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]\n",
    "\n",
    "best_score = 0\n",
    "best_params = {'C': None, 'gamma': None}\n",
    "\n",
    "for C in C_values:\n",
    "    for gamma in gamma_values:\n",
    "        svc = svm.SVC(C=C, gamma=gamma)\n",
    "        svc.fit(X, y)\n",
    "        score = svc.score(Xval, yval)\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params['C'] = C\n",
    "            best_params['gamma'] = gamma\n",
    "\n",
    "best_score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-90KJkShS0p7"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7lFmHtqTZb6"
   },
   "source": [
    "# SPAM FILTER - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sI1CSOzYOAyW"
   },
   "source": [
    "Şimdi alıştırmanın ikinci kısmına geçeceğiz. \n",
    "\n",
    "Bu bölümde amacımız, bir spam filtresi oluşturmak için SVM'leri kullanmaktır. Alıştırma metninde, verilerimizi bir SVM'nin işlemesi için uygun bir formatta almak için bazı metin ön işlemelerini içeren bir görev vardır. Ancak, görev oldukça önemsizdir (alıştırma için sağlanan bir sözlükten sözcükleri bir kimliğe eşlemek) ve HTML kaldırma, kök çıkarma, normalleştirme vb. gibi ön işleme adımlarının geri kalanı zaten yapılmıştır. Bu ön işleme adımlarını yeniden oluşturmak yerine, önceden işlenmiş trenden bir sınıflandırıcı oluşturmayı içeren makine öğrenimi görevine atlayacağım ve kelime oluşum vektörlerine dönüştürülmüş spam ve istenmeyen e-posta olmayan e-postalardan oluşan veri kümelerini test edeceğim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_dl7OKWOAyX"
   },
   "outputs": [],
   "source": [
    "spam_train = loadmat(DATASET_PATH+'spamTrain.mat')\n",
    "spam_test = loadmat(DATASET_PATH+'spamTest.mat')\n",
    "\n",
    "spam_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjMsihLbOAyX"
   },
   "outputs": [],
   "source": [
    "X = spam_train['X']\n",
    "Xtest = spam_test['Xtest']\n",
    "y = spam_train['y'].ravel()\n",
    "ytest = spam_test['ytest'].ravel()\n",
    "\n",
    "X.shape, y.shape, Xtest.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40J7dk-bOAyX"
   },
   "source": [
    "Her belge, sözlükteki 1.899 kelimeye karşılık gelen 1.899 boyutlu bir vektöre dönüştürülmüştür. Değerler ikili olup, belgede kelimenin varlığını veya yokluğunu gösterir. Bu noktada, eğitim ve değerlendirme, yalnızca sınıflandırıcıyı test etmeye uydurma meselesidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YDTbVxXOOAyX"
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC()\n",
    "svc.fit(X, y)\n",
    "print('Training accuracy = {0}%'.format(np.round(svc.score(X, y) * 100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hSZhBVSLOAyY"
   },
   "outputs": [],
   "source": [
    "print('Test accuracy = {0}%'.format(np.round(svc.score(Xtest, ytest) * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jA1JevPWOAyY"
   },
   "source": [
    "Bu sonuç varsayılan parametrelerledir. Bazı parametre ayarlarını kullanarak muhtemelen biraz daha yükseğe çıkarabiliriz, ancak %95 doğruluk yine de fena değil.\n",
    "\n",
    "Bu, egzersiz 6'yı sonuçlandırıyor! Bir sonraki alıştırmada, K-Means ve temel bileşen analizi ile kümeleme ve görüntü sıkıştırma gerçekleştireceğiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9sw5H5TUc59"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day6_SupportVectorMachines_Demo3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
