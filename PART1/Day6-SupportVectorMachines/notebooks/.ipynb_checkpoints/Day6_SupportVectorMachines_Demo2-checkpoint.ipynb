{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHe_zAMr-oQ9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, load_wine\n",
    "from sklearn.datasets import make_circles, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import statistics\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, plot_roc_curve, plot_precision_recall_curve, roc_curve, auc\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVgrOKrK_0jX"
   },
   "source": [
    "# Görev 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vz0YE7Amz0cG"
   },
   "source": [
    "SVM (Destek Vektör Makinesi) - iki kategoriden birine ait olmanın değerlendirilmesini sağlayan bir sınıflandırma modeli. \n",
    "Doğrusal veriler için idealdir. \n",
    "Bu model, verileri sınıflarına göre bölen bir hiper düzlem arar. \n",
    "Tüm olası düzlemler arasından, en büyük marjı olan seçilir (hiper düzlem ile sınıflardan en yakın noktalar arasındaki mesafe).\n",
    "\n",
    "  ![](https://drive.google.com/uc?id=1ecb_cgEsQgz0MwtmMLq0oAf4gYOyT_28)\n",
    "\n",
    "Veriler doğrusal olarak ayrılabilir ise, model çok iyi çalışır. \n",
    "Ancak, durumun böyle olmadığı durumlarla çok sık karşılaşıyoruz. Hafif doğrusal olmama durumunda, eğitim sırasında sınıflandırmada küçük hatalar yapmamıza izin verebiliriz, böylece verileri hiper düzleme bölebiliriz. Biz sözde kuruyoruz parametre C - sınıflandırma doğruluğu ve marj genişliği arasındaki uzlaşmayı ayarlamaya izin verir.\n",
    "\n",
    "![](https://drive.google.com/uc?id=1PbVm-npunWGtn0R8k0aK95KUTctJfRjl)\n",
    "\n",
    "Peki ya tamamen ayrılamaz veriler? Böyle bir durumda hiper düzlemi etkili bir şekilde bulmak imkansızdır. Daha sonra, verileri daha kolay ayırmak için problemi daha yüksek bir boyuta taşıyabiliriz (daha büyük bir boyuttaki hiperdüzlem). Girdi verilerini daha yüksek boyuttaki noktalara eşleyen bir işlev arıyoruz. Ancak bu çözüm, genellikle büyük hesaplamalarla ilişkilendirilen böyle bir işlevin ve veri işlemenin bulunmasını gerektirir. Bu amaçla, sözde kullanabilirsiniz. çekirdek hilesi. Bu sayede, bir haritalama işlevi aramamıza ve girdi verilerinin boyutunu artırmamıza gerek kalmıyor. Uygun hiperdüzlemi bulmak için eşlenen vektörlerin tam değerlerini bilmemize gerek yoktur. Sadece aralarındaki nokta çarpımlarına ihtiyacımız var. Değerleri bilinmeyen vektörlerin çarpımı nasıl hesaplanır? RBF gibi çekirdek fonksiyonlarını kullanabiliriz.\n",
    "Bu tür işlevler, orijinal verileri (başlangıç ​​boyutu) kullanarak daha yüksek bir boyutta vektörlerin nokta ürünlerini hesaplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PhQjHRF1rM_"
   },
   "outputs": [],
   "source": [
    "#Yardımcı fonksiyonlar\n",
    "def classification(X, Y, X_test, Y_test, kernel, c=1):\n",
    "  classifier = svm.SVC(kernel = kernel, C =c)\n",
    "  \n",
    "  classifier.fit(X,Y)\n",
    "\n",
    "  \n",
    "  x_min = X[:, 0].min() - 5\n",
    "  x_max = X[:, 0].max() + 5\n",
    "  y_min = X[:, 1].min() - 5\n",
    "  y_max = X[:, 1].max() + 5\n",
    "\n",
    "  XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "  decision_function = classifier.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "  decision_function = decision_function.reshape(XX.shape)\n",
    "\n",
    "  \n",
    "  y_predicted = classifier.predict(X_test)\n",
    "  \n",
    "  accuracy = accuracy_score(Y_test, y_predicted)\n",
    "\n",
    "\n",
    "  return XX, YY, decision_function, accuracy\n",
    "\n",
    "def plot_classifications(train_data, train_labels, test_data, test_labels, c, data_type ): \n",
    "  kernels = ['linear','poly','sigmoid' , 'rbf'] \n",
    "  f, axis = plt.subplots(1, len(kernels), figsize=(20, 6),sharey=True)\n",
    "  f.suptitle(data_type, fontsize=16)\n",
    "  for i,kernel in enumerate(kernels):\n",
    "    \n",
    "    XX, YY, decision_function, accuracy = classification(train_data, train_labels, test_data, test_labels, kernel, c)\n",
    "    axis[i].scatter(train_data[:, 0], train_data[:, 1], c=train_labels, s=100,cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "    axis[i].pcolormesh(XX, YY, decision_function < 0, cmap=plt.cm.Pastel1)\n",
    "    axis[i].contour(XX, YY, decision_function, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'], levels=[-1, 0, 1])\n",
    "    axis[i].set_title(\"kernel: \"+kernel)\n",
    "  \n",
    "    print(\"Test verilerine çekirdek SVM sınıflandırıcısını uyguladıktan sonra doğruluk: {}: {:.3f}%\".format(kernel,float(accuracy)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Snxs6ssuDqJ2"
   },
   "source": [
    "## Mükemmel şekilde ayrılabilir veriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vNAcY-xS1rS2"
   },
   "outputs": [],
   "source": [
    "# [2, 10] ve [10, 0]'daki ölçülerle rastgele 50 nokta\n",
    "numPoints = 50\n",
    "XY, labels = make_blobs(n_samples=numPoints, n_features=2, centers = [[2, 10], [10, 0]])\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(XY, \n",
    "                                        labels, train_size=0.75, random_state=0)\n",
    "\n",
    "plt.scatter(train_data[:, 0], train_data[:, 1], c=train_labels,s =100, cmap='RdYlGn', edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1tyl2g3UcxV"
   },
   "outputs": [],
   "source": [
    "plot_classifications(train_data, train_labels,test_data, test_labels, 1, 'Mükemmel ayrılabilir veriler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JvzYFTtJ9sO"
   },
   "source": [
    "SVM sınıflandırıcının çok iyi çalıştığını görebilirsiniz (doğrusal sınıflandırıcı yeterlidir, önizleme için diğer çekirdekler). Ek olarak, doğrusal çekirdek hariç, sınıflandırma grafiklerinin yalnızca daha büyük boyutlu bir hiperdüzlemin projeksiyonları olduğu dikkate alınmalıdır. (dolayısıyla düz çizgiler değildir, orijinal veriler üzerindeki sınırları görselleştirmenize olanak tanır)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63gkKZVfD6Hk"
   },
   "source": [
    "## Daha zayıf ayrılabilir veriler (kötü sınıflandırmalar olabilir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89ihuNT0YpMw"
   },
   "outputs": [],
   "source": [
    "a = np.array([(2,2),(2,8),(2,3),(6,2)])\n",
    "XY_new = np.vstack((train_data, a))\n",
    "labels_new = np.append(train_labels,[1,1,1,0])\n",
    "plt.scatter(XY_new[:, 0], XY_new[:, 1], c=labels_new,s =100, cmap='RdYlGn', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNDMhk4JHeqS"
   },
   "source": [
    "**C parametresinin kullanımı - öğrenme sırasında sınıflandırmanın doğruluğu ile marj genişliği arasında bir uzlaşma - ne kadar yüksek olursa, doğruluk o kadar yüksek = daha dar marj**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIDdpq8EDwjc"
   },
   "outputs": [],
   "source": [
    "plot_classifications(XY_new, labels_new,test_data,test_labels, 1, 'Daha az ayrılabilir veri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2EKXs4OMJfc"
   },
   "source": [
    "### C parametresini değiştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jClp1fzIL7iy"
   },
   "outputs": [],
   "source": [
    "plot_classifications(XY_new, labels_new,test_data, test_labels, 1000, 'Daha az ayrılabilir veri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X4LbgDxMJCSm"
   },
   "source": [
    "C parametresi çok yüksektir (1000), yani öğrenme sırasında sınıflandırmanın doğruluğunu önemseriz. Bu yaklaşım, \"aşırı uyuma(overfitting)\" neden olabilecek küçük marjlara neden olur (model, eğitim verileri için idealdir, ancak mutlaka genel bir çözüm değildir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhLJwzYNMXkp"
   },
   "outputs": [],
   "source": [
    "plot_classifications(XY_new, labels_new, test_data, test_labels, 0.01, 'Daha az ayrılabilir veri')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcBXJgsbLXyA"
   },
   "source": [
    "Bu durumda, C parametresi çok küçüktür ve bu da zayıf sınıflandırma doğruluğuna neden olur. \"Sigmoid\" ve \"rbf\" çekirdekleri için SVM'nin tüm verileri tek bir kategoride sınıflandırdığını görebilirsiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTpStzkkZ1RH"
   },
   "source": [
    "## Ayrılamayan veriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9TA0KAHZ-ym"
   },
   "outputs": [],
   "source": [
    "numPoints = 100\n",
    "not_separable_data, not_separable_labels = make_circles(n_samples=numPoints,\n",
    "  factor=.3, noise=.06)\n",
    "not_separable_data = 10 * not_separable_data\n",
    "not_separable_train_data, not_separable_test_data, not_separable_train_labels, not_separable_test_labels = train_test_split(not_separable_data, \n",
    "                                        not_separable_labels, train_size=0.75, random_state=0)\n",
    "plt.scatter(not_separable_train_data[:, 0], not_separable_train_data[:, 1], c=not_separable_train_labels, s=100, zorder=10, cmap='RdYlGn',\n",
    "                edgecolors='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_PtAzY_H7y4"
   },
   "source": [
    "### Çekirdek hilesi kullanmadan bir çözüm örneği\n",
    "\n",
    "Daha büyük bir boyuta eşlenen bir fonksiyon buluyoruz ve ardından verileri iki sınıfa bölen bir hiperdüzlem oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IvpAmi1IcIPV"
   },
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "  return x**2 + y**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsSMFAA1cMVG"
   },
   "outputs": [],
   "source": [
    "z = f(not_separable_train_data[:, 0], not_separable_train_data[:, 1])\n",
    "z_test = f(not_separable_test_data[:, 0], not_separable_test_data[:, 1])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8)) \n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(not_separable_train_data[:, 0], not_separable_train_data[:, 1], z, c=not_separable_train_labels, zorder=10, cmap='RdYlGn', edgecolors='k')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2hdfE_k0vUG"
   },
   "outputs": [],
   "source": [
    "mapped_data = np.c_[not_separable_train_data, z]\n",
    "mapped_test_data = np.c_[not_separable_test_data, z_test]\n",
    "classifier = svm.SVC(kernel=\"linear\")\n",
    "classifier.fit(mapped_data, not_separable_train_labels)\n",
    "\n",
    "predicted = classifier.predict(mapped_test_data)\n",
    "\n",
    "accuracy = accuracy_score(not_separable_test_labels, predicted)\n",
    "print(\"Test verilerine SVM sınıflandırıcı uygulandıktan sonra doğruluk: %.3f%%\" % (float(accuracy)*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2c4KfkG3dMu"
   },
   "source": [
    "### Çekirdek hilesiyle\n",
    "\n",
    "Verileri daha yüksek boyutlara işleyen bir haritalama işlevi ve hesaplamalar aramaktan kaçınırız"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jkF8wgBHaokI"
   },
   "outputs": [],
   "source": [
    "plot_classifications(not_separable_train_data, not_separable_train_labels, not_separable_test_data, not_separable_test_labels, 1, 'Doğrusal olmayan veriler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VhzWGiOXa8zd"
   },
   "outputs": [],
   "source": [
    "plot_classifications(not_separable_train_data, not_separable_train_labels, not_separable_test_data, not_separable_test_labels, 1000, 'Doğrusal olmayan veriler')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsHgLPuZNlLp"
   },
   "source": [
    "\"rbf\" çekirdeğinin bu tür veriler (halkalar) için mükemmel olduğunu fark edeceksiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9LDHJ5sL6Xd"
   },
   "source": [
    "## Model değerlendirme yöntemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRTQ3k-V2wvv"
   },
   "source": [
    "--------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L6vTF1_VAJTh"
   },
   "outputs": [],
   "source": [
    "#Yardımcı fonksiyonlar\n",
    "def calculate_f1_score(train_data, train_labels, test_data, test_labels, c, kernel):\n",
    "    classifier = svm.SVC(kernel = kernel, C =c)\n",
    "\n",
    "    classifier.fit(train_data, train_labels)\n",
    "    predicted_labels = classifier.predict(test_data)\n",
    "    return f1_score(test_labels, predicted_labels)\n",
    "\n",
    "def plot_roc(train_data, train_labels, test_data, test_labels, c, kernel):\n",
    "    classifier = svm.SVC(kernel = kernel, C =c)\n",
    "\n",
    "    classifier.fit(train_data, train_labels)\n",
    "    plot_roc_curve(classifier, test_data, test_labels)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "\n",
    "def plot_PR(train_data, train_labels, test_data, test_labels, c, kernel):\n",
    "    classifier = svm.SVC(kernel = kernel, C =c)\n",
    "\n",
    "    classifier.fit(train_data, train_labels)\n",
    "\n",
    "    plot_precision_recall_curve(classifier, test_data, test_labels)\n",
    "\n",
    "    plt.title('Precision-Recall')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "  \n",
    "def plot_classification(train_data, train_labels, test_data, test_labels, c, data_type, kernel):\n",
    "    XX, YY, decision_function, accuracy = classification(train_data, train_labels, test_data, test_labels, kernel, c)\n",
    "\n",
    "    f, axis = plt.subplots(1, 2, figsize=(20, 6),sharey=True)\n",
    "    f.suptitle(data_type + '\\nkernel: ' + kernel, fontsize=16)\n",
    "\n",
    "    axis[0].scatter(train_data[:, 0], train_data[:, 1], c=train_labels, s=80,cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "    axis[0].pcolormesh(XX, YY, decision_function < 0, cmap=plt.cm.Pastel1)\n",
    "    axis[0].contour(XX, YY, decision_function, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'], levels=[-1, 0, 1])\n",
    "    axis[0].set_title('dane treningowe')\n",
    "\n",
    "    axis[1].scatter(test_data[:, 0], test_data[:, 1], c=test_labels, s=80,cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "    axis[1].pcolormesh(XX, YY, decision_function < 0, cmap=plt.cm.Pastel1)\n",
    "    axis[1].contour(XX, YY, decision_function, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'], levels=[-1, 0, 1])\n",
    "    axis[1].set_title('dane testowe')\n",
    "\n",
    "    print(\"SVM sınıflandırıcısını test verilerine uyguladıktan sonra doğruluk: %.3f%%\" % (float(accuracy)*100.0))\n",
    "\n",
    "def plot_contingency_table(train_data, train_labels, test_data, test_labels, c, kernel):\n",
    "    classifier = svm.SVC(kernel = kernel, C =c)\n",
    "\n",
    "    classifier.fit(train_data, train_labels)\n",
    "\n",
    "    plot_confusion_matrix(classifier, test_data, test_labels, display_labels=['red', 'green'], cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5fFtu8tJVjEv"
   },
   "source": [
    "### Çapraz doğrulama\n",
    "\n",
    "Veri setini bir eğitim seti ve bir test seti (basit doğrulama) olarak ayırdığımız, ardından modeli eğitim seti kullanarak eğitip test seti ile test ettiğimiz istatistiksel bir yöntem.\n",
    "\n",
    "Ayrıca, veri kümesini muhtemelen eşit K alt kümelerine böldüğümüz, ardından her birini tam olarak bir kez bir test kümesi olarak ve kalan K-1'i bir eğitim kümesi olarak kullandığımız ve böylece K simülasyonları gerçekleştirdiğimiz bir K-katlama doğrulaması vardır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRdAy7g-VjHn"
   },
   "source": [
    "### Receiver Operating Characteristic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CW40ZEEBI2XH"
   },
   "source": [
    "ROC eğrisinin nereden geldiğini görelim:\n",
    "- bir veri seti alıyoruz, üzerinde doğrusal bir SVC sınıflandırması yapıyoruz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzQ53K73IJjm"
   },
   "outputs": [],
   "source": [
    "# test verileri - (2, 10) ve (10, 0) etrafında toplanan puan grupları\n",
    "train_data, train_labels = make_blobs(n_samples=150, n_features=2, centers = [[2, 10], [4, 4], [10, 2]])\n",
    "train_labels = [1 if x==1 else 0 for x in train_labels]\n",
    "\n",
    "# hafif gürültü ekliyoruz\n",
    "train_data = np.vstack((train_data, np.array([(2,10),(1,11),(3,12),(10, -2), (10, 2)])))\n",
    "train_labels = np.append(train_labels,[1,1,1,0,1])\n",
    "\n",
    "# öncekilere benzer şekilde oluşturulan test verileri\n",
    "test_data, test_labels = make_blobs(n_samples=45, n_features=2, centers = [[2, 10], [4, 4], [10, 2]])\n",
    "test_labels = [1 if x==1 else 0 for x in test_labels]\n",
    "test_data = np.vstack((test_data, np.array([(2,10),(1,11),(3,12),(10, -2), (10, 2)])))\n",
    "test_labels = np.append(test_labels,[1,1,1,0,1])\n",
    "\n",
    "f, axis = plt.subplots(nrows=1, ncols=2, figsize=(18, 6))\n",
    "axis[0].scatter(train_data[:, 0], train_data[:, 1], c=train_labels, s = 50,  cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "axis[0].set_title(\"Eğitim verileri\")\n",
    "axis[1].scatter(test_data[:, 0], test_data[:, 1], c=test_labels, s = 50,cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "axis[1].set_title(\"Test verileri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7_sNRg7LOO0"
   },
   "outputs": [],
   "source": [
    "plot_classification(train_data, train_labels, test_data, test_labels, 1, 'Test verileri', 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdb1JpRpT2rW"
   },
   "source": [
    "- Hata matrisini çiziyoruz (*karışıklık matrisi / beklenmedik durum tablosu ), Dört alandan oluşuyor:\n",
    "   - *TP*: gerçek pozitifler, punky kırmızı olarak işaretlendi (Gerçek etiketler) ve böylece sınıflandırıldı (Öngörülen etiketler),\n",
    "   - *FP*: yanlış pozitifler, kırmızı olarak sınıflandırılan yeşil noktalar,\n",
    "   - *FN*: yanlış negatifler, yeşil olarak sınıflandırılan kırmızı noktalar,\n",
    "   - *TN*: gerçek negatifler, yeşil olarak sınıflandırılan yeşil noktalar,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4FIeIB3u-pm"
   },
   "source": [
    "![confusion matrix ](https://drive.google.com/uc?id=1b04cjONAeZ479CBQjMcxuOcoJOhLRLHr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ew7CUNXRlyK"
   },
   "outputs": [],
   "source": [
    "plot_contingency_table(train_data, train_labels, test_data, test_labels, 1, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTeFQsADbyVQ"
   },
   "source": [
    "Buna dayanarak, aşağıdaki değerleri hesaplayabiliriz:\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "$$True \\hspace{0.2cm} Positive \\hspace{0.2cm} Rate = Sensitivity = \\frac{True Positives}{True Positives + False Negatives}$$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "$$False \\hspace{0.2cm} Positive \\hspace{0.2cm} Rate = 1 - Specificity = \\frac{False Positives}{False Positives + True Negatives}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3WRBKSbiqcS"
   },
   "source": [
    "*sınıflandırma* işlevinde, verilen noktaların her biri için bir değer döndüren *karar_ işlevi* işlevini kullanırız. Belirli bir eşiğin üzerindeki değerlerin, belirli bir noktanın bir sınıfa ve altının diğerine ait olduğu anlamına geldiğini varsayıyoruz (varsayılan olarak bu eşik 0'dır).\n",
    "\n",
    "Bu eşik değiştirilebilir, bu da modelin noktaları bir veya diğer sınıfa (bizim durumumuzda yeşil veya kırmızı olarak) ait olarak işaretleme eğiliminin artmasına neden olur. Modelin trendi değiştikçe hata matrisindeki değerler de değişmektedir.\n",
    "\n",
    "**ROC** eğrisi, belirli bir eşik için *True Positive Rate* (ROC eğrisinin dikey ekseni) ve False Positive Rate (ROC eğrisinin yatay ekseni) değeri hesaplanarak oluşturulur.\n",
    "\n",
    "Eğrinin eksenin sol üst köşesine mümkün olduğunca yakın olması için True Positive Rate = 1 ve False Positive Rate = 0 olması en iyisidir.\n",
    "\n",
    "İhtiyaçlarımıza en uygun eşiği seçebiliriz - yüksek Gerçek Pozitif Oranı, düşük Yanlış Pozitif Oranı veya optimal bir modeli vardır, yani eksen üzerindeki noktaya (0,1) en yakın sonucu verir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHbGFcg4kIzD"
   },
   "source": [
    "- bizim durumumuz ve lineer çekirdek için ROC eğrisini çiziyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4-yU4aC2fb07"
   },
   "outputs": [],
   "source": [
    "plot_roc(train_data, train_labels, test_data, test_labels, 1, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvJJLKEFkgmm"
   },
   "source": [
    "### Precision-Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOy3ALRskpxY"
   },
   "source": [
    "Eğriyi oluşturma prensibi ROC eğrisi ile aynı kalır, sadece eksenler değişir, burada elimizde:\n",
    "\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "$$Precision = \\frac{True Positives}{True Positives + False Positives}$$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "$$Recall = \\frac{True Positives}{True Positives + False Negatives}$$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Örneğimizde, eğri şöyle görünecektir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fir-F6u_lu6_"
   },
   "outputs": [],
   "source": [
    "plot_PR(train_data, train_labels, test_data, test_labels, 1, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu4e8cdklBlW"
   },
   "source": [
    "Na tej krzywej idealnym punktem jest punkt (1, 1), ponieważ oznacza on, że *False Positives* = *False Negatives* = 0. \n",
    "\n",
    "Najlepiej jest więc wybierać próg, który sprawi, że zarówno *precision* jak i *recall* będą możliwie blisko 1, z przewagą jednego lub drugiego, w zależności od tego czy wolimy mieć z większym prawdopodobieństwem wyniki fałszywe były klasyfikowane jako wyniki z pierwszej czy drugiej klasy.\n",
    "\n",
    "\n",
    "\n",
    "Bu eğride ideal nokta (1, 1)'dir çünkü *False Positives* = *False Negatives* = 0 anlamına gelir.\n",
    "\n",
    "Bu nedenle, daha olası yanlış sonuçlara sahip olmayı tercih edip etmememize bağlı olarak, hem *kesinliği (precision)* hem de *duyarlılık (recall)* mümkün olduğunca 1'e yakınlaştıracak bir eşik seçmek en iyisidir. birinci veya ikinci sınıfın sonuçları olarak sınıflandırılır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Jv_zB5llBl2"
   },
   "source": [
    "### ROC ve Recision-Recall Karşılaştırması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJaIt1TdlGcj"
   },
   "source": [
    "Bu eğrilerin her ikisi de bizim için hangi eşiğin uygun olacağına karar vermemize yardımcı olabilir, ancak prensipte:\n",
    "\n",
    "- ROC eğrisi oldukça basittir ve her iki sınıfa ait oldukça eşit olarak dağıtılmış verilere sahip olduğumuzda kullanılabilir,\n",
    "- bir sınıftan gelen veriler baskın olduğunda, PR eğrisini kullanmalıyız,\n",
    "\n",
    "Bunun nedeni, eşit olmayan verilerle ROC eğrisinin bize modelin performansının iyimser bir resmini sunabilmesidir [bknz. örnek](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/), PR eğrisi ise modelin gerçek davranışını daha iyi yansıtır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9LIy35rtVHo"
   },
   "source": [
    "Eşik değiştirilirken eğrilerin nasıl çizileceğini gösteren örnek:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1400/1*Dmsoecp2PPYRIXJk_ESBdw.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcMdhjLvlAAv"
   },
   "source": [
    "### Eğrinin Altındaki Alan\n",
    "\n",
    "Çizimin altındaki alan, belirli bir problem için kullanılan farklı modelleri karşılaştırırken faydalı olabilir. Genel olarak, AUC ne kadar büyük olursa, model o kadar iyi olur.\n",
    "\n",
    "Örneğin, verilerimiz için kullanılan iki çekirdeği karşılaştıralım:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6G9_Qy_knSV5"
   },
   "outputs": [],
   "source": [
    "plot_roc(train_data, train_labels, test_data, test_labels, 1, 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECZcWg2snT_d"
   },
   "outputs": [],
   "source": [
    "plot_roc(train_data, train_labels, test_data, test_labels, 1, 'rbf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ib-7kJDbn4em"
   },
   "source": [
    "Açıklamada görülebileceği gibi, her iki çekirdeğin AUC'si ve grafiğin kendisi farklıdır. * rbf * çekirdeği daha iyisini yapmalıdır, çünkü bu veri kurulumu ile onu iyi ayıran düz bir çizgi çizmek mümkün değildir ve aynı zamanda yanlış sınıflandırılan miktarı azaltacak yeşil noktaların etrafına bölünmüş bir çizgi çizebilirsiniz. veri."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_WEi1u5wlKMV"
   },
   "source": [
    "### Doğruluk (Accurancy)\n",
    "\n",
    "Doğruluk, bir sınıflandırmanın kalitesini değerlendirmek için bir ölçüdür. Şu formülden hesaplanır:\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "$$Accurancy = \\frac{True Positive + True Negative}{True Positive + True Negative + False Positive + False Negative}$$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Tüm durumlara doğru bir şekilde sınıflandırılan vakaların bir ölçüsüdür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKiPtfiFifrY"
   },
   "outputs": [],
   "source": [
    "_, _, _, accuracy = classification(train_data, train_labels, test_data, test_labels, 'linear', 1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKrK4RoJv1T9"
   },
   "source": [
    "### F1\n",
    "\n",
    "F1 skoru, Precision (Kesinlik) ve Precision(Duyarlılık)'in harmonik ortalaması olarak hesaplanır:\n",
    "\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "$$F1 = 2 * \\frac{Precision * Recall}{Precision + Recall}$$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "Her iki önlem de hata matrisinin dört alanını da hesaba katar ve modelin kalitesini belirlemeye izin verir. Aradaki fark, F1'in **False Positive** ve **False Negative** arasındaki farka daha duyarlı olmasıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBs6wwcBiFGI"
   },
   "outputs": [],
   "source": [
    "calculate_f1_score(train_data, train_labels, test_data, test_labels, 1, 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9APKovz8FuaJ"
   },
   "source": [
    "# Görev 2\n",
    "\n",
    "SVM sınıflandırıcısının farklı çekirdekler için nasıl çalıştığını gösterin. Çapraz doğrulama (Cross-validate). \n",
    "\n",
    "ROC ve PR eğrilerinin yanı sıra F-1 skoru ve bunların altındaki alanları karşılaştırın."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CDh7UX2eFw5x"
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qsBZzT_4Hdkc"
   },
   "outputs": [],
   "source": [
    "df_cancer = pd.DataFrame(np.c_[cancer['data'], cancer['target']], columns = np.append(cancer['feature_names'], ['target']))\n",
    "\n",
    "df_cancer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0c9h4EBHrxN"
   },
   "outputs": [],
   "source": [
    "print(\"Öznitelik isimleri:\",df_cancer.columns)\n",
    "print(\"(Örnek sayısı, Öznitelik sayısı):\",df_cancer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_fodm01-IEg1"
   },
   "outputs": [],
   "source": [
    "# VERİ HAZIRLAMA\n",
    "X = df_cancer.drop(['target'], axis = 1)\n",
    "y = df_cancer['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#normalleştirme\n",
    "X_train_min = X_test.min()\n",
    "X_train_range = (X_train - X_train_min).max()\n",
    "X_train_scaled = (X_train - X_train_min)/X_train_range\n",
    "\n",
    "X_test_min = X_test.min()\n",
    "X_test_range = (X_test - X_test_min).max()\n",
    "X_test_scaled = (X_test - X_test_min)/X_test_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iYn_lNa2oXx"
   },
   "outputs": [],
   "source": [
    "def classification(train_data, train_labels, test_data, test_labels, c, kernel):\n",
    "    classifier = svm.SVC(kernel = kernel, C =c)\n",
    "  \n",
    "    classifier.fit(train_data,train_labels)\n",
    "    predicted_labels = classifier.predict(test_data)\n",
    "    accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "    \n",
    "    return (classifier, predicted_labels, accuracy, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpW30EdIMxpO"
   },
   "outputs": [],
   "source": [
    "kernels = ['linear','poly','sigmoid' , 'rbf'] \n",
    "\n",
    "classification_results = []\n",
    "for kernel in kernels:\n",
    "   classification_results.append(classification(X_train_scaled, y_train, X_test_scaled, y_test, 1, kernel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzdd1rTh4JEQ"
   },
   "outputs": [],
   "source": [
    "#plotting confusion matrix\n",
    "display_labels = ['cancer', 'no cancer']\n",
    "f, axis = plt.subplots(1, len(classification_results), figsize=(16, 4),sharey=True)\n",
    "\n",
    "for i, result in enumerate(classification_results):\n",
    "  axis[i].set_title(\"Kernel: {}\".format(result[3]))\n",
    "  plot_confusion_matrix(result[0], X_test_scaled, y_test, display_labels=display_labels, cmap=plt.cm.Blues, ax = axis[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8euasQoe0D0V"
   },
   "outputs": [],
   "source": [
    "def plot_classification_quality(classification_result, test_data, test_labels):\n",
    "  f, axis = plt.subplots(1, 2, figsize=(10, 4),sharey=True)\n",
    "  f.tight_layout(pad=4.0)\n",
    "  plot_roc_curve(classification_result[0], test_data, test_labels, ax = axis[0])\n",
    "\n",
    "  axis[0].set_xlim([-0.05, 1.05])\n",
    "  axis[0].set_ylim([-0.05, 1.05])\n",
    "  axis[0].plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
    "  axis[1].set_title(\" eğri: {}\".format( \"Precision-Recall\"))\n",
    "  \n",
    "\n",
    "  plot_precision_recall_curve(classification_result[0], test_data, test_labels, ax = axis[1])\n",
    "\n",
    "\n",
    "  axis[1].set_xlim([-0.05, 1.05])\n",
    "  axis[1].set_ylim([-0.05, 1.05])\n",
    "      \n",
    "  \n",
    "  print(\"Sınıflandırıcıyı kullandıktan sonra doğruluk: %.3f%%\" % (float(classification_result[2])*100.0))\n",
    "  print(\"F1 skoru: {}\".format(f1_score(test_labels, classification_result[1])))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSNb408YIej_"
   },
   "source": [
    "## Kalite kontrolü\n",
    "\n",
    "Bir sınıfın baskın olduğu ve bu daha küçük sınıfın öğelerini tespit etmek istediğimiz veriler için, doğruluk yüzdesinden ziyade diğer kalite sınıflandırıcılarını kullanmak daha iyidir. Örneğin, nadiren yanlış olan bir kanser tespit modelini (örneğimizde olduğu gibi) alın. Yüksek doğruluk yüzdesine rağmen, modelimiz birinin yaşamının bağlı olduğu böylesine önemli bir noktada yanlıştır. <br>\n",
    "\n",
    "Modelin kalitesini daha iyi kontrol etmeye yardımcı olacak sınıflandırıcılar şunlar olabilir:\n",
    "- ROC eğrisi\n",
    "- Hassas-Geri Çağırma eğrisi\n",
    "- F1 Skoru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3qFK_EBajzxI"
   },
   "outputs": [],
   "source": [
    "for i, result in enumerate(classification_results):\n",
    "  print(\"Kernel: \", result[3])\n",
    "  plot_classification_quality(result, X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xjOliVCqLll"
   },
   "source": [
    "# Görev 3\n",
    "\n",
    "PCA yöntemini kullandıktan sonra görev 2'deki küme için sınıflandırma sonuçları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Is8cf28rtPx3"
   },
   "outputs": [],
   "source": [
    "def plot_results_with_pca(test_data, test_labels, predicted_labels): \n",
    "  \n",
    "  #VERİLERİN HAZIRLANMASI\n",
    "  scaler = StandardScaler()\n",
    "  scaled_test_data = scaler.fit_transform(test_data)\n",
    "\n",
    "  pca = PCA(n_components=2)\n",
    "  pca_data = pca.fit_transform(scaled_test_data) \n",
    "\n",
    "  f, axis = plt.subplots(1, 2, figsize=(10, 4),sharey=True)\n",
    "  f.tight_layout(pad=4.0)\n",
    "\n",
    "  #etiket değerlerinin dizilerin görev 4 için eşleme\n",
    "  mapped_prediction = map(lambda x: int(x),predicted_labels)\n",
    "  mapped_original = map(lambda x: int(x),test_labels)\n",
    "\n",
    "  axis[0].scatter(pca_data[:, 0], pca_data[:, 1], c=list(mapped_original), s=100,cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "  axis[0].set_title(\"Gerçek sınıflandırmalar\")\n",
    "  axis[1].scatter(pca_data[:, 0], pca_data[:, 1], c=list(mapped_prediction), s=100,cmap='RdYlGn', zorder=10, edgecolors='k')\n",
    "  axis[1].set_title(\"Öngörülen sınıflandırmalar\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4cE0Kdtt--t"
   },
   "outputs": [],
   "source": [
    "for i, result in enumerate(classification_results):\n",
    "  print(\"Kernel: \", result[3])\n",
    "  plot_results_with_pca(X_test,y_test, result[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day6_SupportVectorMachines_Demo2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
