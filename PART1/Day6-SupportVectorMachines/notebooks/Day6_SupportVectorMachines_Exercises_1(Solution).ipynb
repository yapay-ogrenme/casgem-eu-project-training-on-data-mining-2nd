{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B54rvceJhAO"
      },
      "source": [
        "<a class=\"anchor\" id=\"0\"></a>\n",
        "# **Python ile Destek Vektör Makineleri Sınıflandırıcı Eğitimi** \n",
        "\n",
        "Destek Vektör Makineleri (kısaca SVM'ler), sınıflandırma ve regresyon amacıyla kullanılan denetimli makine öğrenme algoritmalarıdır. \n",
        "Bu notebookta, bir Pulsar yıldızını sınıflandırmak için bir Destek Vektör Makineleri sınıflandırıcısı oluşturacağız. \n",
        "\n",
        "Bu proje için **Bir Pulsar Yıldızını Tahmin Etme (Predicting a Pulsar Star)** veri setini kullanalım.\n",
        "\n",
        "Öyleyse başlayalım."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztmFyoOgJhAp"
      },
      "source": [
        "# **1. Destek Vektör Makinelerine Giriş** <a class=\"anchor\" id=\"1\"></a>\n",
        "\n",
        "**Support Vector Machines** (kısaca SVM'ler), sınıflandırma ve regresyon amacıyla kullanılan makine öğrenme algoritmalarıdır. SVM'ler, sınıflandırma, regresyon ve aykırı değer tespiti amaçları için güçlü makine öğrenimi algoritmalarından biridir. Bir SVM sınıflandırıcı, verilen kategorilerden birine yeni veri noktaları atayan bir model oluşturur. Bu nedenle, olasılıksal olmayan bir ikili doğrusal sınıflandırıcı olarak görülebilir.\n",
        "\n",
        "SVM'ler doğrusal sınıflandırma amaçları için kullanılabilir. Doğrusal sınıflandırma gerçekleştirmeye ek olarak, SVM'ler **çekirdek hilesi (kernel trick)** kullanarak doğrusal olmayan bir sınıflandırmayı verimli bir şekilde gerçekleştirebilir. Girdileri örtük olarak yüksek boyutlu özellik uzaylarına eşlememizi sağlar.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2Rt9YytJhAu"
      },
      "source": [
        "# 2. Destek Vektör Makinesi Terminolojisi\n",
        "\n",
        "\n",
        "### Hiperdüzlem (Hyperplane)\n",
        "\n",
        "Hiper düzlem, farklı sınıf etiketlerine sahip veri noktaları arasında ayrım yapan bir karar sınırıdır. SVM sınıflandırıcısı, **maksimum marj miktarına sahip bir hiper düzlem kullanarak** veri noktalarını ayırır.\n",
        "\n",
        "Bu hiperdüzlem, `maximum margin hyperplane ('maksimum marjlı hiperdüzlem)'` olarak bilinir ve tanımladığı doğrusal sınıflandırıcı ise `maximum margin classifier (maksimum marjlı sınıflandırıcı)` olarak bilinir.\n",
        "\n",
        "\n",
        "### Destek Vektörler (Support Vectors)\n",
        "\n",
        "Destek vektörleri, hiper düzleme en yakın olan örnek veri noktalarıdır. Bu veri noktaları, marjları hesaplayarak ayırma çizgisini veya hiper düzlemi daha iyi tanımlayacaktır.\n",
        "\n",
        "\n",
        "### Marj (Margin)\n",
        "\n",
        "Marj (kenar boşluğu-margin), en yakın veri noktalarındaki iki çizgi arasındaki ayrım boşluğudur. Vektörleri veya en yakın veri noktalarını desteklemek için çizgiden dikey mesafe olarak hesaplanır. SVM'lerde, maksimum marj elde etmek için bu ayrım boşluğunu maksimize etmeye çalışıyoruz.\n",
        "\n",
        "Aşağıdaki diyagram bu kavramları görsel olarak göstermektedir.\n",
        "\n",
        "### SVM'de Marj \n",
        "\n",
        "![Margin in SVM](https://static.wixstatic.com/media/8f929f_7ecacdcf69d2450087cb4a898ef90837~mv2.png)\n",
        "\n",
        "SVM'lerde ana hedefimiz, verilen veri kümesindeki destek vektörleri arasında mümkün olan maksimum marjı olan bir hiperdüzlem seçmektir. SVM, aşağıdaki 2 adımlı süreçte maksimum marj hiper düzlemini arar –\n",
        "\n",
        "1.\tSınıfları mümkün olan en iyi şekilde ayıran hiper düzlemler oluşturun. Verileri sınıflandırabilecek birçok hiper düzlem vardır. İki sınıf arasındaki en büyük ayrımı veya marjı temsil eden en iyi hiperdüzlemi aramalıyız.\n",
        "\n",
        "2.\tBu nedenle, hiperdüzlemi, ondan her iki taraftaki destek vektörlerine olan uzaklığı maksimize edecek şekilde seçiyoruz.Böyle bir hiperdüzlem varsa, **maksimum marjlı hiperdüzlem (maximum margin hyperplane)** olarak bilinir ve tanımladığı lineer sınıflandırıcı, **maksimum marj sınıflandırıcı (maximum margin classifier)** olarak bilinir.\n",
        "\n",
        "Aşağıdaki şema, **maksimum marj(maximum margin)** ve **maksimum marj hiperdüzlem (maximum margin hyperplane)** kavramını net bir şekilde göstermektedir.\n",
        "\n",
        "\n",
        "### Maksimum marj hiperdüzlem (maximum margin hyperplane)\n",
        "\n",
        "![Maximum margin hyperplane](https://static.packt-cdn.com/products/9781783555130/graphics/3547_03_07.jpg)\n",
        "\n",
        "\n",
        "\n",
        "### Dağınık veri kümeleriyle ilgili sorun\n",
        "\n",
        "Bazen, örnek veri noktaları o kadar dağınıktır ki, onları doğrusal bir hiperdüzlem kullanarak ayırmak mümkün değildir.\n",
        "Böyle bir durumda, SVM'ler, aşağıdaki şemada gösterildiği gibi giriş alanını daha yüksek boyutlu bir alana dönüştürmek için bir \"çekirdek hilesi (kernel trick)\" kullanır. 2 boyutlu girdi alanını 3 boyutlu girdi alanına dönüştürmek için bir eşleme işlevi kullanır. Artık, doğrusal ayırma kullanarak veri noktalarını kolayca ayırabiliriz.\n",
        "\n",
        "### Çekirdek hilesi (Kernel Trick) - girdi uzayının daha yüksek boyutlu uzaya dönüştürülmesi\n",
        "\n",
        "![Kernel trick](http://www.aionlinecourse.com/uploads/tutorials/2019/07/11_21_kernel_svm_3.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL7juiHzJhAy"
      },
      "source": [
        "# 3. Çekirdek hilesi (Kernel Trick)\n",
        "\n",
        "\n",
        "Pratikte, SVM algoritması bir \"çekirdek (kernel)\" kullanılarak uygulanır. \"Çekirdek hilesi(Kernel Trick)\" adı verilen bir teknik kullanır. Basit bir deyişle, bir \"çekirdek (kernel)\", verilerin ayrışılbileceği daha yüksek bir boyuta eşleyen bir işlevdir. Çekirdek, düşük boyutlu bir girdi veri alanını daha yüksek boyutlu bir alana dönüştürür. **Böylece, lineer olmayan ayrılabilir problemleri, daha fazla boyut ekleyerek lineer ayrılabilir problemlere dönüştürür**. Böylece, çekirdek hilesi daha doğru bir sınıflandırıcı oluşturmamıza yardımcı olur. Bu nedenle, doğrusal olmayan ayırma problemlerinde yararlıdır.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsDWx3CKJhAz"
      },
      "source": [
        "Bir çekirdek fonksiyonunu aşağıdaki gibi tanımlayabiliriz:\n",
        "\n",
        "\n",
        "### Çekirdek Fonksiyonu\n",
        "\n",
        "![Kernel function](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTodZptqcRor0LGo8Qn7_kJB9n9BACMt6jgIPZ4C3g_rgh_uSRZLQ&s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJrSybBUJhA0"
      },
      "source": [
        "SVM'ler için kullanılan 4 popüler çekirdek vardır - `Linear kernel`,`Polynomial kernel`,`Radial Basis Function (RBF) kernel` (Gauss çekirdeği olarak da adlandırılır) ve `Sigmoid kernel`. Bunlar aşağıda açıklanmıştır -\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2oBw2_kJhA1"
      },
      "source": [
        "## **3.1 Lineer çekirdek (Linear kernel)**\n",
        "\n",
        "Doğrusal çekirdekte, çekirdek işlevi aşağıdaki gibi doğrusal bir işlev biçimini alır:\n",
        "\n",
        "**doğrusal çekirdek (linear kernel) : K(xi , xj ) = xiT xj**\n",
        "\n",
        "Doğrusal çekirdek, veriler doğrusal olarak ayrılabilir olduğunda kullanılır. Bu, verilerin tek bir satır kullanılarak ayrılabileceği anlamına gelir. En sık kullanılan çekirdeklerden biridir. **Çoğunlukla bir veri kümesinde çok sayıda özellik olduğunda kullanılır.** Doğrusal çekirdek genellikle metin sınıflandırma amacıyla kullanılır.\n",
        "\n",
        "**Doğrusal bir çekirdekle eğitim genellikle daha hızlıdır, çünkü yalnızca C düzenlileştirme parametresini optimize etmemiz gerekir.** Diğer çekirdeklerle eğitim yaparken, γ parametresini de optimize etmemiz gerekir. Bu nedenle, bir ızgara araması (grid search) yapmak genellikle daha fazla zaman alacaktır.\n",
        "\n",
        "Doğrusal çekirdek aşağıdaki şekil ile görselleştirilebilir.\n",
        "\n",
        "### Linear Kernel\n",
        "\n",
        "![Linear Kernel](https://scikit-learn.org/stable/_images/sphx_glr_plot_svm_kernels_thumb.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6syp4j8JhA3"
      },
      "source": [
        "## **3.2 Polinom çekirdeği (Polynomial Kernel)**\n",
        "\n",
        "Polinom çekirdeği, bir öznitelik uzayındaki vektörlerin (eğitim örnekleri) orijinal değişkenlerin polinomları üzerindeki benzerliğini temsil eder. Polinom çekirdeği, benzerliklerini belirlemek için yalnızca girdi örneklerinin verilen özelliklerine değil, aynı zamanda girdi örneklerinin kombinasyonlarına da bakar.\n",
        "\n",
        "d.-derece polinomlar için polinom çekirdeği aşağıdaki gibi tanımlanır:\n",
        "\n",
        "**Polynomial kernel : K(xi , xj ) = (γxiT xj + r)d , γ > 0**\n",
        "\n",
        "Polinom çekirdeği, Doğal Dil İşleme'de çok popülerdir. En yaygın derece d = 2'dir (quadratic), çünkü daha büyük dereceler NLP problemlerine fazla uyma (overfit) eğilimindedir. Aşağıdaki şema ile görselleştirilebilir.\n",
        "\n",
        "\n",
        "### Polinom çekirdeği (Polynomial Kernel)\n",
        "\n",
        "![Polynomial Kernel](https://www.researchgate.net/profile/Cheng_Soon_Ong/publication/23442384/figure/fig12/AS:341444054274063@1458418014823/The-effect-of-the-degree-of-a-polynomial-kernel-The-polynomial-kernel-of-degree-1-leads.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UP0-BNALJhA5"
      },
      "source": [
        "## **3.3 Radyal Temelli Fonksiyon Çekirdeği (Radial Basis Function Kernel)**\n",
        "\n",
        "Radyal tabanlı fonksiyon çekirdeği, genel amaçlı bir çekirdektir. Veriler hakkında önceden bilgimiz olmadığında kullanılır. İki örnek x ve y üzerindeki RBF çekirdeği aşağıdaki denklemle tanımlanır:\n",
        "\n",
        "\n",
        "### Radyal Temelli Fonksiyon Çekirdeği (Radial Basis Function Kernel)\n",
        "\n",
        "![RBK Kernel](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6yZru5HJhA6"
      },
      "source": [
        "Aşağıdaki şema, rbf çekirdeği ile SVM sınıflandırmasını göstermektedir.\n",
        "\n",
        "### rbf çekirdekli SVM Sınıflandırması\n",
        "\n",
        "![SVM Classification with rbf kernel](https://www.researchgate.net/profile/Periklis_Gogas/publication/286180566/figure/fig5/AS:304327777374210@1449568804246/An-example-of-an-SVM-classification-using-the-RBF-kernel-The-two-classes-are-separated.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziRDoFuJJhA7"
      },
      "source": [
        "## **3.4 Sigmoid çekirdek**\n",
        "\n",
        "Sigmoid çekirdeğin kökeni sinir ağlarındadır. Sinir ağları için proxy olarak kullanabiliriz. Sigmoid çekirdeği aşağıdaki denklemle verilir -\n",
        "\n",
        "\n",
        "**sigmoid kernel : k (x, y) = tanh(αxTy + c)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNHGZqgOJhA8"
      },
      "source": [
        "Sigmoid çekirdeği aşağıdaki şema ile görselleştirilebilir:\n",
        "\n",
        "### Sigmoid çekirdek\n",
        "\n",
        "![Sigmoid kernel](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTKeXbOIlniBXYwMYlEYLKPwZZg8vFU1wVm3RWMACjVcT4iBVDy&s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBlTsWllJhA9"
      },
      "source": [
        "# **4. SVM Scikit-Learn kütüphaneleri** <a class=\"anchor\" id=\"4\"></a>\n",
        "\n",
        "\n",
        "Scikit-Learn, bir veri kümesinde Destek Vektör Makinesi algoritmasını uygulamak için yararlı kütüphaneleri sağlar. SVM'i sorunsuz bir şekilde uygulamamıza yardımcı olabilecek birçok kütüphane vardır. Sadece ihtiyaçlarımıza uygun parametrelerle kütüphaneyi aramamız gerekiyor. Bu notebookta, bir sınıflandırma görevi ile uğraşacaz. Bu yüzden SVM sınıflandırması için Scikit-Learn kütüphanelerinden bahsedeceğiz.\n",
        "\n",
        "İlk olarak, bir **LinearSVC()** sınıflandırıcısı vardır. Adından da anlaşılacağı gibi, bu sınıflandırıcı yalnızca **doğrusal** çekirdek kullanır. LinearSVC() sınıflandırıcısında, yalnızca doğrusal sınıflandırma amacıyla kullanıldığından çekirdeğin değerini iletmiyoruz.\n",
        "\n",
        "Scikit-Learn, sınıflandırma amacıyla kullanılan **SVC()** ve **NuSVC()** olmak üzere iki sınıflandırıcı daha sağlar. Bu sınıflandırıcılar, parametrelerde bazı farklılıkları olsa da büyük oranda benzerdir. **NuSVC()**, **SVC()** ile benzerdir ancak destek vektörlerinin sayısını kontrol etmek için bir parametre kullanır. Kernel, **gama ve C değerlerini** diğer parametrelerle birlikte iletiyoruz. **Çekirdek parametresi varsayılan olarak değeri olarak rbf'yi kullanır, ancak poli, doğrusal, sigmoid veya çağrılabilir işlev gibi değerleri iletebiliriz.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0BylMfaJhA-"
      },
      "source": [
        "# **5. Veri kümesinin ayrıntıları** <a class=\"anchor\" id=\"5\"></a>\n",
        "\n",
        "\n",
        "Bu notebookta **Bir Pulsar Yıldızını Tahmin Etme (Predicting a Pulsar Star)** veri setini kullanacağız.\n",
        "\n",
        "Pulsarlar, burada Dünya'da tespit edilebilen radyo emisyonu üreten nadir bir Nötron yıldızı türüdür. Uzay-zaman, yıldızlar arası ortam ve maddenin hallerinin sondaları olarak önemli bilimsel ilgiye sahiptirler. Özellikle veri kümelerini ikili sınıflandırma problemleri olarak ele alan sınıflandırma algoritmaları benimsenmektedir. Burada meşru pulsar örnekleri azınlık pozitif sınıfını ve sahte örnekler çoğunluk negatif sınıfını oluşturur.\n",
        "\n",
        "Burada paylaşılan veri seti, **RFI/gürültü kaynaklı 16.259 sahte örnek ve 1.639 gerçek pulsar örneği** içermektedir. Her satır önce değişkenleri listeler ve sınıf etiketi son giriştir. Kullanılan sınıf etiketleri 0 (negatif) ve 1 (pozitif) şeklindedir.\n",
        "\n",
        "\n",
        "### Öznitelikleri:\n",
        "\n",
        "Her örnek, 8 sürekli değişken ve tek bir sınıf değişkeni ile tanımlanır. İlk dördü, entegre nabız profilinden elde edilen basit istatistiklerdir. Kalan dört değişken benzer şekilde DM-SNR eğrisinden elde edilir. Bunlar aşağıda özetlenmiştir:\n",
        "\n",
        "1. Entegre profilin ortalaması (Mean of the integrated profile)\n",
        "\n",
        "2. Entegre profilin standart sapması(Standard deviation of the integrated profile)\n",
        "\n",
        "3. Entegre profilin aşırı basıklığı (Excess kurtosis of the integrated profile)\n",
        "\n",
        "4. Entegre profilin eğriliği (Skewness of the integrated profile)\n",
        "\n",
        "5. DM-SNR eğrisinin ortalaması (Mean of the DM-SNR curve)\n",
        "\n",
        "6. DM-SNR eğrisinin standart sapması (Standard deviation of the DM-SNR curve)\n",
        "\n",
        "7. DM-SNR eğrisinin aşırı basıklığı (Excess kurtosis of the DM-SNR curve)\n",
        "\n",
        "8. DM-SNR eğrisinin eğriliği (Skewness of the DM-SNR curve)\n",
        "\n",
        "9. Sınıf Etiketi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9OQLlwNJhA_"
      },
      "source": [
        "# **6. Kütüphaneleri Yükleyelim** <a class=\"anchor\" id=\"6\"></a>\n",
        "\n",
        "\n",
        "\n",
        "Gerekli Python kitaplıklarını import ederek başlıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2wju8vhJhA_"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization\n",
        "import seaborn as sns # for statistical data visualization\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeaBtwAsJhBC"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MiF2j23JhBD"
      },
      "source": [
        "# **7.Veri kümesini yüklemek** <a class=\"anchor\" id=\"7\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF8QDN5yKBVc"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQQUV6N9KFD7"
      },
      "outputs": [],
      "source": [
        "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day6-SupportVectorMachines/notebooks\"\n",
        "ROOT_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining-2nd/main/PART1/Day6-SupportVectorMachines/notebooks\"\n",
        "\n",
        "DATASET_PATH = ROOT_DIR + \"/datasets/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWe-q3OqJhBD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATASET_PATH + 'pulsar_stars.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U02epYumJhBE"
      },
      "source": [
        "# **8. Keşifsel veri analizi** <a class=\"anchor\" id=\"8\"></a>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Şimdi, veriler hakkında fikir edinmek için verileri keşfedeceğiz."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: Veri kümesinin boyutlarını yazdırın.**"
      ],
      "metadata": {
        "id": "UwPFaaxjdH6u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKOuMwdoJhBF"
      },
      "outputs": [],
      "source": [
        "# view dimensions of dataset\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrX-2UW5JhBF"
      },
      "source": [
        "Veri setinde 17898 örnek ve 9 değişken olduğunu görebiliriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u21EvOxlJhBG",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# let's preview the dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KR7OF4RJhBG"
      },
      "source": [
        "Veri setinde 9 değişken olduğunu görebiliriz. (8 sürekli değişken ve 1 ayrık değişken) \n",
        "Ayrık değişken, `target_class`  değişkenidir. Aynı zamanda hedef değişkendir.\n",
        "\n",
        "**Yapılacaklar: baştaki ve sondaki boşlukları kontrol etmek için sütun adlarını görüntüleyin.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYKjrYshJhBH"
      },
      "outputs": [],
      "source": [
        "# view the column names of the dataframe\n",
        "col_names = df.columns\n",
        "col_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk3WpZG-JhBI"
      },
      "source": [
        "**Yapılacaklar: Kolon adlarının başındaki boşlukları kaldırın.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mQrPWzRJhBI"
      },
      "outputs": [],
      "source": [
        "# remove leading spaces from column names\n",
        "df.columns = df.columns.str.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev9IXvLaJhBJ"
      },
      "source": [
        "Sütun adlarının başındaki boşluklar kaldırıldı. Aynı şeyi doğrulamak için sütun adlarına tekrar bakalım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpYmboLzJhBJ"
      },
      "outputs": [],
      "source": [
        "# view column names again\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19zyXhtMJhBK"
      },
      "source": [
        "Sütun adından baştaki boşlukların kaldırıldığını görebiliriz. Ancak sütun adları çok uzun. \n",
        "Bu yüzden onları yeniden adlandırarak kısaltıyoruz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-XlLE9aJhBL"
      },
      "outputs": [],
      "source": [
        "# rename column names\n",
        "df.columns = ['IP Mean', 'IP Sd', 'IP Kurtosis', 'IP Skewness', \n",
        "              'DM-SNR Mean', 'DM-SNR Sd', 'DM-SNR Kurtosis', 'DM-SNR Skewness', 'target_class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otLmAyq4JhBM"
      },
      "outputs": [],
      "source": [
        "# view the renamed column names\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4YHGEVvJhBM"
      },
      "source": [
        "Sütun adlarının kısaltıldığını görebiliriz. IP, `integrated profile` (entegre profil) anlamına gelir ve DM-SNR, `delta modulation and signal to noise ratio` (delta modülasyonu ve sinyal-gürültü oranı) anlamına gelir. Artık sütunlarla çalışmak çok daha kolay.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G563yqKUJhBN"
      },
      "source": [
        "Hedef değişkenimiz `target_class` sütunudur. Bu yüzden dağılımını kontrol edeceğiz.\n",
        "\n",
        "\n",
        "**Yapılacaklar: hedef sütunun her birden değerden kaçar adet olduğuna bakın.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yw8NusqJhBO"
      },
      "outputs": [],
      "source": [
        "# check distribution of target_class column\n",
        "df['target_class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: hedef sütunun değerlerinin tüm değerlere oranını yazdırınız.**"
      ],
      "metadata": {
        "id": "9FfiarqvmKeq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzipXWsBJhBO"
      },
      "outputs": [],
      "source": [
        "# view the percentage distribution of target_class column\n",
        "df['target_class'].value_counts()/np.float(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target_class'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "vxl8FPPg3Yc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khDrS94zJhBP"
      },
      "source": [
        "`0` ve `1` sınıf etiketinin gözlem yüzdesinin %90.84 ve %9.16 olduğunu görebiliriz. Yani, bu sınıf dengesiz bir problemdir.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcV_W11XJhBP"
      },
      "outputs": [],
      "source": [
        "# view summary of dataset\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvM1jodnJhBQ"
      },
      "source": [
        "Veri setinde eksik değer olmadığını ve tüm değişkenlerin sayısal değişkenler olduğunu görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTCAYSCKJhBQ"
      },
      "source": [
        "### Değişkenlerdeki eksik değerleri keşfedelim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: tüm sütunlar için eksik verilerin kontrol ediniz.**"
      ],
      "metadata": {
        "id": "w8d7wYYLmZHg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBPfjguhJhBR"
      },
      "outputs": [],
      "source": [
        "# check for missing values in variables\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-7yNNmEJhBR"
      },
      "source": [
        "Veri setinde eksik değer olmadığını görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWQ9snfwJhBS"
      },
      "source": [
        "### Sayısal değişkenlerin özeti\n",
        "\n",
        "\n",
        "- Veri setinde 9 adet sayısal değişken bulunmaktadır.\n",
        "\n",
        "\n",
        "- 8 sürekli değişkenler ve 1 ayrık değişkendir.\n",
        "\n",
        "\n",
        "- Ayrık değişken, `target_class`değişkenidir. Aynı zamanda hedef değişkendir.\n",
        "\n",
        "\n",
        "- Veri setinde eksik değer yok."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ar8XVr92JhBS"
      },
      "source": [
        "### Sayısal değişkenlerde aykırı değerler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjIawqfjJhBT"
      },
      "outputs": [],
      "source": [
        "# view summary statistics in numerical variables\n",
        "round(df.describe(),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yanaE52lJhBT"
      },
      "source": [
        "Daha yakından incelendiğinde, tüm sürekli değişkenlerin aykırı değerler içerebileceğinden şüphelenebiliriz.\n",
        "\n",
        "Yukarıdaki değişkenlerde aykırı değerleri görselleştirmek için boxplot çizeceğiz.\n",
        "\n",
        "**Yapılacaklar: Her bir IP Mean, IP Sd, IP Kurtosis, IP Skewness, DM-SNR Mean, DM-SNR Sd, DM-SNR Kurtosis, DM-SNR Skewness kolonu için boxplot() çizdirin.**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column='IP Mean', figsize=(10,10))"
      ],
      "metadata": {
        "id": "T5CoPrn039xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.boxplot(column='IP Sd', figsize=(10,10))"
      ],
      "metadata": {
        "id": "khgMh083uk9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tk454CeJhBU"
      },
      "outputs": [],
      "source": [
        "# draw boxplots to visualize outliers\n",
        "plt.figure(figsize=(24,20))\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "fig = df.boxplot(column='IP Mean')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Mean')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "fig = df.boxplot(column='IP Sd')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Sd')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "fig = df.boxplot(column='IP Kurtosis')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Kurtosis')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "fig = df.boxplot(column='IP Skewness')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Skewness')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "fig = df.boxplot(column='DM-SNR Mean')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Mean')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "fig = df.boxplot(column='DM-SNR Sd')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Sd')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "fig = df.boxplot(column='DM-SNR Kurtosis')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Kurtosis')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "fig = df.boxplot(column='DM-SNR Skewness')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Skewness')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cghhR4MPJhBV"
      },
      "source": [
        "Yukarıdaki kutu grafikleri, bu değişkenlerde çok sayıda aykırı değer olduğunu doğrulamaktadır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWIX6RwIJhBV"
      },
      "source": [
        "### Aykırı değerleri SVM'lerle ele alalım\n",
        "\n",
        "SVM'lerin 2 çeşidi vardır. Bunlar SVM'in `hard-margin variant of SVM` ve SVM'in `soft-margin variant of SVM`'ıdır.\n",
        "\n",
        "SVM'in sert marjlı çeşidi (hard-margin variant of SVM) aykırı değerlerle ilgilenmez. Bu durumda, her eğitim noktasını en az 1 marj ile doğru bir şekilde sınıflandırılacak şekilde maksimum marjlı hiperdüzlemi bulmak istiyoruz. Bu teknik aykırı değerlerle iyi bir şekilde başa çıkamaz.\n",
        "\n",
        "SVM'in başka bir versiyonuna SVM'in yumuşak marjlı varyantı (soft-margin variant of SVM) denir. Bu durumda, yanlış sınıflandırılmış birkaç noktamız olabilir veya 1'den küçük bir marjla sınıflandırılır. Ancak her nokta için, aykırı değerleri kontrol eden 'C' parametresi şeklinde bir ceza ödememiz gerekir. \"Düşük C\", daha fazla aykırı değere izin verdiğimizi ve \"yüksek C\", daha az aykırı değer anlamına gelir.\n",
        "\n",
        "**Yani bu durumda, bu veri kümesi aykırı değerler içerdiğinden, modeli eğitirken C'nin değerinin yüksek olması gerekmektedir.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aDBYdPSJhBW"
      },
      "source": [
        "### Değişkenlerin dağılımını kontrol edelim\n",
        "\n",
        "Şimdi, dağılımların normal mi yoksa çarpık mı olduğunu anlamak için histogramları çizelim.\n",
        "\n",
        "**Yapılacaklar: Her bir IP Mean, IP Sd, IP Kurtosis, IP Skewness, DM-SNR Mean, DM-SNR Sd, DM-SNR Kurtosis, DM-SNR Skewness kolonu için histogramı (bins=20) çizdirin.**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['IP Mean'].hist(bins=50)"
      ],
      "metadata": {
        "id": "MXPr-Sd348HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXHarqF4JhBW"
      },
      "outputs": [],
      "source": [
        "# plot histogram to check distribution\n",
        "plt.figure(figsize=(24,20))\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "fig = df['IP Mean'].hist(bins=20)\n",
        "fig.set_xlabel('IP Mean')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "fig = df['IP Sd'].hist(bins=20)\n",
        "fig.set_xlabel('IP Sd')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "fig = df['IP Kurtosis'].hist(bins=20)\n",
        "fig.set_xlabel('IP Kurtosis')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "fig = df['IP Skewness'].hist(bins=20)\n",
        "fig.set_xlabel('IP Skewness')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "fig = df['DM-SNR Mean'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Mean')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "fig = df['DM-SNR Sd'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Sd')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "fig = df['DM-SNR Kurtosis'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Kurtosis')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "fig = df['DM-SNR Skewness'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Skewness')\n",
        "fig.set_ylabel('Number of pulsar stars')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3YvopA5JhBX"
      },
      "source": [
        "8 sürekli değişkenin hepsinin çarpık olduğunu görebiliriz. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcUfMc0dJhBX"
      },
      "source": [
        "# **9. Özellik vektörü ve hedef değişkeni bildirelim** <a class=\"anchor\" id=\"9\"></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: y değişkenine sadece target_class kolonunu, X değişkenine de target_class haricindekileri tanımlayın.**\n"
      ],
      "metadata": {
        "id": "J820zbs3oXld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "YSBvcYMSa_6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOg1IjZVJhBY"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['target_class'], axis=1)\n",
        "\n",
        "y = df['target_class']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "vLNn1EgebCML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "RWiut74mAtVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tznU4dOiJhBZ"
      },
      "source": [
        "# **10. Verileri eğitim ve test setlerine ayıralım** <a class=\"anchor\" id=\"10\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar:** \n",
        "\n",
        "*   **StandartScaler ile öznitelikleri ölçeklendirin.** \n",
        "\n",
        "*   **Eğitim ve test kümesini %80-20 şeklinde ayırın.**\n"
      ],
      "metadata": {
        "id": "pR_4_nhdovHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaler = scaler.fit_transform(X)\n",
        "\n",
        "#X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "wfuarZSU5lLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaler"
      ],
      "metadata": {
        "id": "A9E_gKRDv8fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "G1qvhRGh6Eh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_scaler)"
      ],
      "metadata": {
        "id": "PoyXySht5_TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysorH0LwJhBZ"
      },
      "outputs": [],
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaler, y, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGOXYYJ9JhBa"
      },
      "outputs": [],
      "source": [
        "# check the shape of X_train and X_test\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "OFSyTvfobGXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG3RD8SJJhBe"
      },
      "source": [
        "Artık SVM sınıflandırıcısına vermeye hazır 'X_train' veri setimiz var.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQyQ__QBJhBe"
      },
      "source": [
        "# **12. SVM'yi varsayılan hiper parametrelerle çalıştıralım** <a class=\"anchor\" id=\"12\"></a>\n",
        "\n",
        "Varsayılan hiperparametre, diğer parametrelerin yanı sıra C=1.0, kernel=`rbf` ve gamma=`auto` anlamına gelir."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: Default hiperparametreler ile SVM sınıflandırıcısı ile sınıflandırın**"
      ],
      "metadata": {
        "id": "5gRic87hpnna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNZumdtuJhBe"
      },
      "outputs": [],
      "source": [
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "# import metrics to compute accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# instantiate classifier with default hyperparameters\n",
        "svc=SVC() \n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: Test kümesi ile prediction sonuçlarını elde edin ve accuracy_score() ile modelin sınıflandırma başarımını hesaplayın.**"
      ],
      "metadata": {
        "id": "EblZvwSCqGyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "kH4S4CDuqIkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "JKvXPH4m7TSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byQIqF3EJhBf"
      },
      "source": [
        "### SVM'yi rbf çekirdeği ve C=100.0 ile çalıştırın\n",
        "\n",
        "Veri setimizde aykırı değerler olduğunu gördük. Bu nedenle, C'nin değerini artırmalıyız, çünkü daha yüksek C, daha az aykırı değer anlamına gelir.\n",
        "SVM'yi kernel=`rbf` ve C=100.0 ile çalıştıralım.\n",
        "\n",
        "**Yapılacaklar: çekirdek olarak rbf ve C=100.0 hiperparametreleri lie SVM modeli eğitin.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTeHzYEZJhBf"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with rbf kernel and C=100\n",
        "svc=SVC(C=100.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacaklar: Test kümesi ile prediction sonuçlarını elde edin ve accuracy_score() ile modelin sınıflandırma başarımını hesaplayın.**"
      ],
      "metadata": {
        "id": "ZqW888TkqWv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ],
      "metadata": {
        "id": "yfzlAAohqXh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htAUl3oYJhBf"
      },
      "source": [
        "Daha yüksek C daha az aykırı değer anlamına geldiğinden, C=100.0 ile daha yüksek bir doğruluk elde ettiğimizi görebiliriz.\n",
        "\n",
        "Şimdi, C=1000.0 değerini daha da artıralım ve doğruluğunu kontrol edelim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44xufvx8JhBg"
      },
      "source": [
        "### SVM'yi rbf çekirdeği ve C=1000.0 ile çalıştıralım\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-cLSsbpJhBg"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with rbf kernel and C=1000\n",
        "svc=SVC(C=1000.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoSxWCEWJhBg"
      },
      "source": [
        "Bu durumda doğruluğun C=1000.0 ile azaldığını görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HE3fRNQSJhBh"
      },
      "source": [
        "# **13. SVM'yi linear kernel ile çalıştıralım** <a class=\"anchor\" id=\"13\"></a>\n",
        "\n",
        "\n",
        "### SVM'yi linear kernel ve C=1.0 ile çalıştıralım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wantn_TJhBh"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with linear kernel and C=1.0\n",
        "linear_svc=SVC(kernel='linear', C=1.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc.fit(X_train,y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred_test=linear_svc.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PokaDvS3JhBi"
      },
      "source": [
        "### SVM'i linear kernel ve C=100.0 ile çalıştıralım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi5X9mmDJhBi"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with linear kernel and C=100.0\n",
        "linear_svc100=SVC(kernel='linear', C=100.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc100.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc100.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm7QD6EFJhBi"
      },
      "source": [
        "### SVM'i linear kernel ve C=1000.0 ile çalıştıralım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBN70Qh6JhBi"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with linear kernel and C=1000.0\n",
        "linear_svc1000=SVC(kernel='linear', C=1000.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc1000.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc1000.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVPFpDeEJhBj"
      },
      "source": [
        "C=1.0'a göre C=100.0 ve C=1000.0 ile daha yüksek doğruluk elde edebileceğimizi görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kj_PHYwbJhBj"
      },
      "source": [
        "Burada, **y_test** gerçek sınıf etiketleridir ve **y_pred**, test kümesindeki tahmin edilen sınıf etiketleridir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDqgDIoLJhBj"
      },
      "source": [
        "### Eğitim seti ve test seti doğruluğunu karşılaştıralım.\n",
        "\n",
        "\n",
        "Şimdi, aşırı uyum (overfit) olup olmadığını kontrol etmek için eğitim seti ve test seti doğruluğunu karşılaştıralım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg-9QRsWJhBk"
      },
      "outputs": [],
      "source": [
        "y_pred_train = linear_svc.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq4tvjJyJhBk"
      },
      "outputs": [],
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22mkYtAHJhBk"
      },
      "source": [
        "Eğitim seti ve test seti doğruluğunun çok karşılaştırılabilir olduğunu görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0N12zdlJhBk"
      },
      "source": [
        "### Fazla ve eksik uyum olup olmadığını kontrol edelim."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwzjMGKyJhBl"
      },
      "outputs": [],
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrhIXVaFJhBl"
      },
      "source": [
        "Eğitim seti doğruluk puanı 0.9783 iken test seti doğruluğu 0.9830'dur. Bu iki değer oldukça karşılaştırılabilir. Yani, fazla uydurma sorunu yoktur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsyHGhg9JhBp"
      },
      "source": [
        "# **14. SVM'i polynomial kernel ile çalıştıralım** <a class=\"anchor\" id=\"14\"></a>\n",
        "\n",
        "### SVM'yi polynomial kernel ve C=1.0 ile çalıştıralım"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-DH3ZYOJhBq"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with polynomial kernel and C=1.0\n",
        "poly_svc=SVC(kernel='poly', C=1.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc.fit(X_train,y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9-GUWp4JhBq"
      },
      "source": [
        " ### SVM'i polynomial kernel ve C=100.0 ile çalıştıralım."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uBM1dIlYJhBq"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with polynomial kernel and C=100.0\n",
        "poly_svc100=SVC(kernel='poly', C=100.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc100.fit(X_train, y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc100.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NowNbNyJhBr"
      },
      "source": [
        "Polinom çekirdek düşük performans verir. Eğitim setine fazla uyuyor olabilir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0ud3A1eJhBs"
      },
      "source": [
        "# **15. SVM'i sigmoid kernel ile çalıştıralım** <a class=\"anchor\" id=\"15\"></a>\n",
        "\n",
        "### SVM'yi sigmoid kernel ve C=1.0 ile çalıştıralım"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnhNGRs6JhBt"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with sigmoid kernel and C=1.0\n",
        "sigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc.fit(X_train,y_train)\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc.predict(X_test)\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cnd3LuFZJhBu"
      },
      "source": [
        "### SVM'yi sigmoid kernel ve C=100.0 ile çalıştıralım"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqxJT9VZJhBu"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with sigmoid kernel and C=100.0\n",
        "sigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc100.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfkEfSCCJhBu"
      },
      "source": [
        "Aynı polinom çekirdeğinde olduğu gibi sigmoid çekirdeğin de kötü performans gösterdiğini görebiliriz."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmTFjPk-JhBu"
      },
      "source": [
        "### Yorumlar\n",
        "\n",
        "`rbf` ve `linear` kernel ile C=100.0 ile maksimum doğruluk elde ediyoruz (doğruluk 0.9832'dir). Yukarıdaki analize dayanarak, sınıflandırma modeli doğruluğumuzun çok iyi olduğu sonucuna varabiliriz. Modelimiz, sınıf etiketlerini tahmin etme açısından çok iyi bir iş çıkarıyor.\n",
        "\n",
        "Ama bu doğru değil. Burada dengesiz bir veri setimiz var. Sorun şu ki, doğruluk, dengesiz veri kümesi probleminde tahmine dayalı performansı ölçmek için yetersiz bir ölçüdür.\n",
        "\n",
        "Bu nedenle, model seçiminde daha iyi rehberlik sağlayan alternatif ölçümleri araştırmalıyız. Özellikle, değerlerin altında yatan dağılımı ve sınıflandırıcımızın yaptığı hataların türünü bilmek isteriz.\n",
        "\n",
        "Dengesiz sınıflar probleminde model performansını analiz etmek için böyle bir metrik \"Karışıklık matrisi\"dir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoGOp0FIJhBv"
      },
      "source": [
        "# **16. Confusion matrix** <a class=\"anchor\" id=\"16\"></a>\n",
        "\n",
        "A confusion matrix is a tool for summarizing the performance of a classification algorithm. A confusion matrix will give us a clear picture of classification model performance and the types of errors produced by the model. It gives us a summary of correct and incorrect predictions broken down by each category. The summary is represented in a tabular form.\n",
        "\n",
        "\n",
        "Four types of outcomes are possible while evaluating a classification model performance. These four outcomes are described below:-\n",
        "\n",
        "\n",
        "**True Positives (TP)** – True Positives occur when we predict an observation belongs to a certain class and the observation actually belongs to that class.\n",
        "\n",
        "\n",
        "**True Negatives (TN)** – True Negatives occur when we predict an observation does not belong to a certain class and the observation actually does not belong to that class.\n",
        "\n",
        "\n",
        "**False Positives (FP)** – False Positives occur when we predict an observation belongs to a    certain class but the observation actually does not belong to that class. This type of error is called **Type I error.**\n",
        "\n",
        "\n",
        "\n",
        "**False Negatives (FN)** – False Negatives occur when we predict an observation does not belong to a certain class but the observation actually belongs to that class. This is a very serious error and it is called **Type II error.**\n",
        "\n",
        "\n",
        "\n",
        "These four outcomes are summarized in a confusion matrix given below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu_4qsIZJhBv"
      },
      "outputs": [],
      "source": [
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQHnbr2CJhBv"
      },
      "source": [
        "Karışıklık matrisi \"3289 + 230 = 3519 doğru tahmin\" ve \"17 + 44 = 61 yanlış tahmin\" gösterir.\n",
        "\n",
        "Bu durumda, elimizde\n",
        "\n",
        "- `Gerçek Pozitifler (True Positives)` (Actual Positive:1 and Predict Positive:1) - 3289\n",
        "\n",
        "\n",
        "- `Gerçek Negatif (True Negatives)` (Actual Negative:0 and Predict Negative:0) - 230\n",
        "\n",
        "\n",
        "- `Yanlış Pozitifler (False Positives)` (Actual Negative:0 but Predict Positive:1) - 17 `(Type I error)`\n",
        "\n",
        "\n",
        "- `Yanlış Negatifler (False Negatives)` (Actual Positive:1 but Predict Negative:0) - 44 `(Type II error)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE7siRmJJhBw"
      },
      "outputs": [],
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jix5cpS6JhBw"
      },
      "source": [
        "# **17. Sınıflandırma metrikleri** <a class=\"anchor\" id=\"17\"></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRHLUPFNJhBw"
      },
      "source": [
        "### Sınıflandırma Raporu\n",
        "\n",
        "**Sınıflandırma raporu (Classification report)**, sınıflandırma modeli performansını değerlendirmenin başka bir yoludur. Model için **kesinlik (precision)**, **duyarlılık(recall)**, **f1** ve **destek (support)** puanlarını görüntüler.\n",
        "\n",
        "Aşağıdaki gibi bir sınıflandırma raporu yazdırabiliriz:-\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxJMYTpJJhBw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MhK35o_JhBx"
      },
      "source": [
        "### Sınıflandırma Doğruluğu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mncuLd8oJhBx"
      },
      "outputs": [],
      "source": [
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmV2cbv2JhBx"
      },
      "outputs": [],
      "source": [
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4pyYUlBJhBx"
      },
      "source": [
        "### Sınıflandırma Hatası"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QLpxeqVJhBx"
      },
      "outputs": [],
      "source": [
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K20bZaTTJhBy"
      },
      "source": [
        "### Kesinlik (Precision)\n",
        "\n",
        "**Kesinlik (Precision)**, tahmin edilen tüm olumlu sonuçlar içinde doğru tahmin edilen olumlu sonuçların yüzdesi olarak tanımlanabilir. Gerçek pozitiflerin (TP) doğru ve yanlış pozitiflerin (TP + FP) toplamına oranı olarak verilebilir.\n",
        "\n",
        "Bu nedenle, **Kesinlik**, doğru tahmin edilen olumlu sonucun oranını tanımlar. Negatif sınıftan çok pozitif sınıfla ilgilenir.\n",
        "\n",
        "Matematiksel olarak kesinlik, 'TP'nin (TP + FP)'ye oranı olarak tanımlanabilir.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Me99tFfLJhBy"
      },
      "outputs": [],
      "source": [
        "# print precision score\n",
        "\n",
        "precision = TP / float(TP + FP)\n",
        "\n",
        "\n",
        "print('Precision : {0:0.4f}'.format(precision))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Od6odJJhB0"
      },
      "source": [
        "### Duyarlılık(Recall)\n",
        "\n",
        "Duyarlılık(Recall), tüm gerçek olumlu sonuçlardan doğru olarak tahmin edilen olumlu sonuçların yüzdesi olarak tanımlanabilir.\n",
        "Gerçek pozitiflerin (TP) gerçek pozitiflerin ve yanlış negatiflerin (TP + FN) toplamına oranı olarak verilebilir. **Duyarlılık(Recall)** aynı zamanda **Hassasiyet (Sensitivity)** olarak da adlandırılır.\n",
        "\n",
        "**Duyarlılık(Recall)**, doğru tahmin edilen gerçek pozitiflerin oranını tanımlar.\n",
        "\n",
        "Matematiksel olarak, **hatırlama**, 'TP'nin (TP + FN)' oranı olarak tanımlanabilir.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f0Nxr2RJhB0"
      },
      "outputs": [],
      "source": [
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oll1-lRIJhB1"
      },
      "source": [
        "### Gerçek Pozitif Oran (True Positive Rate)\n",
        "\n",
        "**Gerçek Pozitif Oran (True Positive Rate)**, **Recall** ile eş anlamlıdır.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iM-NMROFJhB1"
      },
      "outputs": [],
      "source": [
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmWXsg-gJhB1"
      },
      "source": [
        "### Yanlış Pozitif Oran"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-OgPzB2aJhB1"
      },
      "outputs": [],
      "source": [
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVxrg4MVJhB2"
      },
      "source": [
        "### Özgüllük (Specificity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKYHeXSvJhB2"
      },
      "outputs": [],
      "source": [
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p4vPoXBJhB2"
      },
      "source": [
        "### F1-Skoru\n",
        "\n",
        "\n",
        "**F1-Skoru** kesinlik ve duyarlılığın ağırlıklı harmonik ortalamasıdır. Mümkün olan en iyi **f1 skoru** 1.0 ve en kötüsü ise 0.0 olacaktır. \n",
        "\n",
        "**f1-skor**, kesinlik ve duyarlılığın harmonik ortalamasıdır. \n",
        "\n",
        "Bu nedenle, **f1-skor**, hesaplamalarına kesinlik ve duyarlılık yerleştirdiklerinden, doğruluk ölçümlerinden her zaman daha düşüktür. \n",
        "\n",
        "Sınıflandırıcı modellerini karşılaştırmak için genel doğruluk değil, ağırlıklı ortalama \"f1-puanı\" kullanılmalıdır.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxUjFcYaJhB3"
      },
      "source": [
        "# **18. ROC - AUC** <a class=\"anchor\" id=\"18\"></a>\n",
        "\n",
        "### ROC Curve\n",
        "\n",
        "Sınıflandırma modeli performansını görsel olarak ölçmek için başka bir araç **ROC Eğrisi**'dir. ROC Eğrisi, **Receiver Operating Characteristic Curve** anlamına gelir. **ROC Eğrisi**, çeşitli sınıflandırma eşik seviyelerinde bir sınıflandırma modelinin performansını gösteren bir grafiktir.\n",
        "\n",
        "**ROC Eğrisi**, çeşitli eşik seviyelerinde **Yanlış Pozitif Oranı (FPR)** karşısında **Gerçek Pozitif Oranı (TPR)** gösterir.\n",
        "\n",
        "**Gerçek Pozitif Oran (TPR)** aynı zamanda **Duyarlılık(Recall)** olarak da adlandırılır. 'TP'nin (TP + FN)'ye oranı olarak tanımlanır.\n",
        "\n",
        "**Yanlış Pozitif Oranı (FPR)**, 'FP'nin (FP + TN)' oranı olarak tanımlanır.\n",
        "\n",
        "\n",
        "ROC Eğrisinde, tek bir noktanın TPR (True Positive Rate) ve FPR (False Positive Rate) değerlerine odaklanacağız. Bu bize çeşitli eşik seviyelerinde TPR ve FPR'den oluşan ROC eğrisinin genel performansını verecektir. Bu nedenle, bir ROC Eğrisi, farklı sınıflandırma eşik seviyelerinde TPR'ye karşı FPR'yi çizer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHBP1NO2JhB3"
      },
      "outputs": [],
      "source": [
        "# plot ROC Curve\n",
        "\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_test)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "\n",
        "plt.plot(fpr, tpr, linewidth=2)\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--' )\n",
        "\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "plt.title('ROC curve for Predicting a Pulsar Star classifier')\n",
        "\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi3XVFVbJhB3"
      },
      "source": [
        "ROC eğrisi, belirli bir bağlam için duyarlılık ve özgüllüğü dengeleyen bir eşik düzeyi seçmemize yardımcı olur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHmjvrKZJhB4"
      },
      "source": [
        "### ROC  AUC\n",
        "\n",
        "**ROC AUC**, **Receiver Operating Characteristic - Area Under Curve** anlamına gelir. Sınıflandırıcı performansını karşılaştırmak için bir tekniktir. \n",
        "\n",
        "Bu teknikte 'eğrinin altındaki alanı (AUC)' ölçüyoruz. \n",
        "\n",
        "Mükemmel bir sınıflandırıcının ROC AUC'si 1'e eşitken, tamamen rastgele bir sınıflandırıcının ROC AUC'si 0,5'e eşit olacaktır.\n",
        "\n",
        "Dolayısıyla, **ROC AUC**, eğrinin altındaki ROC grafiğinin yüzdesidir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBO9u-AfJhB4"
      },
      "outputs": [],
      "source": [
        "# compute ROC AUC\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "ROC_AUC = roc_auc_score(y_test, y_pred_test)\n",
        "\n",
        "print('ROC AUC : {:.4f}'.format(ROC_AUC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooxi8tcbJhB4"
      },
      "source": [
        "### Yorumlar\n",
        "\n",
        "- ROC AUC, sınıflandırıcı performansının tek sayılı bir özetidir. Değer ne kadar yüksek olursa, sınıflandırıcı o kadar iyi olur.\n",
        "\n",
        "- Modelimizin ROC AUC'si 1'e yaklaşıyor. Böylece, sınıflandırıcımızın pulsar yıldızını sınıflandırmada iyi bir iş çıkardığı sonucuna varabiliriz.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWZPPI9MJhB5"
      },
      "outputs": [],
      "source": [
        "# calculate cross-validated ROC AUC \n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Cross_validated_ROC_AUC = cross_val_score(linear_svc, X_train, y_train, cv=10, scoring='roc_auc').mean()\n",
        "\n",
        "print('Cross validated ROC AUC : {:.4f}'.format(Cross_validated_ROC_AUC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SToZ17SoJhB5"
      },
      "source": [
        "# **19. Karışık bölme ile katmanlı k-kat Çapraz Doğrulama (Stratified k-fold Cross Validation with shuffle split)** <a class=\"anchor\" id=\"19\"></a>\n",
        "\n",
        "k-kat çapraz doğrulama, model performansını değerlendirmek için çok kullanışlı bir tekniktir. Ancak burada başarısız oluyor çünkü dengesiz bir veri setimiz var. Bu nedenle, dengesiz veri kümesi durumunda, model performansını değerlendirmek için başka bir teknik kullanacağız. Buna 'katmanlı k-kat çapraz doğrulama'  (`stratified k-fold cross-validation`) denir.\n",
        "\n",
        "\n",
        "'Katmanlı k-kat çapraz doğrulama'da, verileri sınıflar arasındaki oranlar tüm veri kümesinde olduğu gibi her katta aynı olacak şekilde böleriz.\n",
        "\n",
        "Ayrıca, bölmeden önce verileri karıştıracağız çünkü karıştırma çok daha iyi sonuç verir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAEtiIREJhB5"
      },
      "source": [
        "### Doğrusal çekirdekli (Linear Kernel) shuffle split ile Katmanlı k-Fold Çapraz Doğrulama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84yTWSo2JhB5"
      },
      "outputs": [],
      "source": [
        "#from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "s_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "linear_svc = SVC(kernel='linear')\n",
        "\n",
        "linear_scores = cross_val_score(linear_svc, X, y, cv=s_kfold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0H6CTw5EJhB6"
      },
      "outputs": [],
      "source": [
        "# print cross-validation scores with linear kernel\n",
        "\n",
        "print('Stratified cross-validation scores with linear kernel:\\n\\n{}'.format(linear_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVaESDGaJhB6"
      },
      "outputs": [],
      "source": [
        "# print average cross-validation score with linear kernel\n",
        "\n",
        "print('Average stratified cross-validation score with linear kernel:{:.4f}'.format(linear_scores.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz6ddP6_JhB6"
      },
      "source": [
        "### rbf kernel'li shuffle split ile Katmanlı k-Fold Çapraz Doğrulama  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su8Xw557JhB6"
      },
      "outputs": [],
      "source": [
        "rbf_svc=SVC(kernel='rbf')\n",
        "\n",
        "rbf_scores = cross_val_score(rbf_svc, X, y, cv=s_kfold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTfbx1baJhB7"
      },
      "outputs": [],
      "source": [
        "# print cross-validation scores with rbf kernel\n",
        "\n",
        "print('Stratified Cross-validation scores with rbf kernel:\\n\\n{}'.format(rbf_scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szNHZc5DJhB7"
      },
      "outputs": [],
      "source": [
        "# print average cross-validation score with rbf kernel\n",
        "\n",
        "print('Average stratified cross-validation score with rbf kernel:{:.4f}'.format(rbf_scores.mean()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJdcT9ciJhB7"
      },
      "source": [
        "### Yorumlar\n",
        "\n",
        "Doğrusal çekirdek ile 0.9789'luk daha yüksek ortalama katmanlı k-kat çapraz doğrulama puanı elde ediyoruz, ancak model doğruluğu 0.9832.\n",
        "\n",
        "Bu nedenle, katmanlı çapraz doğrulama tekniği model performansını iyileştirmeye yardımcı olmaz.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kva2xsxNJhB8"
      },
      "source": [
        "# 20. GridSearch CV kullanarak Hiperparametre Optimizasyonu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMprH8a7JhB8"
      },
      "outputs": [],
      "source": [
        "# import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# instantiate classifier with default hyperparameters with kernel=rbf, C=1.0 and gamma=auto\n",
        "svc=SVC() \n",
        "\n",
        "\n",
        "\n",
        "# declare parameters for hyperparameter tuning\n",
        "parameters = [ {'C':[1, 10, 100, 1000], 'kernel':['linear']},\n",
        "               {'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
        "               {'C':[1, 10, 100, 1000], 'kernel':['poly'], 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05]} \n",
        "              ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator = svc,  \n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5,\n",
        "                           verbose=0)\n",
        "\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp1TPBiBJhB9"
      },
      "outputs": [],
      "source": [
        "# examine the best model\n",
        "\n",
        "\n",
        "# best score achieved during the GridSearchCV\n",
        "print('GridSearch CV best score : {:.4f}\\n\\n'.format(grid_search.best_score_))\n",
        "\n",
        "\n",
        "# print parameters that give the best results\n",
        "print('Parameters that give the best results :','\\n\\n', (grid_search.best_params_))\n",
        "\n",
        "\n",
        "# print estimator that was chosen by the GridSearch\n",
        "print('\\n\\nEstimator that was chosen by the search :','\\n\\n', (grid_search.best_estimator_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate classifier with sigmoid kernel and C=100.0\n",
        "svm_best=SVC(kernel='rbf', C=10.0, gamma=0.3) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svm_best.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svm_best.predict(X_test)"
      ],
      "metadata": {
        "id": "ws8O0Bxt_1-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "1D9Vo_sAA7FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "NiWaq1PHA5up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "b8t_nJnnA_7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=svm_best.predict(X_test)"
      ],
      "metadata": {
        "id": "aNFU6kefBEq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[\"sonuclarimiz\"] = y_pred\n",
        "X_test"
      ],
      "metadata": {
        "id": "lXdVAFOcBJkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "0EGGJRrX__h1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "GFBSe7cUAb3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "jw5YSpJWAajm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1YNbi8Li__kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYdn5IwoJhB9"
      },
      "outputs": [],
      "source": [
        "# calculate GridSearch CV score on test set\n",
        "\n",
        "print('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlQkSP3GJhB9"
      },
      "source": [
        "### Yorumlar\n",
        "\n",
        "- Orijinal model test doğruluğumuz 0.9832 iken, test setindeki GridSearch CV puanı 0.9835'tir.\n",
        "\n",
        "\n",
        "- Böylece, GridSearch CV, bu belirli model için performansı artıracak parametreleri belirlemeye yardımcı olur.\n",
        "\n",
        "\n",
        "- Burada, 'grid_search'ün `best_score_` özniteliği ile test setindeki `score` yöntemini karıştırmamalıyız.\n",
        "\n",
        "\n",
        "- Test setindeki `score` yöntemi, modelin genelleme performansını verir. `score` yöntemini kullanarak, tüm eğitim seti üzerinde eğitilmiş bir model kullanıyoruz.\n",
        "\n",
        "\n",
        "- `best_score_` özelliği, eğitim setinde gerçekleştirilen çapraz doğrulama ile ortalama çapraz doğrulama doğruluğunu verir.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKv4Cu_eJhB9"
      },
      "source": [
        "# **21. Sonuç ve Kapanış** <a class=\"anchor\" id=\"21\"></a>\n",
        "\n",
        "1. Veri setimizde aykırı değerler var. Bu nedenle, daha az aykırı değeri sınırlamak için C değerini artırdıkça doğruluk arttı. Bu, farklı çekirdek türleri için geçerlidir.\n",
        "\n",
        "2. 'rbf' ve 'linear' kernel ile C=100.0 ile maksimum doğruluk elde ediyoruz ve doğruluk 0.9832'dir. Dolayısıyla, sınıf etiketlerini tahmin etme açısından modelimizin çok iyi bir iş çıkardığı sonucuna varabiliriz. Ama bu doğru değil. Burada dengesiz bir veri setimiz var. Doğruluk, dengesiz veri kümesi probleminde tahmine dayalı performansı ölçmek için yetersiz bir ölçüdür. Bu nedenle, model seçiminde daha iyi rehberlik sağlayan \"karışıklık matrisi\"ni araştırmalıyız.\n",
        "\n",
        "3. Modelimizin ROC AUC'si 1'e çok yakındır. Dolayısıyla, sınıflandırıcımızın pulsar yıldızını sınıflandırmada iyi bir iş çıkardığı sonucuna varabiliriz.\n",
        "\n",
        "4. Doğrusal çekirdek ile 0.9789'luk daha yüksek ortalama katmanlı k-kat çapraz doğrulama puanı elde ettik, ancak model doğruluğu 0.9832'dir. Bu nedenle, katmanlı çapraz doğrulama tekniği model performansını iyileştirmeye yardımcı olmadı.\n",
        "\n",
        "5. Orijinal model test doğruluğumuz 0.9832 iken, test setindeki GridSearch CV puanı 0.9835'tir. Bu nedenle GridSearch CV, bu belirli model için performansı artıracak parametreleri belirlemeye yardımcı olur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0aIUXz-JhB-"
      },
      "source": [
        "# **22. Referanslar** <a class=\"anchor\" id=\"22\"></a>\n",
        "\n",
        "\n",
        "  1. Hands on Machine Learning with Scikit-Learn and Tensorflow by Aurélién Géron\n",
        "\n",
        "  2. Introduction to Machine Learning with Python by Andreas C. Müller and Sarah Guido\n",
        "\n",
        "  3. Udemy course – Machine Learning – A Z by Kirill Eremenko and Hadelin de Ponteves\n",
        "\n",
        "  4. Udemy course – Feature Engineering for Machine Learning by Soledad Galli\n",
        "\n",
        "  5. https://en.wikipedia.org/wiki/Support-vector_machine\n",
        "\n",
        "  6. https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
        "\n",
        "  7. http://dataaspirant.com/2017/01/13/support-vector-machine-algorithm/\n",
        "\n",
        "  8. https://www.ritchieng.com/machine-learning-evaluate-classification-model/\n",
        "\n",
        "  9. https://en.wikipedia.org/wiki/Kernel_method\n",
        "\n",
        "  10. https://en.wikipedia.org/wiki/Polynomial_kernel\n",
        "\n",
        "  11. https://en.wikipedia.org/wiki/Radial_basis_function_kernel\n",
        "\n",
        "  12. https://data-flair.training/blogs/svm-kernel-functions/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "de2QMLiFM-Rs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "TWQ9snfwJhBS",
        "FWIX6RwIJhBV",
        "NmTFjPk-JhBu",
        "6p4vPoXBJhB2",
        "bJdcT9ciJhB7",
        "wlQkSP3GJhB9",
        "BKv4Cu_eJhB9"
      ],
      "name": "Day6_SupportVectorMachines_Exercises_1(Solution).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}