{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvpbYKCopJ3x"
      },
      "source": [
        "# Birliktelik Kuralı Madenciliği - Mlxtend ile Pazar Sepeti Analizi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIssamQnpJ34"
      },
      "source": [
        "# 1. Giriş"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jYYS-c_pJ35"
      },
      "source": [
        "<img width=\"1000\" height=\"400\" alt=\"netflix\" align=\"left\" src=\"https://user-images.githubusercontent.com/36535914/78720348-369df700-792e-11ea-9950-8f5731409171.png\">\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBAjMnZ9pJ36"
      },
      "source": [
        "Birliktelik kuralı öğrenme, büyük veritabanlarındaki değişkenler arasındaki ilişkileri keşfetmek için kural tabanlı bir makine öğrenme yöntemidir. Amaç, güven (confidence) veya lift gibi bazı ölçüleri kullanarak veri kümelerinde keşfedilen güçlü ilişkileri belirlemektir.\n",
        "\n",
        "Tüketici davranışına dayalı daha somut bir örnekte olduğu gibi, çocuk bezi satın alan kişilerin aynı zamanda bira da satın alma olasılığının yüksek olduğunu öne süren {Çocuk Bezi}→{Bira} gibi ilişkilerin yakalanmasına sebep olur. Böyle bir birliktelik kuralının \"ilgisini\" değerlendirmek için farklı metrikler geliştirilmiştir. Mevcut uygulama, yukarıda bahsettiğimiz güven ve lift metriklerini kullanıyor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E79P22e9pJ36"
      },
      "source": [
        "- ***Bir müşteri ekmek satın alırsa, süt satın alma olasılığı %70'tir.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PkelU3ZpJ37"
      },
      "source": [
        "Yukarıdaki birliktelik kuralında ekmek girdi, süt ise sonuçtur. Basitçe söylemek gerekirse, müşterilerini daha iyi hedeflemek için bir perakende mağazasının birliktelik kuralı olarak anlaşılabilir. Yukarıdaki kural, bazı veri kümelerinin kapsamlı bir analizinin bir sonucuysa, yalnızca müşteri hizmetlerini iyileştirmek için değil, aynı zamanda şirketin gelirini de iyileştirmek için kullanılabilir.\n",
        "\n",
        "Yukarıdakilere ek olarak, tavsiye sistemleri, tıbbi teşhis, protein dizisi, nüfus sayımı verileri ve hatta suç önleme gibi birçok uygulamada birliktelik kuralına dayalı öğrenme teknikleri de kullanılmaktadır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGOko06upJ38"
      },
      "source": [
        "# 2. Veri Yükleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Ld2smkAPpJ38"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import networkx as nx\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori,association_rules\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day7-DecisionTree/notebooks\"\n",
        "ROOT_DIR = \"https://raw.githubusercontent.com/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART1/Day8-UnsupervisedLearning/notebooks/\"\n",
        "\n",
        "DATASET_PATH = ROOT_DIR + \"/datasets/\""
      ],
      "metadata": {
        "id": "2UEqVK-Z1VGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "5W1Mxzv6pJ3-"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(DATASET_PATH + \"Market_Basket_Optimisation.csv\", header=None)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhS6zv41pJ3_"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XAp929jpJ3_"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nAcYADxpJ4A"
      },
      "source": [
        "# 3. Veri Görselleştirme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5KbFnJApJ4A"
      },
      "source": [
        "***- Veri kümesinde en çok talep edilen öğeler / Top10***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a-8HphApJ4B"
      },
      "outputs": [],
      "source": [
        "# 1. Gather All Items of Each Transactions into Numpy Array\n",
        "transaction = []\n",
        "for i in range(0, data.shape[0]):\n",
        "    for j in range(0, data.shape[1]):\n",
        "        transaction.append(data.values[i,j])\n",
        "\n",
        "transaction = np.array(transaction)\n",
        "\n",
        "# 2. Transform Them a Pandas DataFrame\n",
        "df = pd.DataFrame(transaction, columns=[\"items\"]) \n",
        "df[\"incident_count\"] = 1 # Put 1 to Each Item For Making Countable Table, to be able to perform Group By\n",
        "\n",
        "# 3. Delete NaN Items from Dataset\n",
        "indexNames = df[df['items'] == \"nan\" ].index\n",
        "df.drop(indexNames , inplace=True)\n",
        "\n",
        "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
        "df_table = df.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
        "\n",
        "# 5. Initial Visualizations\n",
        "df_table.head(10).style.background_gradient(cmap='Blues')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMZV6WrpJ4C"
      },
      "source": [
        "***- Veri kümesinde en çok talep edilen öğeler / Top30***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": false,
        "id": "37nCe03_pJ4D"
      },
      "outputs": [],
      "source": [
        "df_table[\"all\"] = \"all\" # to have a same origin\n",
        "\n",
        "fig = px.treemap(df_table.head(30), path=['all', \"items\"], values='incident_count',\n",
        "                  color=df_table[\"incident_count\"].head(30), hover_data=['items'],\n",
        "                  color_continuous_scale='Blues',\n",
        "                  )\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQXb1U44pJ4D"
      },
      "source": [
        "***- Bir işlemde ürünlerin birden fazla kaydı olup olmadığını kontrol edelim.***<br>\n",
        "***- Cevap \"Evet\" ise, sonraki adımlarda apriori algoritmasını yanlış yönlendirebilecekleri için bunları ele almamız gerekir.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLhyK0dipJ4D"
      },
      "outputs": [],
      "source": [
        "# Transform Every Transaction to Seperate List & Gather Them into Numpy Array\n",
        "# By Doing So, We Will Be Able To Iterate Through Array of Transactions\n",
        "\n",
        "transaction = []\n",
        "for i in range(data.shape[0]):\n",
        "    transaction.append([str(data.values[i,j]) for j in range(data.shape[1])])\n",
        "    \n",
        "transaction = np.array(transaction)\n",
        "\n",
        "# Create a DataFrame In Order To Check Status of Top20 Items\n",
        "\n",
        "top20 = df_table[\"items\"].head(20).values\n",
        "array = []\n",
        "df_top20_multiple_record_check = pd.DataFrame(columns=top20)\n",
        "\n",
        "for i in range(0, len(top20)):\n",
        "    array = []\n",
        "    for j in range(0,transaction.shape[0]):\n",
        "        array.append(np.count_nonzero(transaction[j]==top20[i]))\n",
        "        if len(array) == len(data):\n",
        "            df_top20_multiple_record_check[top20[i]] = array\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "\n",
        "df_top20_multiple_record_check.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PUR0bHLpJ4E"
      },
      "outputs": [],
      "source": [
        "df_top20_multiple_record_check.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qVHupJBpJ4E"
      },
      "source": [
        "- ***Yukarıda gördüğünüz gibi sadece Chocolate'ın max değeri 2'dir. Diğerlerinin max değeri 1'dir. Bu nedenle verilerin homojen olduğunu söyleyebiliriz, herhangi bir çıkarım yapmadan ilerleyebiliriz.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tFtdwmlpJ4E"
      },
      "source": [
        "***- Seçim Analizi / Müşterilerin İlk Tercihleri***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTB9A3bGpJ4E"
      },
      "outputs": [],
      "source": [
        "# 1. Gather Only First Choice of Each Transactions into Numpy Array\n",
        "# Similar Pattern to Above, Only Change is the Column Number \"0\" in Append Function\n",
        "transaction = []\n",
        "for i in range(0, data.shape[0]):\n",
        "    transaction.append(data.values[i,0])\n",
        "\n",
        "transaction = np.array(transaction)\n",
        "\n",
        "# 2. Transform Them a Pandas DataFrame\n",
        "df_first = pd.DataFrame(transaction, columns=[\"items\"])\n",
        "df_first[\"incident_count\"] = 1\n",
        "\n",
        "# 3. Delete NaN Items from Dataset\n",
        "indexNames = df_first[df_first['items'] == \"nan\" ].index\n",
        "df_first.drop(indexNames , inplace=True)\n",
        "\n",
        "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
        "df_table_first = df_first.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
        "df_table_first[\"food\"] = \"food\"\n",
        "df_table_first = df_table_first.truncate(before=-1, after=15) # Fist 15 Choice\n",
        "df_table_first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": false,
        "id": "EtlRRy93pJ4F"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (20, 20)\n",
        "\n",
        "first_choice = nx.from_pandas_edgelist(df_table_first, source = 'food', target = \"items\", edge_attr = True)\n",
        "pos = nx.spring_layout(first_choice)\n",
        "\n",
        "nx.draw_networkx_nodes(first_choice, pos, node_size = 12500, node_color = \"lavender\")\n",
        "nx.draw_networkx_edges(first_choice, pos, width = 3, alpha = 0.6, edge_color = 'black')\n",
        "nx.draw_networkx_labels(first_choice, pos, font_size = 18, font_family = 'sans-serif')\n",
        "plt.axis('off')\n",
        "plt.grid()\n",
        "plt.title('Top 15 First Choices', fontsize = 25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4n97QbmpJ4F"
      },
      "source": [
        "***- Seçim Analizi / Müşterilerin İkinci Tercihleri***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "YSzvvAiUpJ4F"
      },
      "outputs": [],
      "source": [
        "# 1. Gather Only Second Choice of Each Transaction into Numpy Array\n",
        "\n",
        "transaction = []\n",
        "for i in range(0, data.shape[0]):\n",
        "    transaction.append(data.values[i,1])\n",
        "\n",
        "transaction = np.array(transaction)\n",
        "\n",
        "# 2. Transform Them a Pandas DataFrame\n",
        "df_second = pd.DataFrame(transaction, columns=[\"items\"]) \n",
        "df_second[\"incident_count\"] = 1\n",
        "\n",
        "# 3. Delete NaN Items from Dataset\n",
        "indexNames = df_second[df_second['items'] == \"nan\" ].index\n",
        "df_second.drop(indexNames , inplace=True)\n",
        "\n",
        "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
        "df_table_second = df_second.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
        "df_table_second[\"food\"] = \"food\"\n",
        "df_table_second = df_table_second.truncate(before=-1, after=15) # Fist 15 Choice\n",
        "df_table_second"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "id": "h2N296dlpJ4G"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "second_choice = nx.from_pandas_edgelist(df_table_second, source = 'food', target = \"items\", edge_attr = True)\n",
        "pos = nx.spring_layout(second_choice)\n",
        "nx.draw_networkx_nodes(second_choice, pos, node_size = 12500, node_color = \"honeydew\")\n",
        "nx.draw_networkx_edges(second_choice, pos, width = 3, alpha = 0.6, edge_color = 'black')\n",
        "nx.draw_networkx_labels(second_choice, pos, font_size = 18, font_family = 'sans-serif')\n",
        "plt.rcParams['figure.figsize'] = (20, 20)\n",
        "plt.axis('off')\n",
        "plt.grid()\n",
        "plt.title('Top 15 Second Choices', fontsize = 25)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EQvfCKbpJ4G"
      },
      "source": [
        "***- Seçim Analizi / Müşterilerin Üçüncü Tercihleri***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "id": "v0hIhCZQpJ4G"
      },
      "outputs": [],
      "source": [
        "# 1. Gather Only Third Choice of Each Transaction into Numpy Array\n",
        "## For Column \"2\"\n",
        "transaction = []\n",
        "for i in range(0, data.shape[0]):\n",
        "    transaction.append(data.values[i,2])\n",
        "\n",
        "transaction = np.array(transaction)\n",
        "\n",
        "# 2. Transform Them a Pandas DataFrame\n",
        "df_third = pd.DataFrame(transaction, columns=[\"items\"]) # Transaction Item Name\n",
        "df_third[\"incident_count\"] = 1 # Put 1 to Each Item For Making Countable Table, Group By Will Be Done Later On\n",
        "\n",
        "# 3. Delete NaN Items from Dataset\n",
        "indexNames = df_third[df_third['items'] == \"nan\" ].index\n",
        "df_third.drop(indexNames , inplace=True)\n",
        "\n",
        "# 4. Final Step: Make a New Appropriate Pandas DataFrame for Visualizations  \n",
        "df_table_third = df_third.groupby(\"items\").sum().sort_values(\"incident_count\", ascending=False).reset_index()\n",
        "df_table_third[\"food\"] = \"food\"\n",
        "df_table_third = df_table_third.truncate(before=-1, after=15) # Fist 15 Choice\n",
        "df_table_third"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQQvNOqppJ4G"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure(data=[go.Bar(x=df_table_third[\"items\"], y=df_table_third[\"incident_count\"],\n",
        "            hovertext=df_table_third[\"items\"], text=df_table_third[\"incident_count\"], textposition=\"outside\")])\n",
        "\n",
        "fig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n",
        "                  marker_line_width=1.5, opacity=0.65)\n",
        "fig.update_layout(title_text=\"Customers' Third Choices\", template=\"plotly_dark\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwaebk1wpJ4G"
      },
      "source": [
        "# 4. Veri Ön işleme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3r_qS2dpJ4H"
      },
      "source": [
        "***Apriori algoritmasını kullanabilmek ve en sık öğe kümelerini elde edebilmek için veri kümemizi satırların işlem, sütunların ise ürün olduğu 1 – 0 matrisine dönüştürmemiz gerekir. Bu matriste, o işlemde ürün alınmışsa “1”, o işlemde ürün satın alınmamışsa “0” kodlanmalıdır. Bu ön işleme algoritmanın kullanımı için gereklidir.***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBN6HSx0pJ4H"
      },
      "outputs": [],
      "source": [
        "# Transform Every Transaction to Seperate List & Gather Them into Numpy Array\n",
        "\n",
        "transaction = []\n",
        "for i in range(data.shape[0]):\n",
        "    transaction.append([str(data.values[i,j]) for j in range(data.shape[1])])\n",
        "    \n",
        "transaction = np.array(transaction)\n",
        "transaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iseh9P64pJ4H"
      },
      "outputs": [],
      "source": [
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transaction).transform(transaction)\n",
        "dataset = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Do85qgJ1pJ4H"
      },
      "outputs": [],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa2nK-TfpJ4I"
      },
      "source": [
        "***Şu anda 121 sütunumuz/özelliğimiz var. 121 özelliğinden en sık görülen öğe kümelerini çıkarmak, başlangıç için zorlayıcı olacaktır*** <br>\n",
        "***Bu nedenle, Bölüm-3'te zaten gösterilen İlk 50 öğe ile başlayacağız***\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrzxKCCgpJ4I"
      },
      "outputs": [],
      "source": [
        "first50 = df_table[\"items\"].head(50).values # Select Top50\n",
        "dataset = dataset.loc[:,first50] # Extract Top50\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpzrbyhxpJ4I"
      },
      "outputs": [],
      "source": [
        "dataset.columns\n",
        "# We extracted first 50 column successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imIRomJlpJ4I"
      },
      "outputs": [],
      "source": [
        "# Convert dataset into 1-0 encoding\n",
        "\n",
        "def encode_units(x):\n",
        "    if x == False:\n",
        "        return 0 \n",
        "    if x == True:\n",
        "        return 1\n",
        "    \n",
        "dataset = dataset.applymap(encode_units)\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMQ51JIfpJ4J"
      },
      "source": [
        "# 5. Algoritmanın Uygulaması"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TszIChbopJ4J"
      },
      "source": [
        "## 5.1. Birliktelik Kurallarının Temel Kavramları / Apriori Algoritması\n",
        "\n",
        "X: 1.ürün Y: 2.ürün N: Toplam Alışveriş\n",
        "\n",
        "**- Destek (Support) : Ürünlerin Birlikte Geçme Olasılığı**\n",
        "\n",
        "Support(X, Y) = Freq(X,Y)/N\n",
        "\n",
        "(X ve Y farklı ürünlerinin birlikte geçme frekansı / Toplam Alışveriş)\n",
        "\n",
        "Support değerini hesaplama amacımız eşik değeri belirlemek. Veri setine bakıldığında bir çok ürün beraber görülebilir eşik değerinin altında kalan ürünlerde eleme yapacağız.\n",
        "\n",
        "**- Güven (Confidence) : X’i Alanların Y’yi Alma Olasılığı**\n",
        "\n",
        "Confidence(X, Y) = Freq(X,Y)/Freq(X)\n",
        "\n",
        "(X ve Y farklı ürünlerinin birlikte geçme frekansı / X’in gözlenme frekansı)\n",
        "\n",
        "Analiz yapıldığında ister support değerine göre ister confidence değerine göre eşik değeri belirlenebilir. \n",
        "\n",
        "Eşik değerini gerçek hayat verilerinde çok az alabiliriz.\n",
        "\n",
        "**- Lift = Support(X,Y)/(Support(X)*Support(Y))**\n",
        "\n",
        "X ürünü alanların Y ürünü satın alması şu kadar kat artıyor yorumu vardır."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtUMHTc-pJ4L"
      },
      "source": [
        "## 5.2. Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfyZMDtqpJ4L"
      },
      "source": [
        "**Birliktelik Kuralları Öğrenme uygulamaları için en yaygın kullanılan kitaplık 'Mlxtend'dir. Biz de o kütüphaneyi kullanacağız.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkqvtnRopJ4L"
      },
      "outputs": [],
      "source": [
        "# Extracting the most frequest itemsets via Mlxtend.\n",
        "# The length column has been added to increase ease of filtering.\n",
        "\n",
        "frequent_itemsets = apriori(dataset, min_support=0.01, use_colnames=True)\n",
        "\n",
        "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
        "frequent_itemsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z06Bz7YzpJ4L"
      },
      "source": [
        "***Öğe kümelerini aşağıdaki gibi kolayca keşfedebiliriz***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQqUS8SmpJ4L"
      },
      "outputs": [],
      "source": [
        "frequent_itemsets[ (frequent_itemsets['length'] == 2) &\n",
        "                   (frequent_itemsets['support'] >= 0.05) ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXq9QmtUpJ4L"
      },
      "outputs": [],
      "source": [
        "frequent_itemsets[ (frequent_itemsets['length'] == 3) ].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41M_le-hpJ4M"
      },
      "source": [
        "***Şimdi, kural oluşturmada çıkarılan sık öğe kümelerini kullanacağız.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v6m5laVpJ4M"
      },
      "outputs": [],
      "source": [
        "# We can create our rules by defining metric and its threshold.\n",
        "\n",
        "# For a start, \n",
        "#      We set our metric as \"Lift\" to define whether antecedents & consequents are dependent our not.\n",
        "#      Treshold is selected as \"1.2\" since it is required to have lift scores above than 1 if there is dependency.\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1.2)\n",
        "\n",
        "rules[\"antecedents_length\"] = rules[\"antecedents\"].apply(lambda x: len(x))\n",
        "rules[\"consequents_length\"] = rules[\"consequents\"].apply(lambda x: len(x))\n",
        "\n",
        "rules.sort_values(\"lift\",ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPe_sAUNpJ4M"
      },
      "source": [
        "***Yukarıdaki tabloya göre, lift puanı eşiğin yaklaşık 2.5 katı olduğu ve güven puanının umut verici (%32) olması nedeniyle (ot-biber) ve (dana kıyma) arasındaki bağımlılığın yüksek olduğunu rahatlıkla söyleyebiliriz.***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnBn78yipJ4M"
      },
      "source": [
        "***Verilerden daha fazla içgörü elde etmek için güvene bakalım!***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "701XprwdpJ4M"
      },
      "outputs": [],
      "source": [
        "# Sort values based on confidence\n",
        "\n",
        "rules.sort_values(\"confidence\",ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wofPW4fRpJ4M"
      },
      "source": [
        "- ***Yukarıdaki tabloya göre (yumurta, kıyma) alan müşterilerin %50 olasılıkla (güven) ile (maden suyu) alması beklenmektedir. Lift puanı da bu hipotezi destekliyor***\n",
        "- ***Satışları artırmak için onları yakın tutmak daha iyi olur!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51_cws97pJ4N"
      },
      "source": [
        "***Veri setinde en çok talep edilen ürün maden suyu olduğu için ilişkilendirme sonuçlarına ağırlıklı olarak maden suyu hakimdir. Bu nedenle, daha fazla içgörü elde etmek için maden suyu hariç bir güven tablosu oluşturmak daha iyidir***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TtxPV1gpJ4N"
      },
      "outputs": [],
      "source": [
        "rules[~rules[\"consequents\"].str.contains(\"mineral water\", regex=False) & \n",
        "      ~rules[\"antecedents\"].str.contains(\"mineral water\", regex=False)].sort_values(\"confidence\", ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOkgerBdpJ4N"
      },
      "source": [
        "***Yukarıdaki maden suyu hariç tutulan tabloya göre kıyma ile spagetti, kırmızı şarap ve spagetti arasında önemli bir ilişki olduğunu söyleyebiliriz. Lift puanları da bunu destekliyor***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqyWzw_mpJ4N"
      },
      "source": [
        "***Fark etmiş olabileceğiniz gibi hem maden suyu dahil hem de hariç tablosunda kıyma en üstte. Bu nedenle, kıyma ile ilgili yeni ilişkiler yakalamak ve satışları artırmak için kıymanın öncül olduğu ilişkilere bakalım.***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoJgrdSDpJ4N"
      },
      "outputs": [],
      "source": [
        "rules[rules[\"antecedents\"].str.contains(\"ground beef\", regex=False) & rules[\"antecedents_length\"] == 1].sort_values(\"confidence\", ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xHO5os7pJ4N"
      },
      "source": [
        "- ***Güven ve lift puanı yüksek birçok ilişki\n",
        " vardır. Doğru yoldayız!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Arb5dkTdpJ4N"
      },
      "source": [
        "# 6. Sonuçlar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFhxTg4-pJ4O"
      },
      "source": [
        "***Yukarıdaki incelemelerde gördüğünüz gibi, algoritmanın ve mlxtend kitaplığının esnekliği yüksektir, bu nedenle farklı yönleri kolayca araştırabilir ve verilerden yeni ilişkilendirmeler elde edebiliriz. Bu nedenle, diğer ürünler (Top50'nin geri kalanı) hesaplamaya dahil edilerek veya kriter eşiği değiştirilerek araştırmalar daha ayrıntılı hale getirilebilir. Bununla birlikte, birliktelik kuralı öğrenme yinelemeli bir şemaya sahip olduğundan, verileri anlama ve yorumlama becerileri ve etkinlikleri gerçekten önemlidir. Bu durumda, doğru yolda olduğumuzdan emin olmak için veri görselleştirme ve/veya veri temizleme (gerekirse) adımlarına yeterince önem vermeliyiz.***"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YfES0gMV2AyQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Day8_UnsupervisedLearning_association_rule_based_learning_explained_Demo3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}