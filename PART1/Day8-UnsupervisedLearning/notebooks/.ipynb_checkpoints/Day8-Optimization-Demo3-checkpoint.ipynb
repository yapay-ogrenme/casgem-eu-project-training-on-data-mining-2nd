{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VVcli7YBfox"
   },
   "source": [
    "# Optimizasyon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMoa-mvrt1vX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjUh2XOFf4W9"
   },
   "outputs": [],
   "source": [
    "def plot_result(history, name):\n",
    "  pd.DataFrame(history.history).plot()\n",
    "  plt.grid(True)\n",
    "  #plt.gca().set_ylim(0, 1)\n",
    "  plt.title(name)\n",
    "  plt.show()\n",
    "\n",
    "def tune_opt_model(optimizer, epochs):\n",
    "  model = keras.models.Sequential()\n",
    "  \n",
    "  model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "  for n_layers in (300, 100, 50, 50, 50):\n",
    "    model.add(keras.layers.Dense(n_layers, activation ='relu', kernel_initializer=\"he_normal\"))\n",
    "\n",
    "  model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "  \n",
    "  start_time = time.time()\n",
    "\n",
    "  history = model.fit(X_train_full, y_train_full, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "  return history\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BU19SVMBfVG"
   },
   "source": [
    "## Sınıflandırma görevi\n",
    "\n",
    "ReLU Aktivasyon fonksiyonunun kullanılması (%86,72 Tren seti; %86,37 Test seti; 99,76 saniye)\n",
    "\n",
    "**Optimizasyon Ayarları**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCOCGlfvB6bN"
   },
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYxLEovYJ3Nc"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, let's see of this improve the model performance nd running time\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.SGD(lr=1e-3)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_SGD = history.history[\"loss\"]\n",
    "val_loss_SGD = history.history[\"val_loss\"]\n",
    "train_acc_SGD = history.history[\"accuracy\"]\n",
    "val_acc_SGD = history.history[\"val_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "35T6fbmZv2Lv"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, SGD(lr=0.001, momentum=0.9) optimizer\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_mom = history.history[\"loss\"]\n",
    "val_loss_mom = history.history[\"val_loss\"]\n",
    "train_acc_mom = history.history[\"accuracy\"]\n",
    "val_acc_mom = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and SDG (lr=0.001, momentum=0.9) optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G5NO1KVF9nc5"
   },
   "outputs": [],
   "source": [
    "epoch_no = list(range(1,41))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid(True)\n",
    "plt.plot(epoch_no, train_loss_SGD, marker = 'x')\n",
    "plt.plot(epoch_no, train_loss_mom)\n",
    "plt.plot(epoch_no, train_loss_SGD, marker = 'x')\n",
    "plt.plot(epoch_no, train_acc_mom)\n",
    "plt.legend([\"SGD Loss\", \"Momentum Loss\",\"SGD Accuracy\", \"Momentum Accuracy\"])\n",
    "plt.xlabel('Number of epochs')\n",
    "#plt.ylim((0.2,1))\n",
    "plt.title(\"Compare SDG and Momentum\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lbqPWavDgCZ"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, SGD(lr=0.001, momentum=0.9) optimizer with nesterov is activated \n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9,nesterov=True)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_NAG = history.history[\"loss\"]\n",
    "val_loss_NAG = history.history[\"val_loss\"]\n",
    "train_acc_NAG = history.history[\"accuracy\"]\n",
    "val_acc_NAG = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and SDG (lr=0.001, momentum=0.9, nesterov=True) optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBdM8QjDD4cR"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, AdaGrad optimizer\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.Adagrad(lr=0.001)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_adagrad = history.history[\"loss\"]\n",
    "val_loss_adagrad = history.history[\"val_loss\"]\n",
    "train_acc_adagrad = history.history[\"accuracy\"]\n",
    "val_acc_adagrad = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and AdaGrad optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLvlSWW2FJTH"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, RMSProp optimizer\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.99)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_rmsprop = history.history[\"loss\"]\n",
    "val_loss_rmsprop = history.history[\"val_loss\"]\n",
    "train_acc_rmsprop = history.history[\"accuracy\"]\n",
    "val_acc_rmsprop = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and RMSProp optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41DFwB24-fuJ"
   },
   "outputs": [],
   "source": [
    "epoch_no = list(range(1,41))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid(True)\n",
    "plt.plot(epoch_no, train_loss_adagrad, marker = 'x')\n",
    "plt.plot(epoch_no, train_loss_rmsprop)\n",
    "plt.plot(epoch_no, train_acc_adagrad, marker = 'x')\n",
    "plt.plot(epoch_no, train_acc_rmsprop)\n",
    "plt.legend([\"Adagrad Loss\", \"RMSprop Loss\",\"Adagrad Accuracy\", \"RMSprop Accuracy\"])\n",
    "plt.xlabel('Number of epochs')\n",
    "#plt.ylim((0.2,1))\n",
    "plt.title(\"Compare Adagrad and RMSprop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAJlxoWHFlzz"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Adam optimizer\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_adam = history.history[\"loss\"]\n",
    "val_loss_adam = history.history[\"val_loss\"]\n",
    "train_acc_adam = history.history[\"accuracy\"]\n",
    "val_acc_adam = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and Adam optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GbGZgMEN-5KT"
   },
   "outputs": [],
   "source": [
    "epoch_no = list(range(1,41))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.grid(True)\n",
    "plt.plot(epoch_no, train_loss_adagrad, marker = 'x', color=\"#070bf2\")\n",
    "plt.plot(epoch_no, train_loss_rmsprop, marker = 'o', color=\"#5fd406\")\n",
    "plt.plot(epoch_no, train_loss_adam, marker = 'v', color=\"#fc0808\")\n",
    "plt.plot(epoch_no, train_acc_adagrad, color=\"#070bf2\")\n",
    "plt.plot(epoch_no, train_acc_rmsprop, color=\"#5fd406\")\n",
    "plt.plot(epoch_no, train_acc_adam, color=\"#fc0808\")\n",
    "plt.legend([\"Adagrad Loss\", \"RMSprop Loss\",\"Adam Loss\", \"Adagrad Accuracy\", \"RMSprop Accuracy\", \"Adam Accuracy\"])\n",
    "plt.xlabel('Number of epochs')\n",
    "#plt.ylim((0.2,1))\n",
    "plt.title(\"Compare Adagrad, RMSprop and Adam\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxlZ8BDnHpTc"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Adamax optimizer\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_adamax = history.history[\"loss\"]\n",
    "val_loss_adamax = history.history[\"val_loss\"]\n",
    "train_acc_adamax = history.history[\"accuracy\"]\n",
    "val_acc_adamax = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and Adamax optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agBk7U8pTBQ1"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Nadam optimizer\n",
    "tf.random.set_seed(50)\n",
    "np.random.seed(50)\n",
    "\n",
    "optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history = tune_opt_model(optimizer=optimizer, epochs = 40)\n",
    "\n",
    "train_loss_nadam = history.history[\"loss\"]\n",
    "val_loss_nadam = history.history[\"val_loss\"]\n",
    "train_acc_nadam = history.history[\"accuracy\"]\n",
    "val_acc_nadam = history.history[\"val_accuracy\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and Nadam optimizer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsncLkYmWCz2"
   },
   "source": [
    "## Regresyon Görevi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOMlFfnaV-rJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n26UpNjkLlgN"
   },
   "outputs": [],
   "source": [
    "def tune_opt_reg(optimizer):\n",
    "  model_default = keras.models.Sequential()\n",
    "  for n_layers in (100, 50, 10, 10, 10):\n",
    "    model_default.add(keras.layers.Dense(n_layers, activation=\"relu\", \n",
    "                                         input_shape=X_train.shape[1:], kernel_initializer='he_normal'))\n",
    "  model_default.add(keras.layers.Dense(1))\n",
    "    \n",
    "  model_default.compile(loss=\"mean_squared_error\",\n",
    "                        optimizer=optimizer)\n",
    "  \n",
    "  start_time = time.time()\n",
    "\n",
    "  history = model_default.fit(X_train, y_train, epochs=40, validation_data=(X_valid, y_valid))\n",
    "  \n",
    "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZG6bqi0hWBmn"
   },
   "outputs": [],
   "source": [
    "# He Initialization with Randomized ReLU activation function\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.SGD(lr=1e-3)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "\n",
    "train_loss_SGD = history.history[\"loss\"]\n",
    "val_loss_SGD = history.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1UekEdLW5BE"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, SGD(lr=0.001, momentum=0.9) optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "plot_result(history, name='He Initialization with ReLU and SGD(lr=0.001, momentum=0.9) optimizer')\n",
    "\n",
    "train_loss_momentum = history.history[\"loss\"]\n",
    "val_loss_momentum = history.history[\"val_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGT-4Cy-XHha"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Nesterov SGD(lr=0.001, momentum=0.9) optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "\n",
    "train_loss_nesterov = history.history[\"loss\"]\n",
    "val_loss_nesterov = history.history[\"val_loss\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and Nesterov SGD(lr=0.001, momentum=0.9) optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2BNEbRQXhZF"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Adagrad optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.Adagrad(lr=0.001)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "train_loss_adagrad = history.history[\"loss\"]\n",
    "val_loss_adagrad = history.history[\"val_loss\"]\n",
    "plot_result(history, name='He Initialization with ReLU and Adagrad optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0K43KYB3XnxG"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, RMSprop optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "\n",
    "train_loss_rmsprop = history.history[\"loss\"]\n",
    "val_loss_rmsprop = history.history[\"val_loss\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and RMSprop optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SfBJTtvX2Di"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Adam optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "train_loss_adam = history.history[\"loss\"]\n",
    "val_loss_adam = history.history[\"val_loss\"]\n",
    "\n",
    "plot_result(history, name='He Initialization with ReLU and Adam optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92BC6gxDX7xv"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Adamax optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "train_loss_adamax = history.history[\"loss\"]\n",
    "val_loss_adamax = history.history[\"val_loss\"]\n",
    "plot_result(history, name='He Initialization with ReLU and Adamax optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2d-e96H2YBaw"
   },
   "outputs": [],
   "source": [
    "# ReLU goes with he initialization, Nadam optimizer\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "history = tune_opt_reg(optimizer=optimizer)\n",
    "train_loss_nadam = history.history[\"loss\"]\n",
    "val_loss_nadam = history.history[\"val_loss\"]\n",
    "plot_result(history, name='He Initialization with ReLU and Nadam optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2uLqy8IhRlR"
   },
   "outputs": [],
   "source": [
    "train_loss = [train_loss_SGD, train_loss_momentum, train_loss_nesterov, train_loss_adagrad, train_loss_rmsprop, train_loss_adam, \n",
    "              train_loss_adamax, train_loss_nadam]\n",
    "epoch_no = list(range(1,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Vc_LwfHdveV"
   },
   "outputs": [],
   "source": [
    "plt.plot(epoch_no, train_loss_SGD)\n",
    "plt.plot(epoch_no, train_loss_momentum)\n",
    "plt.legend([\"train_loss_SGD\", \"train_loss_momentum\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDLKFhsxhzSG"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "for opt in train_loss:\n",
    "  plt.plot(epoch_no, opt)\n",
    "plt.legend([\"SGD\", \"Momentum\",\"Nesterov\", \"Adagrad\", \"RMSprop\", \"Adam\", \"Adamax\", \"Nadam\"])\n",
    "plt.set_cmap(\"jet\")\n",
    "plt.ylabel('Train loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylim((0.2,1))\n",
    "plt.title(\"Train loss by different optimizer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEE7ZmJUiTh7"
   },
   "outputs": [],
   "source": [
    "val_loss = [val_loss_SGD, val_loss_momentum, val_loss_nesterov, val_loss_adagrad, val_loss_rmsprop, val_loss_adam, \n",
    "              val_loss_adamax, val_loss_nadam]\n",
    "plt.figure(figsize=(15,5))\n",
    "for opt in val_loss:\n",
    "  plt.plot(epoch_no, opt)\n",
    "plt.legend([\"SGD\", \"Momentum\",\"Nesterov\", \"Adagrad\", \"RMSprop\", \"Adam\", \"Adamax\", \"Nadam\"])\n",
    "plt.ylabel('Validation loss')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylim((0.2,1))\n",
    "plt.title(\"Validation set loss by different optimizer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fAyvRLcguVS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day8-Optimization-Demo3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
