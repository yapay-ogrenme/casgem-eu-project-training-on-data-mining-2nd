{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIXlDiKAEMyi",
    "papermill": {
     "duration": 0.023705,
     "end_time": "2021-03-05T12:14:00.177525",
     "exception": false,
     "start_time": "2021-03-05T12:14:00.153820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Karar Ağacı\n",
    "\n",
    "Bu Kernel'de Python ve Titanic veri setini kullanan Karar Ağaçlarına bir göz atacağız. \n",
    "\n",
    "Buradaki en doğru Titanic hayatta kalma modeli olması amaçlanmamıştır.\n",
    "\n",
    "Yapılacaklar:\n",
    "\n",
    "- Karar Ağaçları ile Verilerden Öğrenmek\n",
    "- Veri kümesi keşfi ve işleme\n",
    "- Karar Ağaçları için ilgili özellikler\n",
    "- Gini Impurity\n",
    "- Çapraz doğrulama yardımıyla en iyi ağaç derinliğini bulmak\n",
    "- Nihai modeli oluşturma ve görselleştirme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0ed22e93-8f2e-dc75-ab5d-57501c7ff60a",
    "id": "f2wh6rizEMyp",
    "papermill": {
     "duration": 0.02157,
     "end_time": "2021-03-05T12:14:00.221169",
     "exception": false,
     "start_time": "2021-03-05T12:14:00.199599",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Giriş\n",
    "\n",
    "Makine Öğrenimi algoritmalarını uygularken, çözmeye çalıştığımız sorunu daima akılda tutmak çok önemlidir. \n",
    "\n",
    "Çoğu durumda, aradığınız en doğru ve sağlam model olabilir. Ancak bazen mevcut verilerden gerçekten içgörüler elde etmemiz gerekir ve bu durumlarda şeffaf, *Karar Ağaçları* gibi anlaşılması kolay modeller görevimizi büyük ölçüde basitleştirir.\n",
    "\n",
    "Doğrudan bazı görevler için kullanılacak bir model oluşturmamız ve **yalnızca son sonuçlarını göstermemiz gerekiyorsa**, yeterince doğruysa bir tür \"kara kutu\" oluşturmayı gerçekten önemsemiyoruz (Örneğin: görüntü veya konuşma tanıma). Bu nedenle [*Derin Öğrenme*] [1] veya [*Topluluk Öğrenimi*] [2] (cf. [Anisotropik Çekirdek] [3]) gibi gelişmiş teknikler genellikle karmaşık görevler için kullanılır. \n",
    "\n",
    "Ancak KISS prensibini unutmamak gerekiyor! (Basit Tutun, Aptal Olun)! \n",
    "\n",
    "Her zaman karmaşıklık / doğruluk dengesini göz önünde bulundurun: karmaşık teknikler yalnızca önemli iyileştirmeler sağladıkları takdirde kullanılmalıdır. Daha basit modeller de fazla uyuma daha az eğilimlidir ve daha iyi genelleme eğilimindedir.\n",
    "\n",
    "Ancak, **verilerden içgörü elde etmek** için Makine Öğrenimini kullanıyorsak, \"kara kutu\" modelleri neredeyse işe yaramaz ve daha basit, şeffaf tekniklere bağlı kalmak en iyisidir. \n",
    "\n",
    "Müşteri davranışını daha iyi anlamak isteyen bir süpermarket örneğini ele alalım: basit [*Apriori*] [4] algoritması, \"takım elbise satın alan müşterilerin% 80'i kravat da satın aldı\" gibi alakalı bilgileri hızlı bir şekilde sunabilir, böylece bir takım elbise satın alan müşterilere indirim sunarak kravat satışlarını artırılabilir. Elbette, karmaşık bir sınıflandırma algoritması, daha fazla özelliği hesaba katarak kravat satın alan müşterileri belirlemede daha başarılı olacaktır, ancak bu süpermarket için gerçekten yararlı mı?\n",
    "\n",
    "*Karar Ağaçları* da verileri anlamamız gerektiğinde çok yardımcı olabilir. İyi bir örnek, elde edilen ağaçtaki her bir çiçek türünün özelliklerini öğrenebilseydik [sklearn belgeleri] [5] 'de yer alan Iris çiçeklerini sınıflandırmanın geleneksel problemidir. Şeffaflıkları ve nispeten düşük hesaplama maliyetleri göz önüne alındığında, *Karar Ağaçları*, diğer algoritmaları uygulamadan önce verilerinizi keşfetmek için de çok kullanışlıdır. Oluşturulan özelliklerin kalitesini kontrol etmek ve elde edilen ağacı görselleştirerek en alakalı olanları belirlemek için faydalıdırlar.\n",
    "\n",
    "*Karar Ağaçlarının* ana dezavantajları, aşırı uyma eğilimleri, özellikler arasındaki ilişkileri kavrayamamaları ve açgözlü öğrenme algoritmalarının kullanılmasıdır. Bunları [*Rastgele Orman*] [6] 'da kullanmak bu sorunların bazılarının azaltılmasına yardımcı olur.\n",
    "\n",
    "*Karar Ağaçları'na* ve bunların Makine Öğrenmesindeki yerlerine ilişkin bu kısa girişten sonra, bunları Titanik mücadelesine nasıl uygulayacağımızı görelim. İlk olarak, veri setini hazırlayacağız ve en alakalı özellikleri tartışacağız. Daha sonra aşırı uydurmayı önlemek için en iyi ağaç derinliğini bulacağız, son modeli oluşturacağız ve ortaya çıkan ağacın nasıl görselleştirileceğini açıklayacağız.\n",
    "\n",
    "  [1]: https://en.wikipedia.org/wiki/Deep_learning\n",
    "  [2]: https://en.wikipedia.org/wiki/Ensemble_learning\n",
    "  [3]: https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python\n",
    "  [4]: https://en.wikipedia.org/wiki/Apriori_algorithm\n",
    "  [5]: http://scikit-learn.org/stable/modules/tree.html\n",
    "  [6]: https://en.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "af6bb647-50c9-cb5e-5b00-ea49474ff254",
    "id": "RA3hKZmuEMyr",
    "papermill": {
     "duration": 0.021616,
     "end_time": "2021-03-05T12:14:00.264405",
     "exception": false,
     "start_time": "2021-03-05T12:14:00.242789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Titanic veri kümesini hazırlama ##\n",
    "\n",
    "Titanik mücadelesi için *test* veri setindeki bireylerin hayatta kalıp kalmadığını tahmin etmemiz gerekiyor. Ancak şu anki amacımız için, verilerin bize gemi enkazı hakkında ne söyleyebileceğini de bir *Sınıflandırma Ağacı* yardımıyla bulalım. Verileri yükleyelim ve kuş bakışı bir bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MBhnqvHHs2G"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak165DkxHtf_"
   },
   "outputs": [],
   "source": [
    "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part1/Day7-DecisionTree/notebooks\"\n",
    "ROOT_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART1/Day7-DecisionTree/notebooks/\"\n",
    "DATASET_PATH = ROOT_DIR + \"/datasets/titanic/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d66580d1-f255-86b9-e5c0-f012342ab8d8",
    "id": "NAwIUwnYEMyt",
    "papermill": {
     "duration": 2.037403,
     "end_time": "2021-03-05T12:14:02.323436",
     "exception": false,
     "start_time": "2021-03-05T12:14:00.286033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Imports needed for the script\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image as PImage\n",
    "from subprocess import check_call\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# Loading the data\n",
    "df_train = pd.read_csv(DATASET_PATH + 'train.csv')\n",
    "df_test = pd.read_csv(DATASET_PATH + 'test.csv')\n",
    "\n",
    "# Kolay erişim için test yolcu kimliklerimizi saklayın\n",
    "PassengerId = df_test['PassengerId']\n",
    "\n",
    "# Eğitim kümesine genel bakış\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c395abd-2eca-0067-23a3-4356a25703ea",
    "id": "p5fvq3_eEMyv",
    "papermill": {
     "duration": 0.022658,
     "end_time": "2021-03-05T12:14:02.370718",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.348060",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Bu genel bakış sayesinde, veri setimizin bazı işlemlere ihtiyacı olduğunu görebiliriz. Survived sınıfı zaten ikili formattadır, bu nedenle ek formatlamaya gerek yoktur, ancak Ad, Bilet veya Kabin gibi özelliklerin çözmeye çalıştığımız soruna göre uyarlanması gerekir ve ayrıca mevcut olanı birleştirerek veya yeniden gruplandırarak bazı yeni özellikleri tasarlayabiliriz. Bu konuda zaten genişletilmiş çalışmalar var, bu yüzden sadece en iyi yaklaşımlardan birini kullanıyoruz.[1],[2],[3]\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/sinakhorami/titanic/titanic-best-working-classifier\n",
    "  [2]: https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python\n",
    "  [3]: https://www.kaggle.com/mrisdal/titanic/exploring-survival-on-the-titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72063fe1-8b92-850b-3ede-5e030c7429ae",
    "id": "abyb9Fv5EMyw",
    "papermill": {
     "duration": 0.114023,
     "end_time": "2021-03-05T12:14:02.507845",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.393822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Daha sonra ilginç özellikleri araştırırken ihtiyaç duymamız ihtimaline karşı orijinal veri kümesini kopyalayın\n",
    "# UYARI: Sadece referans vermek yerine veri çerçevesini gerçekten kopyalamaya dikkat edin\n",
    "# \"original_train = train\", train değişkenine bir referans oluşturacak ('train'deki değişiklikler' original_train 'için geçerli olacaktır)\n",
    "original_train = df_train.copy()# 'Copy ()' kullanılması, aynı değerlerle farklı bir nesne oluşturarak veri kümesini klonlamaya izin verir\n",
    "\n",
    "full_data = [df_train, df_test]\n",
    "\n",
    "# Titanik'te bir yolcunun kabini olup olmadığını söyleyen özellik\n",
    "df_train['Has_Cabin'] = df_train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "df_test['Has_Cabin'] = df_test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# SibSp ve Parch'ın bir kombinasyonu olarak FamilySize adlı yeni özellik oluşturun\n",
    "for dataset in full_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Yeni özellik oluşturma FamilySize'dan yararlanılacak IsAlone\n",
    "for dataset in full_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Embarked sütunundaki tüm BOŞLUKLARI kaldırın\n",
    "for dataset in full_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Fare sütunundaki tüm BOŞLUKLARI kaldırın\n",
    "for dataset in full_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(df_train['Fare'].median())\n",
    "\n",
    "# Age sütunundaki tüm BOŞLUKLARI kaldırın\n",
    "for dataset in full_data:\n",
    "    age_avg = dataset['Age'].mean()\n",
    "    age_std = dataset['Age'].std()\n",
    "    age_null_count = dataset['Age'].isnull().sum()\n",
    "    age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "    # Next line has been improved to avoid warning\n",
    "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "# Yolcu isimlerinden başlıkları çıkarmak için işlevi tanımlayın\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "   # Başlık varsa, çıkartın ve iade edin.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "    \n",
    "# Tüm yaygın olmayan başlıkları tek bir gruplama \"Rare\" olarak gruplandırın\n",
    "for dataset in full_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in full_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0486bde8-a09f-93c6-832d-c5c9760e2f6e",
    "id": "JtXHDjUZEMyy",
    "papermill": {
     "duration": 0.036379,
     "end_time": "2021-03-05T12:14:02.567840",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.531461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Özellik seçimi: artık ilgili bilgileri içermeyen değişkenleri kaldırın\n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "df_train = df_train.drop(drop_elements, axis = 1)\n",
    "df_test  = df_test.drop(drop_elements, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abef639b-2b31-4209-20ef-d8ba15c4de74",
    "id": "KL-HFRaREMyz",
    "papermill": {
     "duration": 0.022798,
     "end_time": "2021-03-05T12:14:02.613964",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.591166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## İşlenmiş verileri görselleştirme ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b587a7d3-36be-408e-0dee-6fd292e9621b",
    "id": "xxwsiJBPEMy0",
    "papermill": {
     "duration": 0.039353,
     "end_time": "2021-03-05T12:14:02.676501",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.637148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cc298a8b-1fb3-21f9-6437-1fd6cd93d35e",
    "id": "mOMHVTEjEMy1",
    "papermill": {
     "duration": 0.024003,
     "end_time": "2021-03-05T12:14:02.725190",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.701187",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Veri kümemiz, yalnızca sayısal değerler ve potansiyel olarak anlamlı özelliklerle artık eskisinden çok daha temiz. Şimdi veri setimizdeki tüm öznitelikler arasındaki Pearson Korelasyonunu çizerek değişkenlerimiz arasındaki ilişkiyi inceleyelim : [1]\n",
    "\n",
    "\n",
    "  [1]: https://www.kaggle.com/arthurtok/titanic/introduction-to-ensembling-stacking-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d289fd14-d3a9-6131-3b3a-058edced24f1",
    "id": "6im9Kz_VEMy2",
    "papermill": {
     "duration": 1.155071,
     "end_time": "2021-03-05T12:14:03.904615",
     "exception": false,
     "start_time": "2021-03-05T12:14:02.749544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(df_train.astype(float).corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "06e3df1e-de4c-bff7-e364-268403cc2da3",
    "id": "riQpiDkOEMy2",
    "papermill": {
     "duration": 0.026875,
     "end_time": "2021-03-05T12:14:03.958995",
     "exception": false,
     "start_time": "2021-03-05T12:14:03.932120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Bu ısı haritası, ilk gözlem olarak çok kullanışlıdır çünkü her özelliğin tahmini değeri hakkında kolayca fikir edinebilirsiniz. \n",
    "\n",
    "Bu durumda, *Cinsiyet* ve *Başlık*, sınıfla (*Hayatta Kalan*) en yüksek korelasyonları (mutlak olarak) gösterir: Sırasıyla 0,54 ve 0,49. Ancak her ikisi arasındaki mutlak korelasyon da çok yüksektir (0.86, veri setimizdeki en yüksek değer), bu nedenle muhtemelen aynı bilgiyi taşıyorlar ve ikisini aynı model için girdi olarak kullanmak iyi bir fikir olmaz. Nihai karar ağacımızdaki ilk düğüm için bunlardan biri kullanılacak olan yüksek şanslar, bu yüzden önce bu özellikleri daha ayrıntılı inceleyelim ve karşılaştıralım."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "28861e40-1c0b-d4f7-312b-e7f64cb3e5ae",
    "id": "GGAUEtS5EMy3",
    "papermill": {
     "duration": 0.02867,
     "end_time": "2021-03-05T12:14:04.015509",
     "exception": false,
     "start_time": "2021-03-05T12:14:03.986839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*Title* VS *Sex*\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f9f52f7-c758-0614-1c05-c0e4d6a17a44",
    "id": "0d1wye3zEMy3",
    "papermill": {
     "duration": 0.027214,
     "end_time": "2021-03-05T12:14:04.071301",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.044087",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Özellikleri ve sınıfla olan ilişkilerini gruplayarak ve her grup için bazı temel istatistikleri hesaplayarak kolayca karşılaştırabilirsiniz. Aşağıdaki kod bunu tam olarak bir satırda yapar ve ikili bir sınıfla çalışırken her bir metriğin anlamını açıklar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ce843f51-6f28-ef63-5f21-5f6bf8802e7f",
    "id": "8hOgSt_eEMy4",
    "papermill": {
     "duration": 0.055302,
     "end_time": "2021-03-05T12:14:04.154162",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.098860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[['Title', 'Survived']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n",
    "\n",
    "# \"Survived\" bir ikili sınıf (0 veya 1) olduğundan, Title özelliğine göre gruplandırılan bu ölçümler şunları temsil eder:\n",
    "     # MEAN: hayatta kalma oranı\n",
    "     # COUNT: toplam gözlem\n",
    "     # SUM: hayatta kalan insanlar\n",
    "\n",
    "# title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05abd10a-b698-dc8a-f745-59436608e38c",
    "id": "tzQ1XTEgEMy5",
    "papermill": {
     "duration": 0.05193,
     "end_time": "2021-03-05T12:14:04.234721",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.182791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).agg(['mean', 'count', 'sum'])\n",
    "\n",
    "# Survived bir ikili özellik olduğundan, Sex özelliğine göre gruplandırılan bu ölçümler şunları temsil eder:\n",
    "     # MEAN: hayatta kalma oranı\n",
    "     # COUNT: toplam gözlem\n",
    "     # SUM: hayatta kalan insanlar \n",
    "    \n",
    "# sex_mapping = {{'female': 0, 'male': 1}} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e72f4218-550f-342c-65fc-ca3bc0e0d336",
    "id": "qhSiX3LMEMy5",
    "papermill": {
     "duration": 0.029544,
     "end_time": "2021-03-05T12:14:04.293319",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.263775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Veriler, genel olarak erkeklerden (% 18.89) daha az 'Mr' (% 15,67) hayatta kaldığını gösteriyor: * Bu nedenle, amacımız için *Title* özelliğinin *Sex* den daha yararlı görünüyor. Bunun nedeni, *Title*'ın çoğu durumda dolaylı olarak * Sex * hakkında bilgi içermesi olabilir. Bunu doğrulamak için, orijinal eğitim verilerinden yaptığımız kopyayı eşleştirmeler olmadan kullanabilir ve *Title* göre gruplanmış *Sex*  dağılımını kontrol edebiliriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a9e03eff-7835-6804-ee13-3cf3f7a80652",
    "id": "0SDCq6ByEMy6",
    "papermill": {
     "duration": 0.065568,
     "end_time": "2021-03-05T12:14:04.388883",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.323315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Her başlık için cinsiyet dağılımını kontrol etmek için 'orijinal_train' veri çerçevemizi kullanalım.\n",
    "# Original_train veri kümesindeki değişiklikleri önlemek için tekrar copy () kullanıyoruz\n",
    "\n",
    "title_and_sex = original_train.copy()[['Name', 'Sex']]\n",
    "\n",
    "# Create 'Title' feature\n",
    "title_and_sex['Title'] = title_and_sex['Name'].apply(get_title)\n",
    "\n",
    "# Map 'Sex' as binary feature\n",
    "title_and_sex['Sex'] = title_and_sex['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Table with 'Sex' distribution grouped by 'Title'\n",
    "title_and_sex[['Title', 'Sex']].groupby(['Title'], as_index=False).agg(['mean', 'count', 'sum'])\n",
    "\n",
    "# Sex ikili bir özellik olduğundan, Title özelliğine göre gruplandırılan bu ölçümler şunları temsil eder:\n",
    "    # MEAN: erkeklerin yüzdesi\n",
    "    # COUNT: toplam gözlem\n",
    "    # SUM: erkeklerin sayısı"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "05cb2f35-88cd-35ed-3110-370eb5fa6188",
    "id": "_y3qXw86EMy6",
    "papermill": {
     "duration": 0.029357,
     "end_time": "2021-03-05T12:14:04.448870",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.419513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tek bir gözlem ('Dr' başlıklı bir kadın) haricinde, belirli bir Title için tüm gözlemlerin aynı Sex'i paylaştığını görüyoruz. Bu nedenle Title özelliği, Sex'te bulunan tüm bilgileri yakalar. Ek olarak, Title, bireylerin yaş, sosyal sınıf, kişilik, ... gibi diğer özelliklerini yakalayarak görevimiz için daha değerli olabilir.\n",
    "\n",
    "Nadir başlıkları tek bir kategori altında toplayarak, Cinsiyet ile ilgili bazı bilgileri kaybettiğimiz doğrudur. \"Nadir Erkek\" ve \"Nadir Kadın\" olmak üzere iki kategori oluşturabiliriz, ancak \"Rare\" Başlıkların düşük olması nedeniyle bu ayrım neredeyse anlamsız olacaktır (% 2.6, 891 örnekten 23'ü).\n",
    "\n",
    "Sex ve Title özelliklerinin bu derinlemesine analizi sayesinde, Sex özelliğinin Survived sınıfıyla korelasyonu daha yüksek olsa bile, Unvanın Sex bilgilerini taşıdığı için daha zengin bir özellik olduğunu ancak başka özellikler de eklediğini gördük. Bu nedenle, Title büyük olasılıkla son karar ağacımızdaki ilk özellik olacak ve bu ilk bölünmeden sonra Sex'i işe yaramaz hale getirecek.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc88647a-68c0-b399-0b01-bae0064b9a91",
    "id": "JAAbfFTPEMy7",
    "papermill": {
     "duration": 0.031718,
     "end_time": "2021-03-05T12:14:04.511688",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.479970",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Gini Impurity ##\n",
    "\n",
    "* Karar Ağaçları * ile çalışmaya başlamadan önce kısaca nasıl çalıştıklarını açıklayalım. Öğrenme algoritmalarının amacı her zaman ağacın her bir düğümü için en iyi bölünmeyi bulmaktır. Ancak belirli bir bölünmenin \"iyiliğini\" ölçmek öznel bir sorudur, bu nedenle pratikte bölünmeleri değerlendirmek için farklı ölçütler kullanılır. Yaygın olarak kullanılan bir ölçü [Information Gain] [1] 'dır. Diğer bir yaygın ölçü olan [Gini Impurity] [2] aletlerini kullanacağımız * sklearn * kitaplığı, şimdi bunu açıklayalım.\n",
    "\n",
    "Gini Impurity, bir dizi öğenin bozukluğunu ölçer. Bir elemanın kümedeki tüm sınıfların dağılımına göre rastgele etiketlendiği varsayılarak bir elemanın yanlış etiketlenmesi olasılığı olarak hesaplanır. * Karar Ağaçları *, ortaya çıkan iki düğümde Gini İmpurity en çok azaltan ayrımı bulmaya çalışacaktır. Titanic örnek için şu şekilde hesaplanabilir.\n",
    "\n",
    "\n",
    "  [1]: https://en.wikipedia.org/wiki/Information_gain_in_decision_trees\n",
    "  [2]: https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1efa362d-39b9-a193-a35d-051fdfafb35f",
    "id": "pkBhhBXAEMy7",
    "papermill": {
     "duration": 0.03933,
     "end_time": "2021-03-05T12:14:04.581510",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.542180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to calculate Gini Impurity\n",
    "def get_gini_impurity(survived_count, total_count):\n",
    "    survival_prob = survived_count/total_count\n",
    "    not_survival_prob = (1 - survival_prob)\n",
    "    random_observation_survived_prob = survival_prob\n",
    "    random_observation_not_survived_prob = (1 - random_observation_survived_prob)\n",
    "    mislabelling_survided_prob = not_survival_prob * random_observation_survived_prob\n",
    "    mislabelling_not_survided_prob = survival_prob * random_observation_not_survived_prob\n",
    "    gini_impurity = mislabelling_survided_prob + mislabelling_not_survided_prob\n",
    "    return gini_impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0cecfd1b-5bbc-772b-042c-ad08049ac233",
    "id": "h3Lpt2DQEMy8",
    "papermill": {
     "duration": 0.029515,
     "end_time": "2021-03-05T12:14:04.643234",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.613719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Örnek olarak * Sex * ve * Title * özelliklerimizi kullanalım ve her bir bölünmenin genel ağırlıklı Gini Impurity'i ne kadar azaltacağını hesaplayalım. İlk olarak, eğitim veri setimizdeki 891 gözlemin tamamını içeren başlangıç düğümünün Gini Impurity hesaplamamız gerekir. Yalnızca 342 gözlem hayatta kaldığından, hayatta kalma olasılığı yaklaşık% 38,38'dir (342/891)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d752e767-c0df-3eea-f587-e4d21a09128e",
    "id": "MDTlq7VsEMy8",
    "papermill": {
     "duration": 0.039965,
     "end_time": "2021-03-05T12:14:04.713613",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.673648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gini Impurity of starting node\n",
    "gini_impurity_starting_node = get_gini_impurity(342, 891)\n",
    "gini_impurity_starting_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "773177aa-a668-8541-3f03-e0ec7d87fba2",
    "id": "08BpALywEMy9",
    "papermill": {
     "duration": 0.031095,
     "end_time": "2021-03-05T12:14:04.776225",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.745130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Şimdi her iki bölünmeyi de simüle edeceğiz, ortaya çıkan düğümlerin safsızlığını hesaplayacağız ve ardından her bir bölünmenin aslında safsızlığı ne kadar azalttığını ölçmek için bölünmeden sonra ağırlıklı Gini Safsızlığını elde edeceğiz.\n",
    "\n",
    "* Cinsiyete * göre ayrılırsak, aşağıdaki iki düğüme sahip oluruz:\n",
    "\n",
    "  - Erkeklerle düğüm: Sadece 109'u hayatta kalan 577 gözlem\n",
    "  - Kadınlarla düğüm: 233 hayatta kalan 314 gözlem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cd0f8a03-db86-62c2-c88a-2d54de7531bc",
    "id": "s7uMCR8wEMy9",
    "papermill": {
     "duration": 0.049238,
     "end_time": "2021-03-05T12:14:04.863291",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.814053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'Erkek' gözlemleri için düğümde Gini Impurity azalması\n",
    "gini_impurity_men = get_gini_impurity(109, 577)\n",
    "gini_impurity_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "183aa17e-27a9-0fae-35e9-34ff2f8f6c6a",
    "id": "JF3WMZTIEMy-",
    "papermill": {
     "duration": 0.047647,
     "end_time": "2021-03-05T12:14:04.944621",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.896974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 'Kadın' gözlemleri için düğümde Gini Impurity azalması\n",
    "gini_impurity_women = get_gini_impurity(233, 314)\n",
    "gini_impurity_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "60d97095-3d8a-803a-f649-647cfb6f2965",
    "id": "i4bXcknZEMy-",
    "papermill": {
     "duration": 0.041468,
     "end_time": "2021-03-05T12:14:05.017328",
     "exception": false,
     "start_time": "2021-03-05T12:14:04.975860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Düğüm cinsiyete göre bölünürse Gini Impurity azalması\n",
    "men_weight = 577/891\n",
    "women_weight = 314/891\n",
    "weighted_gini_impurity_sex_split = (gini_impurity_men * men_weight) + (gini_impurity_women * women_weight)\n",
    "\n",
    "sex_gini_decrease = weighted_gini_impurity_sex_split - gini_impurity_starting_node\n",
    "sex_gini_decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c2193bce-c628-0154-d205-7f37c985ab35",
    "id": "yE8Fr7N6EMy_",
    "papermill": {
     "duration": 0.038503,
     "end_time": "2021-03-05T12:14:05.094714",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.056211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* Title * == 1 (== Mr) ile bölersek, aşağıdaki iki düğüme sahip oluruz:\n",
    "\n",
    "  - Sadece Mr. olan düğüm: Sadece 81'i hayatta kalan 517 gözlem\n",
    "  - Diğer başlıklara sahip düğüm: 261 hayatta kalan 374 gözlem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a8cf9b6c-5299-e522-07d7-cd9f1914afb8",
    "id": "WIeamt3KEMy_",
    "papermill": {
     "duration": 0.040534,
     "end_time": "2021-03-05T12:14:05.178592",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.138058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Title == 1 == Mr ile gözlemler için düğümde Impurity azalması\n",
    "gini_impurity_title_1 = get_gini_impurity(81, 517)\n",
    "gini_impurity_title_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b0a7c30e-d8d7-9fdb-747e-1187a158051a",
    "id": "a8D5AL1tEMzA",
    "papermill": {
     "duration": 0.040834,
     "end_time": "2021-03-05T12:14:05.251175",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.210341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Title =! 1 =! Mr ile gözlemler için düğümde Impurity azalması\n",
    "gini_impurity_title_others = get_gini_impurity(261, 374)\n",
    "gini_impurity_title_others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8dd27088-768a-b1cd-aa51-0c907e066880",
    "id": "BpYavgTGEMzA",
    "papermill": {
     "duration": 0.042102,
     "end_time": "2021-03-05T12:14:05.325437",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.283335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Düğüm Title == 1 == Mr ile gözlemler için bölünürse, Gini Impurity azalması\n",
    "title_1_weight = 517/891\n",
    "title_others_weight = 374/891\n",
    "weighted_gini_impurity_title_split = (gini_impurity_title_1 * title_1_weight) + (gini_impurity_title_others * title_others_weight)\n",
    "\n",
    "title_gini_decrease = weighted_gini_impurity_title_split - gini_impurity_starting_node\n",
    "title_gini_decrease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d1990369-420d-c755-71e9-5568307559f3",
    "id": "SbCoGsZ8EMzA",
    "papermill": {
     "duration": 0.032243,
     "end_time": "2021-03-05T12:14:05.390106",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.357863",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Title özelliğinin Gini Impurity azaltmada Cinsiyetten biraz daha iyi olduğunu görüyoruz. Bu, önceki analizimizi doğruluyor ve artık Title'ın ilk bölünmede kullanılacağından eminiz. Bu nedenle, bilgiler Title özelliğine zaten dahil edildiği için cinsiyet ihmal edilecektir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a9323d91-0b96-4811-5783-bfe85116a907",
    "id": "GVqKvRU1EMzA",
    "papermill": {
     "duration": 0.032165,
     "end_time": "2021-03-05T12:14:05.454728",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.422563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Çapraz Doğrulama yardımıyla en iyi ağaç derinliğini bulma ##\n",
    "\n",
    "Verileri keşfettikten sonra, çoğunun karar ağacımızla alakalı olabileceğini bulacağız. Bu, her Veri Bilimi projesi için kritik bir noktadır, çünkü çok fazla eğitim verisi kolaylıkla kötü model genellemesine neden olabilir (test / gerçek / görünmeyen gözlemlerde doğruluk). Aşırı uyum (eğitim verilerine aşırı derecede uyarlanmış bir model) yaygın bir nedendir. Diğer durumlarda, çok fazla veri, ya zamanla geliştikleri için ya da yüksek düzeyde ilişkili özellikler, modelin her birinin değerini düzgün bir şekilde yakalamasını engellediği için anlamlı ilişkileri de gizleyebilir.\n",
    "\n",
    "Karar ağaçları söz konusu olduğunda, 'max_depth' parametresi, modelin her bir tahmin için kullanacağı maksimum öznitelik sayısını belirler (veri kümesindeki mevcut özelliklerin sayısına kadar). Bu parametre için en iyi değeri bulmanın iyi bir yolu, mümkün olan tüm derinlikleri yinelemek ve doğruluğu [Çapraz Doğrulama] [1] gibi sağlam bir yöntemle ölçmektir.\n",
    "\n",
    "*Çapraz Doğrulama*, eğitim veri setini belirli sayıda \"kat\" a bölen bir model doğrulama tekniğidir. Her bölüm, eğitim ve test amacıyla farklı veriler kullanır ve modelin her seferinde farklı verilerle eğitilmesine ve test edilmesine olanak tanır. Bu, algoritmanın tüm kıvrımlarda mevcut tüm verilerle eğitilmesine ve test edilmesine izin vererek, herhangi bir bölünme önyargısından kaçınır ve seçilen modelin genelleştirilmesi hakkında iyi bir fikir verir. Ana dezavantajı, *Çapraz Doğrulamanın* modelin her kat için eğitilmesini gerektirmesidir, bu nedenle hesaplama maliyeti, karmaşık modeller veya büyük veri kümeleri için çok yüksek olabilir.\n",
    "\n",
    "\n",
    "  [1]: https://en.wikipedia.org/wiki/Cross-validation_(statistics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "33f3999e-e0da-0e2e-dfa1-7be4824c6a36",
    "id": "7lHr1suPEMzB",
    "papermill": {
     "duration": 0.670553,
     "end_time": "2021-03-05T12:14:06.157631",
     "exception": false,
     "start_time": "2021-03-05T12:14:05.487078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10)            # Desired number of Cross Validation folds\n",
    "accuracies = list()\n",
    "max_attributes = len(list(df_test))\n",
    "depth_range = range(1, max_attributes + 1)\n",
    "\n",
    "# 1'den maksimum özniteliğe maks_depthleri test etme\n",
    "# Uncomment prints for details about each Cross Validation pass\n",
    "for depth in depth_range:\n",
    "    fold_accuracy = []\n",
    "    tree_model = tree.DecisionTreeClassifier(max_depth = depth)\n",
    "    # print(\"Current max depth: \", depth, \"\\n\")\n",
    "    for train_fold, valid_fold in cv.split(df_train):\n",
    "        f_train = df_train.loc[train_fold] # Extract train data with cv indices\n",
    "        f_valid = df_train.loc[valid_fold] # Extract valid data with cv indices\n",
    "\n",
    "        model = tree_model.fit(X = f_train.drop(['Survived'], axis=1), \n",
    "                               y = f_train[\"Survived\"]) # We fit the model with the fold train data\n",
    "                               \n",
    "        valid_acc = model.score(X = f_valid.drop(['Survived'], axis=1), \n",
    "                                y = f_valid[\"Survived\"])# We calculate accuracy with the fold validation data\n",
    "        fold_accuracy.append(valid_acc)\n",
    "\n",
    "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
    "    accuracies.append(avg)\n",
    "    # print(\"Accuracy per fold: \", fold_accuracy, \"\\n\")\n",
    "    # print(\"Average accuracy: \", avg)\n",
    "    # print(\"\\n\")\n",
    "    \n",
    "# Just to show results conveniently\n",
    "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
    "df = df[[\"Max Depth\", \"Average Accuracy\"]]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e98561cf-fceb-792a-49f6-810ef867d650",
    "id": "NI2LHXwTEMzB",
    "papermill": {
     "duration": 0.033031,
     "end_time": "2021-03-05T12:14:06.223964",
     "exception": false,
     "start_time": "2021-03-05T12:14:06.190933",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Bu nedenle, en iyi maksimum derinlik parametresi 3 (10 kat boyunca% 82,8 ortalama doğruluk) gibi görünmektedir ve modeli daha fazla veri ile beslemek, muhtemelen aşırı uydurma nedeniyle en kötü sonuçlara yol açmaktadır. Bu nedenle, son modelimiz için max_depth parametresi olarak 3 kullanacağız."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "035b62df-00f6-ab53-7082-227051ff974e",
    "id": "xaEJiQEoEMzC",
    "papermill": {
     "duration": 0.032884,
     "end_time": "2021-03-05T12:14:06.290219",
     "exception": false,
     "start_time": "2021-03-05T12:14:06.257335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final Tree ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "012339ff-5353-268f-a97b-752aa4aa3602",
    "id": "XL5Odc1pEMzC",
    "papermill": {
     "duration": 0.799028,
     "end_time": "2021-03-05T12:14:07.122755",
     "exception": false,
     "start_time": "2021-03-05T12:14:06.323727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Numpy arrays of train, test and target (Survived) dataframes to feed into our models\n",
    "# Modellerimizi beslemek için Numpy dizileri oluşturalım: eğitim, test ve target (Survived) dataframes\n",
    "y_train = df_train['Survived']\n",
    "x_train = df_train.drop(['Survived'], axis=1).values \n",
    "x_test = df_test.values\n",
    "\n",
    "# Create Decision Tree with max_depth = 3\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "decision_tree.fit(x_train, y_train)\n",
    "\n",
    "# Predicting results for test dataset\n",
    "y_pred = decision_tree.predict(x_test)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": y_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# Export our trained model as a .dot file\n",
    "with open(\"tree1.dot\", 'w') as f:\n",
    "     f = tree.export_graphviz(decision_tree,\n",
    "                              out_file=f,\n",
    "                              max_depth = 3,\n",
    "                              impurity = True,\n",
    "                              feature_names = list(df_train.drop(['Survived'], axis=1)),\n",
    "                              class_names = ['Died', 'Survived'],\n",
    "                              rounded = True,\n",
    "                              filled= True )\n",
    "        \n",
    "#Convert .dot to .png to allow display in web notebook\n",
    "check_call(['dot','-Tpng','tree1.dot','-o','tree1.png'])\n",
    "\n",
    "# Annotating chart with PIL\n",
    "img = Image.open(\"tree1.png\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "font = ImageFont.truetype('/usr/share/fonts/truetype/liberation/LiberationSerif-Bold.ttf', 26)\n",
    "draw.text((10, 0), # Drawing offset (position)\n",
    "          '\"Title <= 1.5\" corresponds to \"Mr.\" title', # Text to draw\n",
    "          (0,0,255), # RGB desired color\n",
    "          font=font) # ImageFont object with desired font\n",
    "img.save('sample-out.png')\n",
    "PImage(\"sample-out.png\")\n",
    "\n",
    "# Code to check available fonts and respective paths\n",
    "# import matplotlib.font_manager\n",
    "# matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "da2fb75f-cd2c-f3ac-5f83-a0f1ff989080",
    "id": "tHxFDxTeEMzC",
    "papermill": {
     "duration": 0.050224,
     "end_time": "2021-03-05T12:14:07.210704",
     "exception": false,
     "start_time": "2021-03-05T12:14:07.160480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_decision_tree = round(decision_tree.score(x_train, y_train) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbd41693-028b-7cd1-3337-66de8fd85d08",
    "id": "BEMI5xRqEMzD",
    "papermill": {
     "duration": 0.037556,
     "end_time": "2021-03-05T12:14:07.285962",
     "exception": false,
     "start_time": "2021-03-05T12:14:07.248406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Nihayet Karar Ağacımız çizildi! Eğitim veri setinde % 82,38 doğruluk elde etti. Grafiğin nasıl okunacağını açıklamaya başlayalım.\n",
    "\n",
    "Her düğümün ilk satırı (son satırdakiler hariç) bölme koşulunu \"*feature* <= *value*\" biçiminde gösterir.\n",
    "\n",
    "Daha sonra, bu çekirdekte zaten açıklanmış olan düğümün Gini Impurtiy buluyoruz. \"Samples\", düğümde bulunan gözlemlerin sayısıdır.\n",
    "\n",
    "\"Value\", örneklerin sınıf dağılımını gösterir ([count non_survived, count survived]).\n",
    "\n",
    "Son olarak, \"class\", her düğümün baskın sınıfına karşılık gelir ve modelimiz bir gözlemi bu şekilde sınıflandırır. Renk aynı zamanda sınıfı temsil eder, opaklık numunelerin gerçek dağılımı ile artar.\n",
    "\n",
    "Modelimiz bu nedenle 4 basit kuralla özetlenebilir:\n",
    "\n",
    "* Gözlemimiz de \"Mr\" Title'ını içeriyorsa, onu hayatta kalmamış olarak sınıflandırırız (ağacın sol tarafındaki tüm dallar turuncu bir düğüme yol açar)\n",
    "* \"Mr.\" Title'ını içermiyorsa ve FamilySize 4 veya daha küçükse, o zaman hayatta kalmış olarak sınıflandırıyoruz.\n",
    "* \"Mr.\" Title'ını içermiyorsa, FamilySize 4'ten fazla ve Pclass 2 veya daha küçükse, o zaman hayatta kalan olarak sınıflandırıyoruz.\n",
    "* \"Mr\" Title'ını içermiyorsa, FamilySize 4'ten büyükse ve Pclass 2'den fazlaysa, onu hayatta kalmamış olarak sınıflandırıyoruz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1c4c9ece-9a53-31a2-69e3-fff9d3725e3f",
    "id": "vy4BMLKYEMzD",
    "papermill": {
     "duration": 0.037622,
     "end_time": "2021-03-05T12:14:07.361476",
     "exception": false,
     "start_time": "2021-03-05T12:14:07.323854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Bu kurallar sayesinde gemi enkazı hakkında bazı içgörüler elde edebiliriz. Görünüşe göre \"Baylar\" unvanlarını onurlandırdılar ve \"Usta\" veya \"Dr.\" gibi daha egzotik unvanlarla kadın ve erkekler lehine kendilerini feda ettiler. Ayrıca, daha küçük ailelerin hayatta kalma şanslarının daha yüksek olduğunu da not edebiliriz, çünkü daha büyük aileler bir arada kalmaya veya kayıp üyeleri aramaya çalıştıkları için cankurtaran sandallarında yer kalmamış olabilir. Son olarak, 3. sınıf yolcuların hayatta kalma şanslarının da daha az olduğunu gözlemleyebiliriz, bu nedenle muhtemelen üst sosyal sosyal sınıflara ait yolcular ayrıcalıklıydı veya sadece 3. sınıf kabinler cankurtaran botlarından daha uzakta olabilirdi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RgIUaUYuEMzD",
    "papermill": {
     "duration": 0.037387,
     "end_time": "2021-03-05T12:14:07.436757",
     "exception": false,
     "start_time": "2021-03-05T12:14:07.399370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day7-DecisionTree-Demo1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.274886,
   "end_time": "2021-03-05T12:14:08.387910",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-05T12:13:54.113024",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
