{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"Day5-LinearLogisticRegression-Exercises.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Lojistik Regresyon Projesi (Tıklamayı Tahmin Et)\n","\n","Logistic Regresyon, **bir örneğin belirli bir sınıfa ait olma olasılığını** tahmin etmek için yaygın olarak kullanılır.\n","\n","Bir örneğin tahmini olasılığı %50'den büyükse, model örneğin o sınıf 1'e ait olduğunu tahmin eder veya aksi takdirde olmadığını tahmin eder.\n","\n","Bu onu ikili bir sınıflandırıcı yapar. Bu notebookta 'Lojistik Regresyon'un arkasındaki teoriye bakacağız ve bunu **belirli bir internet kullanıcısının bir Reklama tıklayıp tıklamadığını belirtmek için** kullanacağız.\n","\n","O kullanıcının özelliklerinden yola çıkarak bir reklama tıklayıp tıklamayacağını tahmin edecek bir model oluşturmaya çalışacağız.\n","\n","Bu veri seti aşağıdaki öznitelikleri içerir:\n","\n","* '`Sitede Geçirilen Günlük Süre:`' dakika cinsinden tüketicinin sitede geçirdiği süre\n","* '`Yaş:`' yıl cinsinden müşterinin yaşı\n","* '`Alan Geliri:`' Tüketicinin bulunduğu coğrafi bölgesinin ortalama geliri\n","* '`Günlük İnternet Kullanımı:'` Günde dakika bazında tüketicinin internette harcadığı zaman\n","* '`Reklam Konusu Satırı:'` İlanın başlığı\n","* '`Şehir:'` Müşterinin bulunduğu şehir \n","* '`Erkek:`' Müşterinin erkek olup olmadığı \n","* '`Ülke:`' Müşterinin bulunduğu ülke\n","* '`Zaman Damgası:`' Tüketicinin Reklamı tıkladığı veya pencereyi kapattığı zaman\n","* '`Reklama Tıklandı:`' Reklamın tıklandığı 0 veya 1 olarak belirtilir"],"metadata":{"id":"ozwQSbDiOdj0"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","%matplotlib inline\n","sns.set_style('whitegrid')\n","plt.style.use(\"fivethirtyeight\")\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:01.061948Z","iopub.execute_input":"2022-04-05T08:48:01.062599Z","iopub.status.idle":"2022-04-05T08:48:01.071184Z","shell.execute_reply.started":"2022-04-05T08:48:01.062257Z","shell.execute_reply":"2022-04-05T08:48:01.070458Z"},"trusted":true,"id":"Sph0siS8Odj6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get the Data"],"metadata":{"id":"5KCC-ZZ8Odj8"}},{"cell_type":"code","source":["ROOT_DIR = \"https://raw.githubusercontent.com/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART1/Day5-Linear_LogisticRegression/notebooks\"\n","DATASET_PATH = ROOT_DIR + \"/datasets/\"\n","\n","data = pd.read_csv(DATASET_PATH + 'advertising.csv')\n","data.head()"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:04.263682Z","iopub.execute_input":"2022-04-05T08:48:04.264184Z","iopub.status.idle":"2022-04-05T08:48:04.290409Z","shell.execute_reply.started":"2022-04-05T08:48:04.26414Z","shell.execute_reply":"2022-04-05T08:48:04.289572Z"},"trusted":true,"id":"Fk16VHTnOdj9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.info()"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:06.691271Z","iopub.execute_input":"2022-04-05T08:48:06.691605Z","iopub.status.idle":"2022-04-05T08:48:06.704335Z","shell.execute_reply.started":"2022-04-05T08:48:06.691555Z","shell.execute_reply":"2022-04-05T08:48:06.703261Z"},"trusted":true,"id":"2rDYIZ6KOdj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data.describe()"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:09.018737Z","iopub.execute_input":"2022-04-05T08:48:09.019351Z","iopub.status.idle":"2022-04-05T08:48:09.054433Z","shell.execute_reply.started":"2022-04-05T08:48:09.019284Z","shell.execute_reply":"2022-04-05T08:48:09.053487Z"},"trusted":true,"id":"z1ebPRZROdj_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 1. Exploratory Data Analysis"],"metadata":{"id":"zeYgzzULOdj_"}},{"cell_type":"code","source":["plt.figure(figsize=(10, 8))\n","data.Age.hist(bins=data.Age.nunique())\n","plt.xlabel('Age')"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:11.61598Z","iopub.execute_input":"2022-04-05T08:48:11.616317Z","iopub.status.idle":"2022-04-05T08:48:12.057978Z","shell.execute_reply.started":"2022-04-05T08:48:11.616241Z","shell.execute_reply":"2022-04-05T08:48:12.056781Z"},"trusted":true,"id":"7b7h7lTEOdkA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.pairplot(data, hue='Clicked on Ad')"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:23.744677Z","iopub.execute_input":"2022-04-05T08:48:23.744979Z","iopub.status.idle":"2022-04-05T08:48:33.646988Z","shell.execute_reply.started":"2022-04-05T08:48:23.744933Z","shell.execute_reply":"2022-04-05T08:48:33.646057Z"},"trusted":true,"id":"pfAAXYImOdkE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data['Clicked on Ad'].value_counts()"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:33.648558Z","iopub.execute_input":"2022-04-05T08:48:33.648928Z","iopub.status.idle":"2022-04-05T08:48:33.656029Z","shell.execute_reply.started":"2022-04-05T08:48:33.648763Z","shell.execute_reply":"2022-04-05T08:48:33.655412Z"},"trusted":true,"id":"YS4DCt1hOdkF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 8))\n","sns.heatmap(data.corr(), annot=True)"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:49.794892Z","iopub.execute_input":"2022-04-05T08:48:49.795419Z","iopub.status.idle":"2022-04-05T08:48:50.45184Z","shell.execute_reply.started":"2022-04-05T08:48:49.795173Z","shell.execute_reply":"2022-04-05T08:48:50.450776Z"},"trusted":true,"id":"JLIdyVzCOdkF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Lojistik Regresyonun Arkasındaki Teori\n","\n","Lojistik regresyon, iki sınıflı problemler için kullanılan doğrusal sınıflandırma algoritmasıdır.\n","Uygulaması kolaydır, anlaşılması kolaydır ve çok çeşitli problemlerde, yöntemin verileriniz için sahip olduğu beklentiler ihlal edildiğinde bile harika sonuçlar alır.\n","\n","### Açıklama\n","\n","#### Lojistik Regresyon\n","\n","Lojistik regresyon, yöntemin özünde kullanılan işlev olan [lojistik işlev](https://en.wikipedia.org/wiki/Logistic_function)'den yola çıkarak adlandırılmıştır.\n","**`Sigmoid fonksiyonu`** olarak da adlandırılan lojistik fonksiyon, istatistikçiler tarafından ekolojideki nüfus artışının özelliklerini, hızla yükselen ve çevrenin taşıma kapasitesini maksimuma çıkaran özelliklerini tanımlamak için geliştirilmiştir.\n","\n","**Bu, gerçek değerli herhangi bir sayıyı alıp 0 ile 1 arasında bir değere eşleyebilen, ancak asla tam olarak bu sınırlarda olmayan S şeklinde bir eğridir.**\n","\n","$$\\frac{1}{1 + e^{-x}}$$\n","\n","$e$, doğal logaritmaların temelidir ve $x$, lojistik işlev aracılığıyla dönüştürmek istediğiniz değerdir.\n"],"metadata":{"id":"1tuZECu6OdkG"}},{"cell_type":"code","source":["x = np.linspace(-6, 6, num=1000)\n","\n","plt.figure(figsize=(10, 6))\n","\n","plt.plot(x, (1 / (1 + np.exp(-x))))\n","\n","plt.title(\"Sigmoid Function\")"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:48:58.269115Z","iopub.execute_input":"2022-04-05T08:48:58.269785Z","iopub.status.idle":"2022-04-05T08:48:58.580332Z","shell.execute_reply.started":"2022-04-05T08:48:58.269718Z","shell.execute_reply":"2022-04-05T08:48:58.579316Z"},"trusted":true,"id":"EK8MK9lNOdkH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lojistik regresyon denklemi, lineer regresyon gibi çok benzer bir temsile sahiptir. \n","**Aradaki fark, modellenen çıktı değerinin doğası gereği ikili olmasıdır.**\n","\n","$$\\hat{y}=\\frac{e^{\\beta_0+\\beta_1x_1}}{1+\\beta_0+\\beta_1x_1}$$\n","\n","veya\n","\n","$$\\hat{y}=\\frac{1.0}{1.0+e^{-\\beta_0-\\beta_1x_1}}$$\n","\n","$\\beta_0$ kesişim terimidir.\n","$\\beta_1$, $x_1$ katsayısıdır.\n","\n","$\\hat{y}$, gerçek değeri 0 ile 1 arasında olan tahmini çıktıdır.\n","Bunu 0 veya 1 ikili çıktısına dönüştürmek için, bunun bir tamsayı değerine yuvarlanması veya sınıf ayrım noktasını belirtmek için bir kesme noktası sağlanması gerekir.\n","\n","***\n","### Lojistik Regresyon Modelini Öğrenmek\n","\n","Lojistik regresyon algoritmasının katsayıları (Beta değerleri b), eğitim verilerinizden tahmin edilmelidir.\n","\n","Bu, [maksimum olasılık tahmini](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) kullanılarak yapılır.\n","\n","Maksimum olabilirlik tahmini, çeşitli makine öğrenimi algoritmaları tarafından kullanılan yaygın bir öğrenme algoritmasıdır, ancak verilerinizin dağıtımı hakkında varsayımlarda bulunur.\n","\n","En iyi katsayılar, varsayılan sınıf için 1'e çok yakın bir değer (örneğin erkek) ve diğer sınıf için 0'a çok yakın bir değer (örneğin kadın) öngören bir modelle sonuçlanacaktır. Lojistik regresyon için maksimum olasılık sezgisi, bir arama prosedürünün, model tarafından tahmin edilen olasılıklardaki hatayı verilerdekilere (örneğin, veri birincil ise 1 olasılığı) en aza indiren katsayılar (Beta değerleri) için değerler aramasıdır).\n","\n","Lojistik regresyon için maksimum olasılık tahmini, bir arama prosedürünün, model tarafından tahmin edilen olasılıklardaki hatayı verilerdekilere (örneğin, veri birincil ise 1 olasılığı) en aza indiren katsayılar (Beta değerleri) için değerler aramasıdır. sınıf).Maksimum olabilirlik matematiğine girmeyeceğiz. Eğitim verileriniz için katsayılar için en iyi değerleri optimize etmek için bir minimizasyon algoritmasının kullanıldığını söylemek yeterlidir. Bu genellikle pratikte verimli sayısal optimizasyon algoritması (Quasi-newton yöntemi gibi) kullanılarak uygulanır.Lojistik öğrenirken, çok daha basit gradyan iniş algoritmasını kullanarak sıfırdan kendiniz uygulayabilirsiniz.\n"],"metadata":{"id":"ulyYDaW_OdkI"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n","    if train:\n","        pred = clf.predict(X_train)\n","        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n","        print(\"Train Result:\\n================================================\")\n","        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n","        print(\"_______________________________________________\")\n","        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n","        print(\"_______________________________________________\")\n","        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n","        \n","    elif train==False:\n","        pred = clf.predict(X_test)\n","        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n","        print(\"Test Result:\\n================================================\")        \n","        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n","        print(\"_______________________________________________\")\n","        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n","        print(\"_______________________________________________\")\n","        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:49:23.272967Z","iopub.execute_input":"2022-04-05T08:49:23.27327Z","iopub.status.idle":"2022-04-05T08:49:23.283127Z","shell.execute_reply.started":"2022-04-05T08:49:23.273232Z","shell.execute_reply":"2022-04-05T08:49:23.281945Z"},"trusted":true,"id":"epUggrAmOdkJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ML ön işleme için scikit-learn (pandas değil) kullanma nedenleri:\n","\n","1. Tüm iş akışını çapraz doğrulayabilirsiniz (cross-validate).\n","2. Grid search model ve ön işleme hiperparametreleri yapabilirsiniz.\n","3. Kaynak DataFrame'e yeni sütunlar eklemekten kaçınır.\n","4. Pandas, veri sızıntısını önlemek için ayrı yerleştirme/dönüştürme adımlarından yoksundur.\n"],"metadata":{"id":"REkVihaDOdkK"}},{"cell_type":"markdown","source":["**Yapılacaklar;**\n","1. Öznitelik değişkeni olarak 'Timestamp', 'Clicked on Ad', 'Ad Topic Line', 'Country', 'City' kolonları ve hedef değişken olan 'Clicked on Ad'  haricindekileri drop ederek X öznitelik değişkeni olarak atayalım.\n","\n","2. 'Clicked on Ad' hedef değişkenini y olarak atayalım.\n","\n","3. Eğitim ve test kümesini %70-%30 şeklinde ayıralım.\n"],"metadata":{"id":"kD43wyEdRArS"}},{"cell_type":"code","source":["# yukarıda beklenen 3 madde burada kodlanacak"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:49:37.705036Z","iopub.execute_input":"2022-04-05T08:49:37.705563Z","iopub.status.idle":"2022-04-05T08:49:37.750926Z","shell.execute_reply.started":"2022-04-05T08:49:37.705501Z","shell.execute_reply":"2022-04-05T08:49:37.750108Z"},"trusted":true,"id":"pVXINKo5OdkK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","num_columns = ['Daily Time Spent on Site', 'Age', 'Area Income', 'Daily Internet Usage', 'Male']\n","\n","# https://scikit-learn.org/stable/modules/generated/sklearn.compose.make_column_transformer.html\n","ct = make_column_transformer(\n","    (MinMaxScaler(), num_columns),\n","    (StandardScaler(), num_columns),\n","    remainder='passthrough'\n",")\n","\n","X_train = ct.fit_transform(X_train)\n","X_test = ct.transform(X_test)"],"metadata":{"id":"c73blKUNR_Cg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. Verileri Lojistik Regresyon İçin Hazırlayın\n","\n","Verilerinizdeki dağılım ve ilişkiler hakkında lojistik regresyon tarafından yapılan varsayımlar, lineer regresyonda yapılan varsayımlarla hemen hemen aynıdır.\n","\n","Bu varsayımları tanımlamak için pek çok çalışma yapılmıştır ve kesin olasılıklı ve istatistiksel dil kullanılmaktadır. Benim tavsiyem, bunları kılavuz veya temel kurallar olarak kullanmak ve farklı veri hazırlama şemalarını denemek.\n","\n","Sonuç olarak, tahmine dayalı modelleme makine öğrenimi projelerinde, lazer sonuçları yorumlamak yerine doğru tahminler yapmaya odaklanıyorsunuz. Bu nedenle, model sağlam olduğu ve iyi performans gösterdiği sürece bazı varsayımları bozabilirsiniz.\n","\n","- **İkili Çıktı Değişkeni (Binary Output Variable):** Bu, daha önce bahsettiğimiz gibi açık olabilir, ancak lojistik regresyon, ikili (iki sınıf) sınıflandırma problemlerine yöneliktir. 0 veya 1 sınıflandırmasına bağlanabilen varsayılan sınıfa ait bir örneğin olasılığını tahmin edecektir.\n","\n","- **Gürültüyü Kaldır (Remove Noise):** Lojistik regresyon, çıktı değişkeninde (y) hata olmadığını varsayar, eğitim verilerinizden aykırı değerleri ve muhtemelen yanlış sınıflandırılmış örnekleri kaldırmayı düşünün.\n","\n","- **Gauss Dağılımı (Gaussian Distribution):** Lojistik regresyon, doğrusal bir algoritmadır (çıktıda doğrusal olmayan bir dönüşümle). Girdi değişkenleri ile çıktı arasında doğrusal bir ilişki olduğunu varsayar. Bu doğrusal ilişkiyi daha iyi ortaya çıkaran girdi değişkenlerinizin veri dönüşümleri, daha doğru bir modelle sonuçlanabilir. Örneğin, bu ilişkiyi daha iyi ortaya çıkarmak için log, root, Box-Cox ve diğer tek değişkenli dönüşümleri kullanabilirsiniz.\n","\n","- **İlgili Girdileri Kaldırın (Remove Correlated Inputs):** Doğrusal regresyon gibi, yüksek düzeyde ilişkili birden fazla girdiniz varsa model fazla sığabilir. Tüm girdiler arasındaki ikili korelasyonları hesaplamayı ve yüksek korelasyonlu girdileri kaldırmayı düşünün.\n","\n","- **Fail to Converge:** Katsayıları öğrenen beklenen olabilirlik tahmin sürecinin yakınsayamaması mümkündür. Bu, verilerinizde yüksek düzeyde ilişkili girdiler varsa veya veriler çok seyrekse (örneğin, girdi verilerinizde çok sayıda sıfır varsa) olabilir.\n"],"metadata":{"id":"LWeomWWVOdkL"}},{"cell_type":"markdown","source":["# 4. Scikit-Learn'de Lojistik Regresyon Uygulaması"],"metadata":{"id":"0VHT0l3ROdkL"}},{"cell_type":"markdown","source":["sklearn'un LogisticRegression() ile solver hiperparametresini \"liblinear\" şeklinde atayarak model eğitimini yapınız. \n","\n","Ve yukarıda kendimizin tanımlamış olduğu print_score() fonksiyonunu kullanarak eğitim ve test başarımlarımızı yazdırınız."],"metadata":{"id":"53gGcYRdScuJ"}},{"cell_type":"code","source":["# LogisticRegression import edilecek "],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:49:59.238708Z","iopub.execute_input":"2022-04-05T08:49:59.239017Z","iopub.status.idle":"2022-04-05T08:49:59.353583Z","shell.execute_reply.started":"2022-04-05T08:49:59.238969Z","shell.execute_reply":"2022-04-05T08:49:59.352642Z"},"trusted":true,"id":"4j95zk-aOdkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model egitimi yapılacak ve skor hesaplanacak\n"],"metadata":{"id":"QfusBfiqSZxs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["RandomForestClassifier() modelini kullanarak eğitim yapınız ve yukarıda kendimizin tanımlamış olduğu print_score() fonksiyonunu kullanarak eğitim ve test başarımlarımızı yazdırınız."],"metadata":{"id":"R5vp_iFHS8tF"}},{"cell_type":"code","source":["# RandomForestClassifier import edilecek \n"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T08:50:01.806465Z","iopub.execute_input":"2022-04-05T08:50:01.806765Z","iopub.status.idle":"2022-04-05T08:50:04.506307Z","shell.execute_reply.started":"2022-04-05T08:50:01.80672Z","shell.execute_reply":"2022-04-05T08:50:04.505507Z"},"trusted":true,"id":"ODKVz8FpOdkL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model egitimi yapılacak ve skor hesaplanacak\n"],"metadata":{"id":"HbnzKQ7oS-v0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Performans ölçümü\n","\n","#### 1. Confusion Matrix\n","- Her satır: gerçek sınıf\n","- Her sütun: tahmini sınıf\n","\n","İlk satır: Tıklanmayan Reklamlar, negatif sınıf:\n","* 143 tane Tıklanmayan Reklamlar olarak doğru bir şekilde sınıflandırıldı. **Gerçek olumsuzlar (True negatives)**.\n","* Kalan 6 tanesi yanlışlıkla tıklanan Reklamlar olarak sınıflandırıldı. **Yanlış pozitif (False positive)**\n","\n","İkinci satır: Tıklanan Reklamlar, pozitif sınıf:\n","* 3 tanesi yanlışlıkla Tıklanmayan Reklamlar olarak sınıflandırıldı. **Yanlış negatifler (False negatives)** \n","* 146 tanesi tıklanan Reklamlar doğru sınıflandırılmıştır. **Gerçek pozitifler (True positives)**\n","\n","\n","#### 2. Kesinlik (Precision)\n","\n","**Kesinlik (Precision)** olumlu tahminlerin doğruluğunu ölçer. Sınıflandırıcının`kesinliği (precision)` of the classifier ==> `98.01%`\n","\n","$$\\textrm{kesinlik (precision)} = \\frac{\\textrm{Gercek pozitifler (True Positives)}}{\\textrm{Gercek pozitifler (True Positives)} + \\textrm{Yanlis pozitif (False positive)}}$$\n","\n","\n","#### 3. Duyarlılık (Recall)\n","\n","`Kesinlik (Precision)` is typically used with `recall` (`Hassasiyet` or `Gerçek Pozitif Oranı`). \n","Sınıflandırıcı tarafından doğru bir şekilde tespit edilen pozitif örneklerin oranı.\n","\n","\n","$$\\textrm{Duyarlilik (Recall)} = \\frac{\\textrm{Gercek pozitifler (True Positives)}}{\\textrm{Gercek pozitifler (True Positives)} + \\textrm{Yanlis negatif (False negatives}}$$ ==> `96.10%`\n","\n","#### 4. F1 Puanı (F1 Score)\n","\n","$F_1$ puanı, kesinlik ve duyarlılığın harmonik ortalamasıdır. Normal ortalama, tüm değerlere eşit ağırlık verir. Harmonik ortalama, düşük değerlere daha fazla ağırlık verir.\n","\n","\n","$$F_1=\\frac{2}{\\frac{1}{\\textrm{kesinlik (Precision)}}+\\frac{1}{\\textrm{Duyarlilik (Recall)}}}=2\\times \\frac{\\textrm{Kesinlik (Precision)}\\times \\textrm{Duyarlilik (Recall)}}{\\textrm{kesinlik (Precision)}+ \\textrm{Duyarlilik (Recall)}}=\\frac{TP}{TP+\\frac{FN+FP}{2}}$$ ==> `97.05%`\n","\n","$F_1$ puanı, benzer kesinliğe ve duyarlılığa sahip sınıflandırıcıları tercih eder.\n","\n","#### 5. Kesinlik (Precision) / Duyarlılık (Recall) Dengesi\n","\n","Artan kesinlik (Precision), duyarlılık (Recall)'ı azaltır (veya tam tersi)\n","\n"],"metadata":{"id":"AXWGVSDxOdkM"}},{"cell_type":"markdown","source":["## The Receiver Operating Characteristics (ROC) Curve\n","\n","ROC eğrisi, kesinliğe(precision) karşı duyarlılığa(recall) çizmek yerine, `yanlış pozitif oran (false positive rate)`a karşı `gerçek pozitif oranı (true positive rate)` çizer. ` Yanlış pozitif oran (false positive rate-FPR)`, hatalı olarak pozitif olarak sınıflandırılan negatif örneklerin oranıdır. Bir eksi, doğru bir şekilde negatif olarak sınıflandırılan negatif örneklerin oranı olan `gerçek negatif oran (true negative rate-TNR)` a eşittir.\n","\n","TNR'ye `özgüllük (specificity)` de denir. Dolayısıyla, ROC eğrisi, \"1 - `özgüllük (specificity)`e karşı `sensitivity` (recall) grafiğini çizer.\n"],"metadata":{"id":"9Kn2Ga-MOdkN"}},{"cell_type":"code","source":["from sklearn.metrics import roc_curve\n","\n","def plot_roc_curve(fpr, tpr, label=None):\n","    plt.plot(fpr, tpr, linewidth=2, label=label)\n","    plt.plot([0, 1], [0, 1], \"k--\")\n","    plt.axis([0, 1, 0, 1])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve')\n","\n","fpr, tpr, thresholds = roc_curve(y_test, lr_clf.predict(X_test))\n","plt.figure(figsize=(12,8)); \n","plot_roc_curve(fpr, tpr)\n","plt.show();"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:08:29.302237Z","iopub.execute_input":"2022-04-05T09:08:29.302538Z","iopub.status.idle":"2022-04-05T09:08:29.741749Z","shell.execute_reply.started":"2022-04-05T09:08:29.302502Z","shell.execute_reply":"2022-04-05T09:08:29.740449Z"},"trusted":true,"id":"gYe97nbROdkN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","roc_auc_score(y_test, lr_clf.predict(X_test))"],"metadata":{"execution":{"iopub.status.busy":"2022-04-05T09:08:33.328521Z","iopub.execute_input":"2022-04-05T09:08:33.328836Z","iopub.status.idle":"2022-04-05T09:08:33.337378Z","shell.execute_reply.started":"2022-04-05T09:08:33.328787Z","shell.execute_reply":"2022-04-05T09:08:33.336425Z"},"trusted":true,"id":"mGplsKQ1OdkO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Pozitif sınıf nadir olduğunda (positive class is rare)** veya yanlış pozitifleri (false positives) yanlış negatiflerden (false negatives) daha fazla önemsediğinizde PR eğrisini kullanın.\n","​\n","**Negatif sınıf nadir olduğunda** veya yanlış pozitiflerden (false positives) çok yanlış negatifleri (false negatives) önemsediğinizde ROC eğrisini kullanın\n","​\n","​\n","Yukarıdaki örnekte, ROC eğrisi, sınıflandırıcının iyi olduğunu gösteriyor gibiydi. Ancak, PR eğrisine baktığınızda, iyileştirme için yer olduğunu görebilirsiniz.\n"],"metadata":{"id":"-LBMpZAYOdkO"}},{"cell_type":"markdown","source":["# 6. Lojistik Regresyon Hiperparametre ayarı"],"metadata":{"id":"SNr_mVL4OdkP"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","lr_clf = LogisticRegression()\n","\n","penalty = ['l1', 'l2']\n","C = [0.5, 0.6, 0.7, 0.8]\n","class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n","solver = ['liblinear', 'saga']\n","\n","param_grid = dict(penalty=penalty, C=C, class_weight=class_weight, solver=solver)\n","\n","lr_cv = GridSearchCV(estimator=lr_clf, param_grid=param_grid, scoring='accuracy', verbose=1, n_jobs=-1, cv=10)\n","lr_cv.fit(X_train, y_train)\n","best_params = lr_cv.best_params_\n","print(f\"Best parameters: {best_params}\")\n","\n","lr_clf = LogisticRegression(**best_params)\n","lr_clf.fit(X_train, y_train)\n","\n","print_score(lr_clf, X_train, y_train, X_test, y_test, train=True)\n","print_score(lr_clf, X_train, y_train, X_test, y_test, train=False)"],"metadata":{"trusted":true,"id":"qFY8szVNOdkP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. Özet\n","\n","Bu notebookta, makine öğrenimi ve tahmine dayalı modelleme için lojistik regresyon algoritmasını keşfettiniz. Çok yol kat ettiniz ve şunları öğrendiniz:\n","\n","- Lojistik fonksiyonun ne olduğu ve lojistik regresyonda nasıl kullanıldığı\n","- Lojistik regresyondaki anahtar temsilin, tıpkı lineer regresyon gibi katsayılar olduğu\n","- Lojistik regresyondaki katsayıların, maksimum olabilirlik tahmini adı verilen bir süreç kullanılarak tahmin edilmesi\n","- Lojistik regresyon kullanarak tahmin yapmak o kadar kolay ki, bunu excel'de yapabilirsiniz\n","- Lojistik regresyon için veri hazırlamanın lineer regresyona çok benzemesi\n","- Bir makine öğrenimi sınıflandırma problemi nasıl değerlendirilir\n","- Lojistik regresyon hiper parametreleri nasıl ayarlanır\n","\n","\n","## References:\n","- [Scikit Learn Library](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning)\n","- [Logistic Regression for Machine Learning by Jason Brownlee PhD](https://machinelearningmastery.com/logistic-regression-for-machine-learning/)"],"metadata":{"id":"UTNIi1K1OdkQ"}},{"cell_type":"code","source":[""],"metadata":{"id":"2IdZW4LHOdkQ"},"execution_count":null,"outputs":[]}]}