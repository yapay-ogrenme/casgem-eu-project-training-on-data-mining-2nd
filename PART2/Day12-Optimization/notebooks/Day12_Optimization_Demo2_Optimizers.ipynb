{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day12_Optimization_Demo2_Optimizers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VVcli7YBfox"
      },
      "source": [
        "# Optimizasyon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoa-mvrt1vX"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjUh2XOFf4W9"
      },
      "source": [
        "def plot_result(history, name):\n",
        "  pd.DataFrame(history.history).plot()\n",
        "  plt.grid(True)\n",
        "  #plt.gca().set_ylim(0, 1)\n",
        "  plt.title(name)\n",
        "  plt.show()\n",
        "\n",
        "def tune_opt_model(optimizer, epochs):\n",
        "  model = keras.models.Sequential()\n",
        "  \n",
        "  model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
        "\n",
        "  for n_layers in (300, 100, 50, 50, 50):\n",
        "    model.add(keras.layers.Dense(n_layers, activation ='relu', kernel_initializer=\"he_normal\"))\n",
        "\n",
        "  model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                optimizer=optimizer,metrics=[\"accuracy\"])\n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  start_time = time.time()\n",
        "\n",
        "  history = model.fit(X_train_full, y_train_full, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n",
        "  return history\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BU19SVMBfVG"
      },
      "source": [
        "## Sınıflandırma görevi\n",
        "\n",
        "ReLU Aktivasyon fonksiyonunun kullanılması (%86,72 Tren seti; %86,37 Test seti; 99,76 saniye)\n",
        "\n",
        "**Optimizasyon Ayarları**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCOCGlfvB6bN"
      },
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "X_train_full = X_train_full / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = SGD - learning_rate = 0.001**"
      ],
      "metadata": {
        "id": "5bo-GWhFSDr7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYxLEovYJ3Nc"
      },
      "source": [
        "# ReLU goes with he initialization, let's see of this improve the model performance nd running time\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "EPOCHS = 15\n",
        "\n",
        "optimizer=keras.optimizers.SGD(lr=1e-3)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_SGD = history.history[\"loss\"]\n",
        "val_loss_SGD = history.history[\"val_loss\"]\n",
        "train_acc_SGD = history.history[\"accuracy\"]\n",
        "val_acc_SGD = history.history[\"val_accuracy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = SGD - learning_rate = 0.001, momentum=0.9**"
      ],
      "metadata": {
        "id": "HITvuIytSvl9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35T6fbmZv2Lv"
      },
      "source": [
        "# ReLU goes with he initialization, SGD(lr=0.001, momentum=0.9) optimizer\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_mom = history.history[\"loss\"]\n",
        "val_loss_mom = history.history[\"val_loss\"]\n",
        "train_acc_mom = history.history[\"accuracy\"]\n",
        "val_acc_mom = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and SDG (lr=0.001, momentum=0.9) optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5NO1KVF9nc5"
      },
      "source": [
        "epoch_no = list(range(1,EPOCHS+1))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.grid(True)\n",
        "plt.plot(epoch_no, train_loss_SGD, marker = 'x')\n",
        "plt.plot(epoch_no, train_loss_mom)\n",
        "plt.plot(epoch_no, train_loss_SGD, marker = 'x')\n",
        "plt.plot(epoch_no, train_acc_mom)\n",
        "plt.legend([\"SGD Loss\", \"Momentum Loss\",\"SGD Accuracy\", \"Momentum Accuracy\"])\n",
        "plt.xlabel('Number of epochs')\n",
        "#plt.ylim((0.2,1))\n",
        "plt.title(\"Compare SDG and Momentum\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = SGD - learning_rate = 0.001, momentum=0.9, nesterov=True**"
      ],
      "metadata": {
        "id": "XSTTge1Yl1qD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lbqPWavDgCZ"
      },
      "source": [
        "# ReLU goes with he initialization, SGD(lr=0.001, momentum=0.9) optimizer with nesterov is activated \n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9,nesterov=True)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_NAG = history.history[\"loss\"]\n",
        "val_loss_NAG = history.history[\"val_loss\"]\n",
        "train_acc_NAG = history.history[\"accuracy\"]\n",
        "val_acc_NAG = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and SDG (lr=0.001, momentum=0.9, nesterov=True) optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Adagrad - learning_rate = 0.001**"
      ],
      "metadata": {
        "id": "95vEWCaNl6py"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBdM8QjDD4cR"
      },
      "source": [
        "# ReLU goes with he initialization, AdaGrad optimizer\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.Adagrad(lr=0.001)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_adagrad = history.history[\"loss\"]\n",
        "val_loss_adagrad = history.history[\"val_loss\"]\n",
        "train_acc_adagrad = history.history[\"accuracy\"]\n",
        "val_acc_adagrad = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and AdaGrad optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = RMSprop - learning_rate = 0.001, rho=0.99**"
      ],
      "metadata": {
        "id": "-OLbpu0gmBNI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLvlSWW2FJTH"
      },
      "source": [
        "# ReLU goes with he initialization, RMSProp optimizer\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.99)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_rmsprop = history.history[\"loss\"]\n",
        "val_loss_rmsprop = history.history[\"val_loss\"]\n",
        "train_acc_rmsprop = history.history[\"accuracy\"]\n",
        "val_acc_rmsprop = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and RMSProp optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41DFwB24-fuJ"
      },
      "source": [
        "epoch_no = list(range(1,EPOCHS+1))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.grid(True)\n",
        "plt.plot(epoch_no, train_loss_adagrad, marker = 'x')\n",
        "plt.plot(epoch_no, train_loss_rmsprop)\n",
        "plt.plot(epoch_no, train_acc_adagrad, marker = 'x')\n",
        "plt.plot(epoch_no, train_acc_rmsprop)\n",
        "plt.legend([\"Adagrad Loss\", \"RMSprop Loss\",\"Adagrad Accuracy\", \"RMSprop Accuracy\"])\n",
        "plt.xlabel('Number of epochs')\n",
        "#plt.ylim((0.2,1))\n",
        "plt.title(\"Compare Adagrad and RMSprop\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Adam - beta1 = 0.9, beta2=0.999**"
      ],
      "metadata": {
        "id": "uMDC5XdzmKK6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAJlxoWHFlzz"
      },
      "source": [
        "# ReLU goes with he initialization, Adam optimizer\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_adam = history.history[\"loss\"]\n",
        "val_loss_adam = history.history[\"val_loss\"]\n",
        "train_acc_adam = history.history[\"accuracy\"]\n",
        "val_acc_adam = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and Adam optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbGZgMEN-5KT"
      },
      "source": [
        "epoch_no = list(range(1,EPOCHS+1))\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.grid(True)\n",
        "plt.plot(epoch_no, train_loss_adagrad, marker = 'x', color=\"#070bf2\")\n",
        "plt.plot(epoch_no, train_loss_rmsprop, marker = 'o', color=\"#5fd406\")\n",
        "plt.plot(epoch_no, train_loss_adam, marker = 'v', color=\"#fc0808\")\n",
        "plt.plot(epoch_no, train_acc_adagrad, color=\"#070bf2\")\n",
        "plt.plot(epoch_no, train_acc_rmsprop, color=\"#5fd406\")\n",
        "plt.plot(epoch_no, train_acc_adam, color=\"#fc0808\")\n",
        "plt.legend([\"Adagrad Loss\", \"RMSprop Loss\",\"Adam Loss\", \"Adagrad Accuracy\", \"RMSprop Accuracy\", \"Adam Accuracy\"])\n",
        "plt.xlabel('Number of epochs')\n",
        "#plt.ylim((0.2,1))\n",
        "plt.title(\"Compare Adagrad, RMSprop and Adam\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Adamax - beta1 = 0.9, beta2=0.999**"
      ],
      "metadata": {
        "id": "ulwZj4nTmWE3"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxlZ8BDnHpTc"
      },
      "source": [
        "# ReLU goes with he initialization, Adamax optimizer\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_adamax = history.history[\"loss\"]\n",
        "val_loss_adamax = history.history[\"val_loss\"]\n",
        "train_acc_adamax = history.history[\"accuracy\"]\n",
        "val_acc_adamax = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and Adamax optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Nadam - beta1 = 0.9, beta2=0.999**"
      ],
      "metadata": {
        "id": "PwpE3_P1mbEn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agBk7U8pTBQ1"
      },
      "source": [
        "# ReLU goes with he initialization, Nadam optimizer\n",
        "tf.random.set_seed(50)\n",
        "np.random.seed(50)\n",
        "\n",
        "optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "history = tune_opt_model(optimizer=optimizer, epochs = EPOCHS)\n",
        "\n",
        "train_loss_nadam = history.history[\"loss\"]\n",
        "val_loss_nadam = history.history[\"val_loss\"]\n",
        "train_acc_nadam = history.history[\"accuracy\"]\n",
        "val_acc_nadam = history.history[\"val_accuracy\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and Nadam optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsncLkYmWCz2"
      },
      "source": [
        "## Regresyon Görevi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOMlFfnaV-rJ"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_valid = scaler.transform(X_valid)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n26UpNjkLlgN"
      },
      "source": [
        "def tune_opt_reg(optimizer):\n",
        "  model_default = keras.models.Sequential()\n",
        "  for n_layers in (100, 50, 10, 10, 10):\n",
        "    model_default.add(keras.layers.Dense(n_layers, activation=\"relu\", \n",
        "                                         input_shape=X_train.shape[1:], kernel_initializer='he_normal'))\n",
        "  model_default.add(keras.layers.Dense(1))\n",
        "    \n",
        "  model_default.compile(loss=\"mean_squared_error\",\n",
        "                        optimizer=optimizer)\n",
        "  \n",
        "  start_time = time.time()\n",
        "\n",
        "  history = model_default.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_valid, y_valid))\n",
        "  \n",
        "  print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "  return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = SGD - learning_rate=0.001**"
      ],
      "metadata": {
        "id": "hbFJ5O8xmfn0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG6bqi0hWBmn"
      },
      "source": [
        "# He Initialization with Randomized ReLU activation function\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.SGD(lr=1e-3)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "\n",
        "train_loss_SGD = history.history[\"loss\"]\n",
        "val_loss_SGD = history.history[\"val_loss\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = SGD - learning_rate=0.001, momentum=0.9**"
      ],
      "metadata": {
        "id": "z6Q-MXtimmRc"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1UekEdLW5BE"
      },
      "source": [
        "# ReLU goes with he initialization, SGD(lr=0.001, momentum=0.9) optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "plot_result(history, name='He Initialization with ReLU and SGD(lr=0.001, momentum=0.9) optimizer')\n",
        "\n",
        "train_loss_momentum = history.history[\"loss\"]\n",
        "val_loss_momentum = history.history[\"val_loss\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = SGD - learning_rate=0.001, momentum=0.9, nesterov=True**"
      ],
      "metadata": {
        "id": "ZXR1UUpDmqEC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGT-4Cy-XHha"
      },
      "source": [
        "# ReLU goes with he initialization, Nesterov SGD(lr=0.001, momentum=0.9) optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "optimizer=keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "\n",
        "train_loss_nesterov = history.history[\"loss\"]\n",
        "val_loss_nesterov = history.history[\"val_loss\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and Nesterov SGD(lr=0.001, momentum=0.9) optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Adagrad - learning_rate = 0.001**"
      ],
      "metadata": {
        "id": "RlRWNGjRmwix"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2BNEbRQXhZF"
      },
      "source": [
        "# ReLU goes with he initialization, Adagrad optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.Adagrad(lr=0.001)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "train_loss_adagrad = history.history[\"loss\"]\n",
        "val_loss_adagrad = history.history[\"val_loss\"]\n",
        "plot_result(history, name='He Initialization with ReLU and Adagrad optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = RMSprop - learning_rate = 0.001, rho=0.9**"
      ],
      "metadata": {
        "id": "gKnd8WJsm3Kw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K43KYB3XnxG"
      },
      "source": [
        "# ReLU goes with he initialization, RMSprop optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "\n",
        "train_loss_rmsprop = history.history[\"loss\"]\n",
        "val_loss_rmsprop = history.history[\"val_loss\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and RMSprop optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Adam - learning_rate=0.001, beta1 = 0.9, beta2=0.999**"
      ],
      "metadata": {
        "id": "UF3b4rkMnLV5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SfBJTtvX2Di"
      },
      "source": [
        "# ReLU goes with he initialization, Adam optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "train_loss_adam = history.history[\"loss\"]\n",
        "val_loss_adam = history.history[\"val_loss\"]\n",
        "\n",
        "plot_result(history, name='He Initialization with ReLU and Adam optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Adamax - learning_rate=0.001, beta1 = 0.9, beta2=0.999**"
      ],
      "metadata": {
        "id": "UseD0UN1nX7_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92BC6gxDX7xv"
      },
      "source": [
        "# ReLU goes with he initialization, Adamax optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "train_loss_adamax = history.history[\"loss\"]\n",
        "val_loss_adamax = history.history[\"val_loss\"]\n",
        "plot_result(history, name='He Initialization with ReLU and Adamax optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer = Nadam - learning_rate=0.001, beta1 = 0.9, beta2=0.999**"
      ],
      "metadata": {
        "id": "6T9H8ZqinbOY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2d-e96H2YBaw"
      },
      "source": [
        "# ReLU goes with he initialization, Nadam optimizer\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "optimizer=keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "history = tune_opt_reg(optimizer=optimizer)\n",
        "train_loss_nadam = history.history[\"loss\"]\n",
        "val_loss_nadam = history.history[\"val_loss\"]\n",
        "plot_result(history, name='He Initialization with ReLU and Nadam optimizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2uLqy8IhRlR"
      },
      "source": [
        "train_loss = [train_loss_SGD, train_loss_momentum, train_loss_nesterov, train_loss_adagrad, train_loss_rmsprop, train_loss_adam, \n",
        "              train_loss_adamax, train_loss_nadam]\n",
        "epoch_no = list(range(1,EPOCHS+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Vc_LwfHdveV"
      },
      "source": [
        "plt.plot(epoch_no, train_loss_SGD)\n",
        "plt.plot(epoch_no, train_loss_momentum)\n",
        "plt.legend([\"train_loss_SGD\", \"train_loss_momentum\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDLKFhsxhzSG"
      },
      "source": [
        "plt.figure(figsize=(15,5))\n",
        "for opt in train_loss:\n",
        "  plt.plot(epoch_no, opt)\n",
        "  \n",
        "plt.legend([\"SGD\", \"Momentum\",\"Nesterov\", \"Adagrad\", \"RMSprop\", \"Adam\", \"Adamax\", \"Nadam\"])\n",
        "plt.set_cmap(\"jet\")\n",
        "plt.ylabel('Train loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylim((0.2,1))\n",
        "plt.title(\"Train loss by different optimizer\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEE7ZmJUiTh7"
      },
      "source": [
        "val_loss = [val_loss_SGD, val_loss_momentum, val_loss_nesterov, val_loss_adagrad, val_loss_rmsprop, val_loss_adam, \n",
        "              val_loss_adamax, val_loss_nadam]\n",
        "              \n",
        "plt.figure(figsize=(15,5))\n",
        "for opt in val_loss:\n",
        "  plt.plot(epoch_no, opt)\n",
        "plt.legend([\"SGD\", \"Momentum\",\"Nesterov\", \"Adagrad\", \"RMSprop\", \"Adam\", \"Adamax\", \"Nadam\"])\n",
        "plt.ylabel('Validation loss')\n",
        "plt.xlabel('Number of epochs')\n",
        "plt.ylim((0.2,1))\n",
        "plt.title(\"Validation set loss by different optimizer\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fAyvRLcguVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}