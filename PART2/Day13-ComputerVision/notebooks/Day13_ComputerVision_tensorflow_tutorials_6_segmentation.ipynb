{"cells":[{"cell_type":"markdown","metadata":{"id":"rCSP-dbMw88x"},"source":["# Resim Segmentasyonu"]},{"cell_type":"markdown","metadata":{"id":"sMP7mglMuGT2"},"source":["Bu çalışma dosyası, değiştirilmiş bir <a href=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/\" class=\"external\">U-Net</a> kullanarak görüntü segmentasyonu görevine odaklanır.\n","\n","## Görüntü segmentasyonu nedir?\n","\n","Bir görüntü sınıflandırma görevinde ağ, her giriş görüntüsüne bir etiket (veya sınıf) atar. Ancak, o nesnenin şeklini, hangi pikselin hangi nesneye ait olduğunu vb. bilmek istediğinizi varsayalım. Bu durumda görüntünün her pikseline bir sınıf atamak isteyeceksiniz. Bu görev, segmentasyon olarak bilinir. Bir segmentasyon modeli, görüntü hakkında çok daha ayrıntılı bilgi verir. Görüntü bölütleme, tıbbi görüntülemede, sürücüsüz arabalarda ve uydu görüntülemede bunlardan birkaçını saymak gerekirse pek çok uygulamaya sahiptir.\n","\n","Bu çalışma dosyası [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/) ([Parkhi et al, 2012](https://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf)). Veri kümesi, cins başına 200 resim (eğitim ve test bölümlerinde her biri ~100) olmak üzere 37 evcil hayvan cinsinin resminden oluşur. Her görüntü, karşılık gelen etiketleri ve piksel bazında maskeleri içerir. Maskeler, her piksel için sınıf etiketleridir. Her piksele üç kategoriden biri verilir:\n","\n","- Sınıf 1: Evcil hayvana ait piksel.\n","- Sınıf 2: Evcil hayvanı çevreleyen piksel.\n","- Sınıf 3: Yukarıdakilerin hiçbiri/çevreleyen bir piksel."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:20.994031Z","iopub.status.busy":"2022-01-26T05:14:20.990482Z","iopub.status.idle":"2022-01-26T05:14:27.960057Z","shell.execute_reply":"2022-01-26T05:14:27.960460Z"},"id":"MQmKthrSBCld"},"outputs":[],"source":["!pip install git+https://github.com/tensorflow/examples.git"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:27.965423Z","iopub.status.busy":"2022-01-26T05:14:27.964840Z","iopub.status.idle":"2022-01-26T05:14:30.074072Z","shell.execute_reply":"2022-01-26T05:14:30.073432Z"},"id":"YQX7R4bhZy5h"},"outputs":[],"source":["import tensorflow as tf\n","\n","import tensorflow_datasets as tfds"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:30.078361Z","iopub.status.busy":"2022-01-26T05:14:30.077772Z","iopub.status.idle":"2022-01-26T05:14:30.678858Z","shell.execute_reply":"2022-01-26T05:14:30.678320Z"},"id":"g87--n2AtyO_"},"outputs":[],"source":["from tensorflow_examples.models.pix2pix import pix2pix\n","\n","from IPython.display import clear_output\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"oWe0_rQM4JbC"},"source":["## Oxford-IIIT Pets veri kümesini indirin\n","\n","Veri kümesi, [TensorFlow Veri Kümeleri]((https://www.tensorflow.org/datasets/catalog/oxford_iiit_pet))'nden edinilebilir. Segmentasyon maskeleri 3+ sürümüne dahil edilmiştir."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:30.683302Z","iopub.status.busy":"2022-01-26T05:14:30.682645Z","iopub.status.idle":"2022-01-26T05:14:38.244653Z","shell.execute_reply":"2022-01-26T05:14:38.245038Z"},"id":"40ITeStwDwZb"},"outputs":[],"source":["dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"]},{"cell_type":"markdown","metadata":{"id":"rJcVdj_U4vzf"},"source":["Ayrıca, görüntü renk değerleri `[0,1]` aralığına normalleştirilir. Son olarak, yukarıda belirtildiği gibi, segmentasyon maskesindeki pikseller ya {1, 2, 3} olarak etiketlenir. Kolaylık sağlamak için, segmentasyon maskesinden 1 çıkarın ve şu etiketlerle sonuçlanır: {0, 1, 2}."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.249802Z","iopub.status.busy":"2022-01-26T05:14:38.249213Z","iopub.status.idle":"2022-01-26T05:14:38.250874Z","shell.execute_reply":"2022-01-26T05:14:38.251206Z"},"id":"FD60EbcAQqov"},"outputs":[],"source":["def normalize(input_image, input_mask):\n","  input_image = tf.cast(input_image, tf.float32) / 255.0\n","  input_mask -= 1\n","  return input_image, input_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.255735Z","iopub.status.busy":"2022-01-26T05:14:38.255184Z","iopub.status.idle":"2022-01-26T05:14:38.257160Z","shell.execute_reply":"2022-01-26T05:14:38.256731Z"},"id":"Zf0S67hJRp3D"},"outputs":[],"source":["def load_image(datapoint):\n","  input_image = tf.image.resize(datapoint['image'], (128, 128))\n","  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n","\n","  input_image, input_mask = normalize(input_image, input_mask)\n","\n","  return input_image, input_mask"]},{"cell_type":"markdown","metadata":{"id":"65-qHTjX5VZh"},"source":["Veri kümesi zaten gerekli eğitim ve test bölümlerini içerir, bu nedenle aynı bölümleri kullanmaya devam edin."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.260861Z","iopub.status.busy":"2022-01-26T05:14:38.260323Z","iopub.status.idle":"2022-01-26T05:14:38.261905Z","shell.execute_reply":"2022-01-26T05:14:38.262235Z"},"id":"yHwj2-8SaQli"},"outputs":[],"source":["TRAIN_LENGTH = info.splits['train'].num_examples\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 1000\n","STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.266864Z","iopub.status.busy":"2022-01-26T05:14:38.266321Z","iopub.status.idle":"2022-01-26T05:14:38.351560Z","shell.execute_reply":"2022-01-26T05:14:38.352002Z"},"id":"39fYScNz9lmo"},"outputs":[],"source":["train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n","test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)"]},{"cell_type":"markdown","metadata":{"id":"T9hGHyg8L3Y1"},"source":["Aşağıdaki sınıf, bir görüntüyü rastgele çevirerek basit bir veri arttırma gerçekleştirir."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.358293Z","iopub.status.busy":"2022-01-26T05:14:38.357296Z","iopub.status.idle":"2022-01-26T05:14:38.359123Z","shell.execute_reply":"2022-01-26T05:14:38.359541Z"},"id":"fUWdDJRTL0PP"},"outputs":[],"source":["class Augment(tf.keras.layers.Layer):\n","  def __init__(self, seed=42):\n","    super().__init__()\n","    # both use the same seed, so they'll make the same random changes.\n","    self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n","    self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n","  \n","  def call(self, inputs, labels):\n","    inputs = self.augment_inputs(inputs)\n","    labels = self.augment_labels(labels)\n","    return inputs, labels"]},{"cell_type":"markdown","metadata":{"id":"xTIbNIBdcgL3"},"source":["Girdileri grupladıktan sonra veri arttırmayı uygulayarak girdi ardışık düzenini(pipeline) oluşturun."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.364902Z","iopub.status.busy":"2022-01-26T05:14:38.364261Z","iopub.status.idle":"2022-01-26T05:14:38.457565Z","shell.execute_reply":"2022-01-26T05:14:38.457916Z"},"id":"VPscskQcNCx4"},"outputs":[],"source":["train_batches = (\n","    train_images\n","    .cache()\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE)\n","    .repeat()\n","    .map(Augment())\n","    .prefetch(buffer_size=tf.data.AUTOTUNE))\n","\n","test_batches = test_images.batch(BATCH_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"Xa3gMAE_9qNa"},"source":["Veri kümesinden bir görüntü örneğini ve buna karşılık gelen maskesini görselleştirin."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.463025Z","iopub.status.busy":"2022-01-26T05:14:38.462458Z","iopub.status.idle":"2022-01-26T05:14:38.464758Z","shell.execute_reply":"2022-01-26T05:14:38.464307Z"},"id":"3N2RPAAW9q4W"},"outputs":[],"source":["def display(display_list):\n","  plt.figure(figsize=(15, 15))\n","\n","  title = ['Input Image', 'True Mask', 'Predicted Mask']\n","\n","  for i in range(len(display_list)):\n","    plt.subplot(1, len(display_list), i+1)\n","    plt.title(title[i])\n","    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n","    plt.axis('off')\n","  plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:38.469471Z","iopub.status.busy":"2022-01-26T05:14:38.468921Z","iopub.status.idle":"2022-01-26T05:14:45.989634Z","shell.execute_reply":"2022-01-26T05:14:45.989973Z"},"id":"a6u_Rblkteqb"},"outputs":[],"source":["for images, masks in train_batches.take(2):\n","  sample_image, sample_mask = images[0], masks[0]\n","  display([sample_image, sample_mask])"]},{"cell_type":"markdown","metadata":{"id":"FAOe93FRMk3w"},"source":["## Modeli tanımlayın\n","\n","Burada kullanılan model değiştirilmiş bir [U-Net](https://arxiv.org/abs/1505.04597)'tir. Bir U-Net, bir kodlayıcı(encoder) (alt örnekleyici(downsampler)) ve kod çözücüden(decoder) (yukarı örnekleyici(upsampler)) oluşur. \n","Sağlam öznitelikleri öğrenmek ve eğitilebilir parametre sayısını azaltmak için kodlayıcı olarak önceden eğitilmiş bir model - MobileNetV2 - kullanacaksınız. Kod çözücü için, TensorFlow Örnekleri deposundaki [pix2pix](https://github.com/tensorflow/examples/blob/master/tensorflow_examples/models/pix2pix/pix2pix.py) örneğinde zaten uygulanmış olan örnekleme bloğunu kullanacaksınız.\n"]},{"cell_type":"markdown","metadata":{"id":"W4mQle3lthit"},"source":["Belirtildiği gibi, kodlayıcı `tf.keras.applications` içinde hazırlanmış ve kullanıma hazır önceden eğitilmiş bir MobileNetV2 modeli olacaktır. Kodlayıcı, modeldeki ara katmanlardan belirli çıktılardan oluşur. Kodlayıcının eğitim sürecinde eğitilmeyeceğini unutmayın."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:46.002911Z","iopub.status.busy":"2022-01-26T05:14:46.000880Z","iopub.status.idle":"2022-01-26T05:14:47.154052Z","shell.execute_reply":"2022-01-26T05:14:47.153567Z"},"id":"liCeLH0ctjq7"},"outputs":[],"source":["base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n","\n","# Use the activations of these layers\n","layer_names = [\n","    'block_1_expand_relu',   # 64x64\n","    'block_3_expand_relu',   # 32x32\n","    'block_6_expand_relu',   # 16x16\n","    'block_13_expand_relu',  # 8x8\n","    'block_16_project',      # 4x4\n","]\n","base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n","\n","# Create the feature extraction model\n","down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n","\n","down_stack.trainable = False"]},{"cell_type":"markdown","metadata":{"id":"KPw8Lzra5_T9"},"source":["Kod çözücü(decoder)/üst örnekleyici(upsampler), TensorFlow örneklerinde uygulanan basit bir dizi üst örnekleme (upsample) bloğudur."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.159752Z","iopub.status.busy":"2022-01-26T05:14:47.159128Z","iopub.status.idle":"2022-01-26T05:14:47.176640Z","shell.execute_reply":"2022-01-26T05:14:47.176993Z"},"id":"p0ZbfywEbZpJ"},"outputs":[],"source":["up_stack = [\n","    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n","    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n","    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n","    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.182866Z","iopub.status.busy":"2022-01-26T05:14:47.182286Z","iopub.status.idle":"2022-01-26T05:14:47.184170Z","shell.execute_reply":"2022-01-26T05:14:47.183767Z"},"id":"45HByxpVtrPF"},"outputs":[],"source":["def unet_model(output_channels:int):\n","  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n","\n","  # Downsampling through the model\n","  skips = down_stack(inputs)\n","  x = skips[-1]\n","  skips = reversed(skips[:-1])\n","\n","  # Upsampling and establishing the skip connections\n","  for up, skip in zip(up_stack, skips):\n","    x = up(x)\n","    concat = tf.keras.layers.Concatenate()\n","    x = concat([x, skip])\n","\n","  # This is the last layer of the model\n","  last = tf.keras.layers.Conv2DTranspose(\n","      filters=output_channels, kernel_size=3, strides=2,\n","      padding='same')  #64x64 -> 128x128\n","\n","  x = last(x)\n","\n","  return tf.keras.Model(inputs=inputs, outputs=x)"]},{"cell_type":"markdown","metadata":{"id":"LRsjdZuEnZfA"},"source":["Son katmandaki filtre sayısının `output_channels` sayısına ayarlandığını unutmayın. Bu, sınıf başına bir çıkış kanalı olacaktır."]},{"cell_type":"markdown","metadata":{"id":"j0DGH_4T0VYn"},"source":["## Modeli eğitin\n","\n","Şimdi geriye sadece modeli derlemek ve eğitmek kalıyor.\n","\n","Bu çok sınıflı bir sınıflandırma problemi olduğundan, etiketler her sınıfın her pikseli için puan vektörleri yerine skaler tam sayılar olduğundan, `from_logits` bağımsız değişkeni `True` olarak ayarlanmış olarak `tf.keras.losses.CategoricalCrossentropy` yitim fonksiyonunu (loss function) kullanın. .\n","\n","Çıkarım (inference) yapılırken piksele atanan etiket en yüksek değere sahip kanaldır. `create_mask` işlevinin yaptığı şey budur."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.190803Z","iopub.status.busy":"2022-01-26T05:14:47.189606Z","iopub.status.idle":"2022-01-26T05:14:47.633417Z","shell.execute_reply":"2022-01-26T05:14:47.633795Z"},"id":"6he36HK5uKAc"},"outputs":[],"source":["OUTPUT_CLASSES = 3\n","\n","model = unet_model(output_channels=OUTPUT_CLASSES)\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"xVMzbIZLcyEF"},"source":["Ortaya çıkan model mimarisine hızlıca bir göz atın:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.638529Z","iopub.status.busy":"2022-01-26T05:14:47.637939Z","iopub.status.idle":"2022-01-26T05:14:47.809358Z","shell.execute_reply":"2022-01-26T05:14:47.809768Z"},"id":"sw82qF1Gcovr"},"outputs":[],"source":["tf.keras.utils.plot_model(model, show_shapes=True)"]},{"cell_type":"markdown","metadata":{"id":"Tc3MiEO2twLS"},"source":["Eğitimden önce neyi tahmin ettiğini kontrol etmek için modeli deneyin."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.815257Z","iopub.status.busy":"2022-01-26T05:14:47.814692Z","iopub.status.idle":"2022-01-26T05:14:47.816090Z","shell.execute_reply":"2022-01-26T05:14:47.816427Z"},"id":"UwvIKLZPtxV_"},"outputs":[],"source":["def create_mask(pred_mask):\n","  pred_mask = tf.argmax(pred_mask, axis=-1)\n","  pred_mask = pred_mask[..., tf.newaxis]\n","  return pred_mask[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.821421Z","iopub.status.busy":"2022-01-26T05:14:47.820864Z","iopub.status.idle":"2022-01-26T05:14:47.822736Z","shell.execute_reply":"2022-01-26T05:14:47.822329Z"},"id":"YLNsrynNtx4d"},"outputs":[],"source":["def show_predictions(dataset=None, num=1):\n","  if dataset:\n","    for image, mask in dataset.take(num):\n","      pred_mask = model.predict(image)\n","      display([image[0], mask[0], create_mask(pred_mask)])\n","  else:\n","    display([sample_image, sample_mask,\n","             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:47.827000Z","iopub.status.busy":"2022-01-26T05:14:47.826427Z","iopub.status.idle":"2022-01-26T05:14:50.539438Z","shell.execute_reply":"2022-01-26T05:14:50.539885Z"},"id":"X_1CC0T4dho3"},"outputs":[],"source":["show_predictions()"]},{"cell_type":"markdown","metadata":{"id":"22AyVYWQdkgk"},"source":["Aşağıda tanımlanan geri arama(callback), eğitim sırasında modelin nasıl geliştiğini gözlemlemek için kullanılır."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:50.545132Z","iopub.status.busy":"2022-01-26T05:14:50.544265Z","iopub.status.idle":"2022-01-26T05:14:50.546254Z","shell.execute_reply":"2022-01-26T05:14:50.546602Z"},"id":"wHrHsqijdmL6"},"outputs":[],"source":["class DisplayCallback(tf.keras.callbacks.Callback):\n","  def on_epoch_end(self, epoch, logs=None):\n","    clear_output(wait=True)\n","    show_predictions()\n","    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:14:50.553216Z","iopub.status.busy":"2022-01-26T05:14:50.552350Z","iopub.status.idle":"2022-01-26T05:16:28.476384Z","shell.execute_reply":"2022-01-26T05:16:28.476868Z"},"id":"StKDH_B9t4SD"},"outputs":[],"source":["EPOCHS = 20\n","VAL_SUBSPLITS = 5\n","VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n","\n","model_history = model.fit(train_batches, epochs=EPOCHS,\n","                          steps_per_epoch=STEPS_PER_EPOCH,\n","                          validation_steps=VALIDATION_STEPS,\n","                          validation_data=test_batches,\n","                          callbacks=[DisplayCallback()])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:28.494859Z","iopub.status.busy":"2022-01-26T05:16:28.492395Z","iopub.status.idle":"2022-01-26T05:16:28.604951Z","shell.execute_reply":"2022-01-26T05:16:28.605303Z"},"id":"P_mu0SAbt40Q"},"outputs":[],"source":["loss = model_history.history['loss']\n","val_loss = model_history.history['val_loss']\n","\n","plt.figure()\n","plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n","plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss Value')\n","plt.ylim([0, 1])\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"unP3cnxo_N72"},"source":["## Tahminlerde bulunun"]},{"cell_type":"markdown","metadata":{"id":"7BVXldSo-0mW"},"source":["Şimdi, bazı tahminlerde bulunun. Zamandan tasarruf amacıyla, devir(epoch) sayısı küçük tutulmuştur, ancak daha doğru sonuçlar elde etmek için bunu daha yükseğe ayarlayabilirsiniz."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:28.609950Z","iopub.status.busy":"2022-01-26T05:16:28.609406Z","iopub.status.idle":"2022-01-26T05:16:30.772513Z","shell.execute_reply":"2022-01-26T05:16:30.772909Z"},"id":"ikrzoG24qwf5"},"outputs":[],"source":["show_predictions(test_batches, 3)"]},{"cell_type":"markdown","metadata":{"id":"QAwvlgSNoK3o"},"source":["## İsteğe bağlı: Dengesiz sınıflar ve sınıf ağırlıkları"]},{"cell_type":"markdown","metadata":{"id":"eqtFPqqu2kxP"},"source":["Semantik segmentasyon veri kümeleri oldukça dengesiz olabilir, bu da belirli sınıf piksellerinin diğer sınıflardan daha fazla görüntülerin içinde bulunabileceği anlamına gelir. Segmentasyon sorunları piksel başına sınıflandırma sorunları olarak ele alınabileceğinden, bunu hesaba katmak için kayıp fonksiyonunu tartarak dengesizlik sorununu çözebilirsiniz. Bu sorunla başa çıkmanın basit ve zarif bir yolu. \n","\n","[Belirsizliği önlemek](https://github.com/keras-team/keras/issues/3653#issuecomment-243939748) için `Model.fit`, 3+ boyutlu girdiler için `class_weight` bağımsız değişkenini desteklemez."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:30.779287Z","iopub.status.busy":"2022-01-26T05:16:30.778720Z","iopub.status.idle":"2022-01-26T05:16:30.783770Z","shell.execute_reply":"2022-01-26T05:16:30.784116Z"},"id":"aHt90UEQsZDn"},"outputs":[],"source":["try:\n","  model_history = model.fit(train_batches, epochs=EPOCHS,\n","                            steps_per_epoch=STEPS_PER_EPOCH,\n","                            class_weight = {0:2.0, 1:2.0, 2:1.0})\n","  assert False\n","except Exception as e:\n","  print(f\"Expected {type(e).__name__}: {e}\")"]},{"cell_type":"markdown","metadata":{"id":"brbhYODCsvbe"},"source":["Dolayısıyla, bu durumda ağırlıklandırmayı kendiniz uygulamanız gerekir. Bunu numune ağırlıklarını (sample weights) kullanarak yapacaksınız: `(data, label)` çiftlerine ek olarak, `Model.fit` ayrıca `(data, label, sample_weight)` üçlülerini de kabul eder.\n","\n","`Model.fit`, `sample_weight`nı kayıplara ve ölçümlere yayar ve bu da bir `sample_weight` argümanını da kabul eder. Numune ağırlığı, indirgeme adımından önce numunenin değeri ile çarpılır. Örneğin:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:30.789215Z","iopub.status.busy":"2022-01-26T05:16:30.788624Z","iopub.status.idle":"2022-01-26T05:16:30.793447Z","shell.execute_reply":"2022-01-26T05:16:30.793773Z"},"id":"EmHtImJn5Kk-"},"outputs":[],"source":["label = [0,0]\n","prediction = [[-3., 0], [-3, 0]] \n","sample_weight = [1, 10] \n","\n","loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True,\n","                                               reduction=tf.losses.Reduction.NONE)\n","loss(label, prediction, sample_weight).numpy()"]},{"cell_type":"markdown","metadata":{"id":"Gbwo3DZ-9TxM"},"source":["Bu çalışma dosyası için örnek ağırlıklar yapmak için bir `(data, label)` çifti alan ve bir `(data, label, sample_weight)` üçlüsü döndüren bir fonksiyona ihtiyacınız var. `sample_weight`, her piksel için sınıf ağırlığını içeren 1 kanallı bir görüntüdür.\n","\n","Mümkün olan en basit uygulama, etiketi bir `sample_weight` listesine bir dizin olarak kullanmaktır:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:30.798668Z","iopub.status.busy":"2022-01-26T05:16:30.798068Z","iopub.status.idle":"2022-01-26T05:16:30.799722Z","shell.execute_reply":"2022-01-26T05:16:30.800083Z"},"id":"DlG-n2Ugo8Jc"},"outputs":[],"source":["def add_sample_weights(image, label):\n","  # The weights for each class, with the constraint that:\n","  #     sum(class_weights) == 1.0\n","  class_weights = tf.constant([2.0, 2.0, 1.0])\n","  class_weights = class_weights/tf.reduce_sum(class_weights)\n","\n","  # Create an image of `sample_weights` by using the label at each pixel as an \n","  # index into the `class weights` .\n","  sample_weights = tf.gather(class_weights, indices=tf.cast(label, tf.int32))\n","\n","  return image, label, sample_weights"]},{"cell_type":"markdown","metadata":{"id":"hLH_NvH2UrXU"},"source":["Ortaya çıkan veri kümesi öğelerinin her biri 3 görüntü içerir:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:30.804028Z","iopub.status.busy":"2022-01-26T05:16:30.803404Z","iopub.status.idle":"2022-01-26T05:16:30.849763Z","shell.execute_reply":"2022-01-26T05:16:30.850108Z"},"id":"SE_ezRSFRCnE"},"outputs":[],"source":["train_batches.map(add_sample_weights).element_spec"]},{"cell_type":"markdown","metadata":{"id":"Yc-EpIzaRbSL"},"source":["Artık bu ağırlıklı veri kümesinde bir model eğitebilirsiniz:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:30.856119Z","iopub.status.busy":"2022-01-26T05:16:30.855537Z","iopub.status.idle":"2022-01-26T05:16:31.254459Z","shell.execute_reply":"2022-01-26T05:16:31.254820Z"},"id":"QDWipedAoOQe"},"outputs":[],"source":["weighted_model = unet_model(OUTPUT_CLASSES)\n","weighted_model.compile(\n","    optimizer='adam',\n","    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-26T05:16:31.259759Z","iopub.status.busy":"2022-01-26T05:16:31.257496Z","iopub.status.idle":"2022-01-26T05:16:34.380209Z","shell.execute_reply":"2022-01-26T05:16:34.379744Z"},"id":"btEFKc1xodGR"},"outputs":[],"source":["weighted_model.fit(\n","    train_batches.map(add_sample_weights),\n","    epochs=1,\n","    steps_per_epoch=10)"]},{"cell_type":"markdown","metadata":{"id":"R24tahEqmSCk"},"source":["## Sonraki adımlar\n","Artık görüntü segmentasyonunun ne olduğunu ve nasıl çalıştığını anladığınıza göre, bu öğreticiyi farklı ara katman çıktıları ve hatta farklı önceden eğitilmiş modeller ile deneyebilirsiniz. Kaggle'da barındırılan [Carvana](https://www.kaggle.com/c/carvana-image-masking-challenge/overview) görüntü maskeleme yarışmasını deneyerek de kendinize meydan okuyabilirsiniz.\n","\n","Kendi verileriniz üzerinde yeniden eğitebileceğiniz başka bir model için [Tensorflow Object Detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/README.md)'yi de görmek isteyebilirsiniz. Önceden eğitilmiş modeller [TensorFlow Hub](https://www.tensorflow.org/hub/tutorials/tf2_object_detection#opsiyonel) adresinde mevcuttur."]},{"cell_type":"code","source":[""],"metadata":{"id":"oPX17IvGiD5H"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Day13_ComputerVision_tensorflow_tutorials_6_segmentation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":0}