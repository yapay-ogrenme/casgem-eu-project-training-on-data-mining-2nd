{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz5jP0XDWR0Z"
      },
      "source": [
        "# Turkish NLP Pipeline with BERT \n",
        "\n",
        "1. Sentiment Analysis\n",
        "2. NER Model\n",
        "3. Question Answering\n",
        "4. Text Summarization *\n",
        "5. Text Categorization\n",
        "6. Text Normalization, Spell Checker *\n",
        "\n",
        "These models are fined tuned based on Turkish-Bert model \n",
        "\n",
        "https://github.com/stefan-it/turkish-bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWeLI30sWR0c"
      },
      "source": [
        "## Requirements\n",
        "* python3\n",
        "* pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j7HNFyXWR0d"
      },
      "outputs": [],
      "source": [
        "#!pip install git+https://github.com/huggingface/transformers.git --upgrade\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6g-zcMIfWR0f"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKbYcj6OWR0g"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw9ptDr1WR0g"
      },
      "source": [
        "# Bert \n",
        "Paper:\n",
        "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\n",
        "https://arxiv.org/pdf/1810.04805\n",
        "\n",
        " *Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova*\n",
        " **Google AI Language**\n",
        "\n",
        "*Abstract*\n",
        "\n",
        "* We introduce a new language representation model called BERT, which stands for **Bidirectional Encoder Representations from Transformers.** \n",
        "* Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pretrain deep bidirectional representations from **unlabeled text** by jointly conditioning on *both left and right context* in all layers. \n",
        "* BERT alleviates the previously mentioned unidirectionality constraint by using a **“masked language model”** (MLM) pre-training objective, inspired by the Cloze task (Taylor, 1953). T\n",
        "* As a result, the pre-trained BERT model can be finetuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as \n",
        "   - question answering and\n",
        "   - language inference, without substantial taskspecific architecture modifications.\n",
        "\n",
        "* BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on **eleven (11)**natural language processing tasks, including pushing the GLUE score to\n",
        "    - 80.5% (7.7% point absolute improvement), \n",
        "    - MultiNLI accuracy to 86.7% (4.6% absolute improvement), \n",
        "    - SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and \n",
        "    - SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YIsElUCWR0i"
      },
      "source": [
        "## Unidirectionality\n",
        "\"I made a bank deposit\" the unidirectional representation of bank is only based on I made a but not deposit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4i8GHp4WR0i"
      },
      "source": [
        "## Training\n",
        "masking out 15% of the words in the input\n",
        "\n",
        "```\n",
        "Input: the man went to the [MASK1] . he bought a [MASK2] of milk.\n",
        "Labels: [MASK1] = store; [MASK2] = gallon\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuqA66LZWR0j"
      },
      "source": [
        "## Bert codes and pre-trained models\n",
        "\n",
        "https://github.com/google-research/bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avcfgYVOWR0k"
      },
      "source": [
        "* Overall pre-training and fine-tuning procedures for BERT.\n",
        "\n",
        "* Apart from output layers, the **same architectures** are used in both **pre-training** and **fine-tuning**. \n",
        "\n",
        "* The same pre-trained model parameters are used to initialize models for **different down-stream tasks**. \n",
        "\n",
        "* During fine-tuning, all parameters are fine-tuned. \n",
        "[CLS] is a special symbol added in front of every input example, and [SEP] is a special separator token (e.g. separating questions/answers)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeJxtb-sWR0l"
      },
      "source": [
        "## Word embeddings\n",
        "* Context-free models such as word2vec or GloVe\n",
        "* Contextual representation (each word is based on the other words in the sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-TbhNVhWR0l"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKd-2T4vWR0m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertForMaskedLM\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-uncased')\n",
        "# Tokenize input\n",
        "text = \"[CLS] yeni derin öğrenme modelleri doğal dil işlemede heyacan uyandırdı [SEP]\"\n",
        "\n",
        "tokenized_text = tokenizer.tokenize(text)\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5KbiM1wWR0o"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5gMzy-SWR0o"
      },
      "outputs": [],
      "source": [
        "uzun=\"Muvaffakiyetsizleştiricileştiriveremeyebileceklerimizdenmişsinizcesinesiniz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DehrKe0WR0p"
      },
      "outputs": [],
      "source": [
        "tokenizer.tokenize(uzun)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULsUS3GVWR0p"
      },
      "outputs": [],
      "source": [
        "tokenizer.tokenize(\"merhaba :) !\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCUYhq5kWR0q"
      },
      "source": [
        "# Language Model Head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLw4wy__WR0q"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel, AutoTokenizer, pipeline, AutoModelWithLMHead\n",
        "#inp=\"dbmdz/electra-base-turkish-cased-discriminator\"\n",
        "inp=\"dbmdz/bert-base-turkish-cased\"\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(inp)\n",
        "tokenizer = AutoTokenizer.from_pretrained(inp)\n",
        "fm=pipeline(\"fill-mask\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad9ArgM4WR0r"
      },
      "outputs": [],
      "source": [
        "fm(\"Ergün [MASK] ayrı düz koştu yaptı\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye6v4CBIWR0r"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMihzm9RWR0r"
      },
      "outputs": [],
      "source": [
        "fe= pipeline(\"feature-extraction\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lpqIKFzWR0s"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "vec=np.array(fe(\"Ergün takım ayrı düz koşu yaptı\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l92tcJZLWR0s"
      },
      "outputs": [],
      "source": [
        "vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blm9-01PWR0s"
      },
      "outputs": [],
      "source": [
        "np.array(vec).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtyQRVKSWR0s"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pHGs0vfWR0t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "vec=np.array(fe(uzun))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ya9OhdkRWR0t"
      },
      "outputs": [],
      "source": [
        "vec.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1_x80voWR0t"
      },
      "source": [
        "# TASKS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sB58qqmWR0w"
      },
      "source": [
        "# BERTurk: Turkish Bert Pre-trained model\n",
        "https://github.com/stefan-it/turkish-bert\n",
        "\n",
        "* The current version of the model is trained on a filtered and sentence segmented version of \n",
        "    * the Turkish OSCAR corpus, \n",
        "    * a recent Wikipedia dump, \n",
        "    * various OPUS corpora \n",
        "    * and a special corpus provided by Kemal Oflazer.\n",
        "\n",
        "* The final training corpus has a size of 35GB and 44,004,976,662 tokens.\n",
        "\n",
        "* Thanks to Google's TensorFlow Research Cloud (TFRC) we can train both cased and uncased models on a TPU v3-8. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7eIdwMsWR0x"
      },
      "source": [
        "# How to train \n",
        "\n",
        "A detailed cheatsheet of how the models were trained, can be found \n",
        "\n",
        "\n",
        "https://github.com/stefan-it/turkish-bert/blob/master/CHEATSHEET.md\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nfHg2JqWR0x"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUaberZaWR0x"
      },
      "source": [
        "# Some Helpful libraries\n",
        "* https://github.com/google-research/bert\n",
        "* https://huggingface.co/ 27 K Stars\n",
        "* SimpleTransformers.ai\n",
        "* FARM: https://farm.deepset.ai/\n",
        "* https://github.com/kaushaltrivedi/fast-bert\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71ukKie6WR0y"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nI_LqE_WR0y"
      },
      "source": [
        "# Turkish NLP downstream tasks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfX9E_FiWR0y"
      },
      "source": [
        "## 1-Sentiment Analysis\n",
        "* This model can get up to %95 success rate on our dataset \n",
        "* To see the training detail and the model performce, check the link \\\n",
        " https://huggingface.co/savasy/bert-base-turkish-sentiment-cased\n",
        " \n",
        " https://github.com/savasy/TurkishSentimentAnalysis\n",
        " \n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rStQZChWR0y"
      },
      "source": [
        "### Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ih-ad7a3WR0y"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
        "# load model, it takes time since it loads over 500 MB model file\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
        "# create pipeline\n",
        "sa= pipeline(\"sentiment-analysis\", tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9smcgJMuWR0z"
      },
      "source": [
        "### Example usage\n",
        "* Label_1: positive\n",
        "* Label_0: negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dZ443-XWR0z"
      },
      "outputs": [],
      "source": [
        "p= sa(\"bu telefon modelleri çok kaliteli\")\n",
        "print(p)\n",
        "#[{'label': 'LABEL_1', 'score': 0.9871089}]\n",
        "print (p[0]['label']=='LABEL_1')\n",
        "#True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXQ2_biNWR0z"
      },
      "outputs": [],
      "source": [
        "p= sa(\"Film çok kötü ve oyuncular çok sahteydi\")\n",
        "print(p)\n",
        "#[{'label': 'LABEL_0', 'score': 0.9975505}]\n",
        "print (p[0]['label']=='LABEL_1')\n",
        "#False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwiGZfswWR00"
      },
      "outputs": [],
      "source": [
        "def sa2(inp):\n",
        "    p=sa(inp)\n",
        "    if p[0]['label']=='LABEL_1':\n",
        "        print(\"Positive - with score of {}\".format(p[0]['score']))\n",
        "    else:\n",
        "        print(\"Negative - with score of {}\".format(p[0]['score']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxQsNtqcWR01"
      },
      "outputs": [],
      "source": [
        "sa2(\"hahaha çok kötü\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWV4BtEEWR01"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IztVrm3aWR01"
      },
      "source": [
        "How to train and fine-tune your own model, please check \n",
        "\n",
        "https://github.com/savasy/TurkishSentimentAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY4tc8jOWR01"
      },
      "source": [
        "# 2- Name Entity Recognizer (NER)\n",
        "This model can get %95 accuracy, currently it works with PER, LOC, and ORG\n",
        "\n",
        "check huugingface model repo and ner pipeline repo for other detail\n",
        "\n",
        "* https://huggingface.co/savasy/bert-base-turkish-ner-cased\n",
        "* https://github.com/savasy/Turkish-Bert-Based-NERModel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sl-W8xGIWR02"
      },
      "source": [
        "## Example usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cp5p6LBbWR02"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n",
        "\n",
        "# load model\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-ner-cased\")\n",
        "\n",
        "ner=pipeline('ner', model=model, tokenizer=tokenizer)\n",
        "\n",
        "res=ner(\"Mustafa Kemal Atatürk 19 Mayıs 1919'da Samsun'a ayak bastı.\")\n",
        "for r in res:\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm3YZF70WR03"
      },
      "outputs": [],
      "source": [
        "res=ner(\"Sait Faik Abasıyanık ömrünün sonuna kadar yazları Burgaz Adadaki köşklerinde kalmıştır\")\n",
        "\n",
        "for r in res:\n",
        "    print(r)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJkhP_NQWR03"
      },
      "source": [
        "# 3- Question Answering  (SQuAD) for Turkish"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06w_ZH0fWR04"
      },
      "source": [
        "This model is tranied with TQuAD dataset (which is SQuAD-like data set of Turkish)\n",
        "\n",
        "https://github.com/TQuad/turkish-nlp-qa-dataset\n",
        "\n",
        "> This dataset is the Turkish Question & Answer dataset on Turkish & Islamic Science History within the scope of Teknofest 2018 Artificial Intelligence competition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYPOhuUkWR04"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGOemO77WR04"
      },
      "source": [
        "* 'exact': 62.55605381165919, \n",
        "* 'f1': 80.48410211644173, \n",
        "* 'HasAns_exact': 62.55605381165919, \n",
        "* 'HasAns_f1': 80.48410211644173, \n",
        "* 'HasAns_total': 892,\n",
        "* 'best_exact': 62.55605381165919, \n",
        "* 'best_f1': 80.48410211644173, \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt4G4T7wWR04"
      },
      "source": [
        "# Loading model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "-3ldM1fvWR05"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, pipeline\n",
        "import torch\n",
        " # LOAD MODEL\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-squad\")\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(\"savasy/bert-base-turkish-squad\")\n",
        "\n",
        "qa=pipeline(\"question-answering\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6K3Q-KLbWR05"
      },
      "outputs": [],
      "source": [
        "sait=\"ABASIYANIK, Sait Faik. Hikayeci (Adapazarı 23 Kasım 1906-İstanbul 11 Mayıs 1954). \\\n",
        "İlk öğrenimine Adapazarı’nda Rehber-i Terakki Mektebi’nde başladı. İki yıl kadar Adapazarı İdadisi’nde okudu.\\\n",
        "İstanbul Erkek Lisesi’nde devam ettiği orta öğrenimini Bursa Lisesi’nde tamamladı (1928). İstanbul Edebiyat \\\n",
        "Fakültesi’ne iki yıl devam ettikten sonra babasının isteği üzerine iktisat öğrenimi için İsviçre’ye gitti. \\\n",
        "Kısa süre sonra iktisat öğrenimini bırakarak Lozan’dan Grenoble’a geçti. Üç yıl başıboş bir edebiyat öğrenimi \\\n",
        "gördükten sonra babası tarafından geri çağrıldı (1933). Bir müddet Halıcıoğlu Ermeni Yetim Mektebi'nde Türkçe \\\n",
        "gurup dersleri öğretmenliği yaptı. Ticarete atıldıysa da tutunamadı. Bir ay Haber gazetesinde adliye muhabirliği\\\n",
        "yaptı (1942). Babasının ölümü üzerine aileden kalan emlakin geliri ile avare bir hayata başladı. Evlenemedi.\\\n",
        "Yazları Burgaz adasındaki köşklerinde, kışları Şişli’deki apartmanlarında annesi ile beraber geçen bu fazla \\\n",
        "içkili bohem hayatı ömrünün sonuna kadar sürdü.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtT7MbQVWR05"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Ne zaman avare bir hayata başladı?\", context=sait))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piv8eg5YWR06"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Sait Faik orta öğrenimini ne zaman bitirdi?\", context=sait))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1DIkfA1WR06"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Sait Faik kimdir?\", context=sait))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKVeKaXwWR06"
      },
      "outputs": [],
      "source": [
        "# Ask your self ! type your question\n",
        "print(qa(question=\"...?\", context=sait))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2IDHwhWWR07"
      },
      "outputs": [],
      "source": [
        "# source: wikipedia\n",
        "ataturk=\"Atatürk  modern, ilerici ve laik bir ulus devleti oluşturmak için politik, ekonomik ve kültürel alanlarda sekülarist ve milliyetçi \\\n",
        " karakterdeki reformlarını başlattı. Yabancılara tanınan ekonomik imtiyazlar kaldırıldı ve onlara ait üretim araçları ve demiryolları millîleştirildi. \\\n",
        " Tevhîd-i Tedrîsât Kanunu ile eğitim Türk hükûmetinin denetimine girdi. Seküler ve bilimsel eğitim esas alındı. Binlerce yeni okul inşa edildi. \\\n",
        " İlköğretim ücretsiz ve zorunlu hale getirildi. Yabancı okullar devlet denetimine alındı. Köylülerin sırtına yüklenen ağır vergiler azaltıldı. \\\n",
        " Erkeklerin serpuş ve kıyafetlerinde değişiklikler yapıldı. Takvim, saat ve ölçülerde değişikliklere gidildi. \\\n",
        " Mecelle kaldırılarak yerine seküler Türk Kanunu Medenisi yürürlüğe konuldu. Kadınların sivil ve politik hakları pek çok Batı ülkesinden önce tanındı. \\\n",
        " Çok eşlilik yasaklandı. Kadınların şahitliği ve miras hakkı erkeklerinkiyle eşit hale getirildi. Benzer şekilde, dünyanın çoğu ülkesinden önce olarak \\\n",
        " Türkiye'de kadınların ilkin yerel seçimlerde (1930), sonra genel seçimlerde (1934) seçme ve seçilme hakkı tanındı. Ceza ve borçlar hukukunda \\\n",
        " seküler yasalar yürürlüğe konuldu. Sanayi Teşvik Kanunu kabul edildi. Toprak Reformu için çabalandı.[3] Arap harfleri temelli Osmanlı alfabesinin yerine \\\n",
        "  Latin harfleri temelli yeni Türk alfabesi kabul edildi. Halkı okuryazar kılmak için eğitim seferberliği başlatıldı. Üniversite Reformu gerçekleştirildi. \\\n",
        "  Birinci Beş Yıllık Sanayi Planı yürürlüğe konuldu. Sınıf ve statü farkı gözeten lâkap ve unvanlar kaldırıldı ve soyadları yürürlüğe konuldu. \\\n",
        "  Homojen ve birleşmiş bir ulus yaratılması için Türkleştirme politikası yürütüldü.[4][5][6] Türk olmayan azınlıklar kamuoyunda Türkçe konuşmaya zorlandı,[7] \\\n",
        "  Türkçe olmayan toponomiler ve azınlıkların soyadları Türkçeye çevrildi.[8][9]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDbF_LrTWR07"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Kimlere ekonomik imtiyaz kaldırıldı?\", context=ataturk))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wgo56frWR07"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"tüm bu devrimleri kim yaptı?\", context=ataturk))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtIviVGCWR08"
      },
      "outputs": [],
      "source": [
        "# Ask your self ! type your question\n",
        "print(qa(question=\"...?\", context=ataturk))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1mi1MtcWR09"
      },
      "outputs": [],
      "source": [
        "text=\"Bugün 19 Mayıs Atatürk'ü Anma, Gençlik ve Spor Bayramı. Mustafa Kemal Atatürk, 19 Mayıs 1919'da Bandırma Vapuru ile Samsun'a çıkmış ve İtilaf Devletleri'nin işgaline karşı Kurtuluş Savaşı'nı başlatmıştı. Siyaset Bilimci Prof. Dr. Ahmet Demirel, Mustafa Kemal'in askeri başarılarıyla tanınan bir Osmanlı paşasıyken tüm yurt çapında saygı duyulan siyasi bir lidere dönüşmesinin ilk adımı olan 19 Mayıs 1919'un öncesi ve sonrasında neler yaşandığını BBC Türkçe'ye anlattı.\"\n",
        "print(qa(question=\"19 Mayıs ne bayramıdır?\", context=text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOoeNkpEWR09"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Atatürk Samsun'a ne zaman çıktı?\", context=text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wU9NwTuZWR0-"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Atatürk Samsun'da neyi başlattı?\", context=text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NMxEe-dWR0-"
      },
      "outputs": [],
      "source": [
        "print(qa(question=\"Kim Samsun'a çıktı?\", context=text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqMO7iPVWR0-"
      },
      "source": [
        "# 4 - Text Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKqpBpayWR0_"
      },
      "source": [
        "...will be soon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6AyLJyZWR0_"
      },
      "source": [
        "# 5- Text/Document Classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSZlpk45WR0_"
      },
      "source": [
        "In this study we fine-tune 7 classes Turkish news dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g_90gRhWR0_"
      },
      "source": [
        "The following Turkish benchmark dataset is used for fine-tuning\n",
        "\n",
        "https://www.kaggle.com/savasy/ttc4900\n",
        "\n",
        " * 'LABEL_0': 'dunya \n",
        " * 'LABEL_1': 'ekonomi '\n",
        " * 'LABEL_2': 'kultur '\n",
        " * 'LABEL_3': 'saglik '\n",
        " * 'LABEL_4': 'siyaset '\n",
        " * 'LABEL_5': 'spor '\n",
        " * 'LABEL_6': 'teknoloji'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1sC_iHgWR1A"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# load models\n",
        "tokenizer= AutoTokenizer.from_pretrained(\"savasy/bert-turkish-text-classification\")\n",
        "model= AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-turkish-text-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snrAqpLwWR1A"
      },
      "outputs": [],
      "source": [
        "# make pipeline\n",
        "tc=pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "# apply model\n",
        "res=tc(\"bla bla beşiktaş ve fenerbahce \")\n",
        "res\n",
        "# [{'label': 'LABEL_2', 'score': 0.4753005802631378}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFk062fkWR1C"
      },
      "outputs": [],
      "source": [
        "text=\"Bugün 19 Mayıs Atatürk'ü Anma, Gençlik ve Spor Bayramı. Mustafa Kemal Atatürk, 19 Mayıs 1919'da Bandırma Vapuru ile Samsun'a çıkmış ve İtilaf Devletleri'nin işgaline karşı Kurtuluş Savaşı'nı başlatmıştı. Siyaset Bilimci Prof. Dr. Ahmet Demirel, Mustafa Kemal'in askeri başarılarıyla tanınan bir Osmanlı paşasıyken tüm yurt çapında saygı duyulan siyasi bir lidere dönüşmesinin ilk adımı olan 19 Mayıs 1919'un öncesi ve sonrasında neler yaşandığını BBC Türkçe'ye anlattı.\"\n",
        "tc(text)[0]['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKGVJzgwWR1C"
      },
      "source": [
        "For the details of traininig models please check\n",
        "\n",
        "* https://github.com/savasy/TurkishTextClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt8Usdh3WR1D"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Day14_NLP_Turkish_NLP_Pipeline_Huggingface.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-sB58qqmWR0w"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}