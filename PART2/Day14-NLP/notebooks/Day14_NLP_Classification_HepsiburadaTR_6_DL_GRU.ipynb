{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vlQLiALWrS0"
      },
      "source": [
        "# Hepsiburada Duygu Analizi \n",
        "\n",
        "hepsiburada.com üzerinden yaklaşık 250.000 yorum derlenmiş ve yorumların sahip olduğu yıldız sayısına göre pozitif veya negatif olarak etiketlenmiştir.\n",
        "\n",
        "*   1 veya 2 yıldız : olumsuz yorum (0)\n",
        "*   4 veya 5 yıldız : olumlu yorum  (1)\n",
        "*   3 yıldıza sahip yorumlar veri kümesinden çıkarılmıştır.\n",
        "\n",
        "**Böylelikle toplamda analiz edilecek yorum sayısı : 243.496**\n",
        "\n",
        "**Yorumların %90'dan fazlası olumlu yoruma sahiptir.**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2BD9sHy_PA3"
      },
      "outputs": [],
      "source": [
        " import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZRQ_TRN_PBB"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hzy9xgDaWYrg"
      },
      "outputs": [],
      "source": [
        "DATA_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining-2nd/main/PART2/Day14-NLP/notebooks/datasets/\"\n",
        "\n",
        "DATASET_PATH = DATA_DIR + \"hepsiburada.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm3FmvxX_PBI"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvsa7Mvo_PBN"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Etiket değerleri ve analiz edilecek yorumları liste olarak alalım.**\n",
        "\n",
        "*   Hedef değişkeni : 'Rating'\n",
        "*   Analiz edilecek yorumlar : 'Review' \n"
      ],
      "metadata": {
        "id": "7xGths2CgZwB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMkyBBHZ_PBR"
      },
      "outputs": [],
      "source": [
        "target = dataset['Rating'].values.tolist()\n",
        "data = dataset['Review'].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eğitim ve Test kümelerini ayıralım.**\n",
        "\n",
        "Elimizdeki verilerin %80'inini eğitim, %20'sini ise test için ayıralım."
      ],
      "metadata": {
        "id": "HObODYOQhI2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2F2qmdU_PBT"
      },
      "outputs": [],
      "source": [
        "cutoff = int(len(data) * 0.80)\n",
        "x_train, x_test = data[:cutoff], data[cutoff:]\n",
        "y_train, y_test = target[:cutoff], target[cutoff:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6CSZv6m_PBU"
      },
      "outputs": [],
      "source": [
        "x_train[500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kNZsmJt_PBV"
      },
      "outputs": [],
      "source": [
        "x_train[800]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l5tlWln_PBX"
      },
      "outputs": [],
      "source": [
        "y_train[800]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenleştirme (Tokenization) \n",
        "\n",
        "Her yorumu kelimelere ayrılacak ve kelime haznesindeki her bir kelimeye bir sayı denk gelecektir.\n",
        "\n",
        "Öncelikle kelime haznemizde en fazla bulunacak kelime sayısını **(num_words=10.000)** tanımlayalım. Böylelikle veri kümesi içerisinde en sık geçen 10.000 kelimeyi ele alacağız. Bu kelimelerin dışında kalan nadir kelimeleri ise yok sayacağız.\n",
        "\n",
        "Not : Herhangi bir sınır belirlemek istemezseniz 'None' yazabilir veya default olarak bırakabilirsiniz."
      ],
      "metadata": {
        "id": "gFFK8Jtjhw23"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59O8gO4p_PBY"
      },
      "outputs": [],
      "source": [
        "num_words = 10000\n",
        "tokenizer = Tokenizer(num_words=num_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvuBhiRZ_PBZ"
      },
      "outputs": [],
      "source": [
        "tokenizer.fit_on_texts(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kelime haznemizi görüntüleyelim."
      ],
      "metadata": {
        "id": "PBfdYD9ijusW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGz4mLJy_PBZ"
      },
      "outputs": [],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eğitim ve Test kümesindeki tüm yorumları tokenler halinde bir değişkende saklayalım.**\n"
      ],
      "metadata": {
        "id": "Z7duFppfj3gM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3iGWdAl_PBa"
      },
      "outputs": [],
      "source": [
        "x_train_tokens = tokenizer.texts_to_sequences(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eğitim kümesindeki 800. yorumu ele alalım. Yorumu görüntüleyip, tokenleştirme sonrası çıktısına bakalım. Yukarıdaki listeden de kontrol ettiğimizde örneğin 'ürünü' kelimesinin 19'a karşılık geldiğini görebiliriz.\n",
        "\n",
        "Kelime haznesini 10.000 ile sınırladığımız için, bu sınırın dışında kalan nadir kelimeler tokenleştirilemeyecektir. Örneğin 800. yorum içerisinde geçen **'bilgisyarım'** kelimesi yazım yanlışı barındıran nadir bir kelimedir, bu sebeple en sık geçen 10.000 kelime içerisinde yoktur. Bu sebeple tokenleştirilememiştir ve bu kelime yok sayılmıştır."
      ],
      "metadata": {
        "id": "YA80G7IGkbt6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTqNZpOR_PBa"
      },
      "outputs": [],
      "source": [
        "x_train[800]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31Nf7EgU_PBb"
      },
      "outputs": [],
      "source": [
        "print(x_train_tokens[800])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d0Y5FJS_PBb"
      },
      "outputs": [],
      "source": [
        "x_test_tokens = tokenizer.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her yorumda bulunan token sayısını bulalım.\n"
      ],
      "metadata": {
        "id": "K3U-ORc-mMv8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8chLKnW_PBc"
      },
      "outputs": [],
      "source": [
        "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
        "num_tokens = np.array(num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yorumlarda ortalama 20 token bulunmaktadır."
      ],
      "metadata": {
        "id": "5fbY0V92mRO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CcFpxRm_PBd"
      },
      "outputs": [],
      "source": [
        "np.mean(num_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En uzun yorumun token sayısını bulalım."
      ],
      "metadata": {
        "id": "ddsxS_qimVHd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgqWhBLO_PBd"
      },
      "outputs": [],
      "source": [
        "np.max(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBtx7Mrq_PBe"
      },
      "outputs": [],
      "source": [
        "np.argmax(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZfiDIq4_PBe"
      },
      "outputs": [],
      "source": [
        "x_train[21941]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding boyutunu belirleyelim.\n",
        "Bunun birçok yolu var. İsteğe bağlı olarak maksimum token sayısına veya ortalama token sayısını eşitlenebilir. Ancak burada, biraz daha matematiksel bir tercih yapılacaktır.\n",
        "\n",
        "**max_tokens = num_tokens'ın ortalaması + 2* (num_tokens'ın standart sapması)**"
      ],
      "metadata": {
        "id": "u2ULeHLWmb24"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N2D5e-C_PBf"
      },
      "outputs": [],
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu hesap sonucunda çıkan 59 token, yorumların yüzde kaçını kapsamaktadır?"
      ],
      "metadata": {
        "id": "O-xT1YMfnJkZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnYwF5PP_PBf"
      },
      "outputs": [],
      "source": [
        "np.sum(num_tokens < max_tokens) / len(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtPJCFrta9wP"
      },
      "outputs": [],
      "source": [
        "len(x_train_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding İşlemi \n",
        "\n",
        "RNN ile oluşturduğumuz modellere belli boyutlarda input'lar veririz.\n",
        "Üzerinde çalıştığımız datasetteki yorumların ise boyutları birbirinden farklıdır. Bu sebeple padding işlemi ile tüm yorumların boyutları eşitlenecektir."
      ],
      "metadata": {
        "id": "TNOwlwLjlg7i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyvxaj3G_PBf"
      },
      "outputs": [],
      "source": [
        "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3aGire6_PBg"
      },
      "outputs": [],
      "source": [
        "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdSsTl34_PBg"
      },
      "outputs": [],
      "source": [
        "x_train_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_uNuHdk_PBh"
      },
      "outputs": [],
      "source": [
        "x_test_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-5XOLpP_PBh"
      },
      "outputs": [],
      "source": [
        "np.array(x_train_tokens[800])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF-Jwddy_PBi"
      },
      "outputs": [],
      "source": [
        "x_train_pad[800]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Token'leri verip string'e çevirelim. "
      ],
      "metadata": {
        "id": "Wg_oDxxdnaD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftPhVqPZ_PBi"
      },
      "outputs": [],
      "source": [
        "idx = tokenizer.word_index\n",
        "inverse_map = dict(zip(idx.values(), idx.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC6AvGIc_PBr"
      },
      "outputs": [],
      "source": [
        "def tokens_to_string(tokens):\n",
        "    words = [inverse_map[token] for token in tokens if token!=0]\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgWqIcHA_PBs"
      },
      "outputs": [],
      "source": [
        "x_train[800]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TgZv8Ca_PBt"
      },
      "outputs": [],
      "source": [
        "tokens_to_string(x_train_tokens[800])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YSA Modelimizi Oluşturalım"
      ],
      "metadata": {
        "id": "h8HRvObgoEoJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2oW9mxL_PBt"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her kelimeye karşılık gelen vektör uzunluğunu belirleyelim.\n",
        "Kelime vektörleri başlangıçta rastgele oluşturacağız, ancak model değitilirken vektörlerde eğitiliyor olacak."
      ],
      "metadata": {
        "id": "i5n57dcYoVOn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9ElFmZD_PBt"
      },
      "outputs": [],
      "source": [
        "embedding_size = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIUvKE5x_PBu"
      },
      "outputs": [],
      "source": [
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_size,\n",
        "                    input_length=max_tokens,\n",
        "                    name='embedding_layer'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EzYPvdm_PBu"
      },
      "outputs": [],
      "source": [
        "model.add(GRU(units=16, return_sequences=True))\n",
        "model.add(GRU(units=8, return_sequences=True))\n",
        "model.add(GRU(units=4))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0V5x_0rS_PBu"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IViMXviD_PBv"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-o5g4FU_PBw"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jr4yXDb-ab3c"
      },
      "outputs": [],
      "source": [
        "x_train_pad = np.array(x_train_pad)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "x_test_pad = np.array(x_test_pad)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iUFIohx_PBw"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train_pad, y_train, epochs=5, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXHNeM4J_PBw"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(x_test_pad, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7454dPu_PBw"
      },
      "outputs": [],
      "source": [
        "result[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yHYie-o_PBw"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x=x_test_pad[0:1000])\n",
        "y_pred = y_pred.T[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sOa985f_PBy"
      },
      "outputs": [],
      "source": [
        "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ2lmKq8_PBy"
      },
      "outputs": [],
      "source": [
        "cls_true = np.array(y_test[0:1000])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BO_U7TT_PBy"
      },
      "outputs": [],
      "source": [
        "incorrect = np.where(cls_pred != cls_true)\n",
        "incorrect = incorrect[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLdX832P_PBy"
      },
      "outputs": [],
      "source": [
        "len(incorrect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ysWKi2k_PBz"
      },
      "outputs": [],
      "source": [
        "idx = incorrect[0]\n",
        "idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM2bc9h6_PBz"
      },
      "outputs": [],
      "source": [
        "text = x_test[idx]\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmaje5_e_PBz"
      },
      "outputs": [],
      "source": [
        "y_pred[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1alNfEp6_PB0"
      },
      "outputs": [],
      "source": [
        "cls_true[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id6zEspO_PB0"
      },
      "outputs": [],
      "source": [
        "text1 = \"bu ürün çok iyi herkese tavsiye ederim\"\n",
        "text2 = \"kargo çok hızlı aynı gün elime geçti\"\n",
        "text3 = \"büyük bir hayal kırıklığı yaşadım bu ürün bu markaya yakışmamış\"\n",
        "text4 = \"mükemmel\"\n",
        "text5 = \"tasarımı harika ancak kargo çok geç geldi ve ürün açılmıştı tavsiye etmem\"\n",
        "text6 = \"hiç resimde gösterildiği gibi değil\"\n",
        "text7 = \"kötü yorumlar gözümü korkutmuştu ancak hiçbir sorun yaşamadım teşekkürler\"\n",
        "text8 = \"hiç bu kadar kötü bir satıcıya denk gelmemiştim ürünü geri iade ediyorum\"\n",
        "text9 = \"tam bir fiyat performans ürünü\"\n",
        "text10 = \"beklediğim gibi çıkmadı\"\n",
        "texts = [text1, text2, text3, text4, text5, text6, text7, text8, text9, text10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN6qXImA_PB1"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.texts_to_sequences(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0mGywh0_PB1"
      },
      "outputs": [],
      "source": [
        "tokens_pad = pad_sequences(tokens, maxlen=max_tokens)\n",
        "tokens_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiwfMvBS_PB1"
      },
      "outputs": [],
      "source": [
        "model.predict(tokens_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FLMf55v_PB2"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Day14_NLP_Classification_HepsiburadaTR_6_DL_GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}