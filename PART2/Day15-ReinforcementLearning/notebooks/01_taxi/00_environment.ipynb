{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. The taxi driving problem (Taksi kullanma sorunu) 🚕 \n",
        "\n",
        "Bir ajana Pekiştirmeli Öğrenme (Reinforcement Learning) kullanarak taksi sürmeyi öğreteceğiz.\n",
        "\n",
        "Gerçek dünyada taksi sürmek, başlamak için çok karmaşık bir iştir. Bu nedenle, iyi bir taksi şoförünün yaptığı 3 temel şeyi içeren basitleştirilmiş bir ortamda çalışacağız, bunlar:\n",
        "\n",
        "- yolcuları alın ve istedikleri yere bırakın.\n",
        "- güvenli sürün, yani çarpışma yok.\n",
        "- onları mümkün olan en kısa sürede sürün.\n",
        "\n",
        "OpenAI Gym'den [Taxi-v3](https://gym.openai.com/envs/Taxi-v3/) ortam adı verilen bir ortamı kullanacağız."
      ],
      "metadata": {
        "id": "uxQ0zQrxYHld"
      },
      "id": "uxQ0zQrxYHld"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://zephyrnet.com/wp-content/uploads/2022/01/hands-on-reinforcement-learning-course-part-2.png\" width=400px/>\n",
        "\n",
        "\n",
        "Bu dünya R(ed), G(reen), Y(ellow) ve B(lue) ile gösterilen dört belirlenmiş konum vardır.\n",
        "\n",
        "Bölüm başladığında, taksi rastgele bir karede hareket eder ve yolcu rastgele bir konumdadır (R, G, Y veya B).\n",
        "\n",
        "Taksi, yolcunun bulunduğu yere gider, yolcuyu alır, yolcunun gideceği yere (belirtilen dört konumdan başka birine) gider ve ardından yolcuyu bırakır. Bunu yaparken, taksi şoförümüzün | olarak işaretlenmiş herhangi bir duvara çarpmamak için dikkatli bir şekilde sürmesi gerekmektedir. \n",
        "Yolcu bırakıldıktan sonra bölüm sona erer.\n"
      ],
      "metadata": {
        "id": "T7NH82SJbjQp"
      },
      "id": "T7NH82SJbjQp"
    },
    {
      "cell_type": "markdown",
      "id": "04a5c882",
      "metadata": {
        "id": "04a5c882"
      },
      "source": [
        "# 2. Environment (Çevre), actions (eylemler), states(durumlar), rewards(ödüller)\n",
        "\n",
        "👉Bir Reinforcement Learning (pekiştirmeli öğrenme) problemini çözmeden önce, ne olduğunu tanımlamanız gerekir.\n",
        "\n",
        "- eylemler (the actions)\n",
        "- dünyanın durumları (the states of the world)\n",
        "- ödüller (the rewards)\n",
        "\n",
        "👉OpenAI's gym'deki Taxi-v3 ortamını kullanıyoruz: https://gym.openai.com/envs/Taxi-v3/\n",
        "\n",
        "👉Taxi-v3 kolay bir ortamdır çünkü eylem alanı küçüktür ve durum alanı büyüktür ancak sonludur.\n",
        "\n",
        "👉Sınırlı sayıda eylem ve duruma sahip ortamlara tablo denir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3629346",
      "metadata": {
        "id": "e3629346"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%pylab inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76e9a06d",
      "metadata": {
        "id": "76e9a06d"
      },
      "source": [
        "## Load the environment (çevreyi yükleme) 🌎\n",
        "\n",
        "Önce ortamı yükleyelim:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebfba291",
      "metadata": {
        "id": "ebfba291"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "env = gym.make(\"Taxi-v3\").env"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her adımda ajanın seçebileceği eylemler nelerdir?\n",
        "\n",
        "- 0 sürücü aşağı\n",
        "- 1 sürücü\n",
        "- 2 sürücü sağa\n",
        "- 3 sürücü sola\n",
        "- 4 yolcu almak\n",
        "- 5 yolcu bırakmak\n"
      ],
      "metadata": {
        "id": "EXpkHRU7fSoM"
      },
      "id": "EXpkHRU7fSoM"
    },
    {
      "cell_type": "markdown",
      "id": "1fcfc13a",
      "metadata": {
        "id": "1fcfc13a"
      },
      "source": [
        "## Action space (Eylem uzayı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98cfdb84",
      "metadata": {
        "id": "98cfdb84"
      },
      "outputs": [],
      "source": [
        "print(\"Action Space {}\".format(env.action_space))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ve durumlar (states)?\n",
        "\n",
        "- 25 olası taksi pozisyonu, çünkü dünya bir 5×5 ızgarası.\n",
        "- Yolcunun R, G, Y, B artı yolcunun takside olduğu durum olmak üzere 5 olası konum\n",
        "- 4 hedef konum\n",
        "\n",
        "bu bize 25 x 5 x 4 = 500 durum verir."
      ],
      "metadata": {
        "id": "6J5Le5VAf0Yj"
      },
      "id": "6J5Le5VAf0Yj"
    },
    {
      "cell_type": "markdown",
      "id": "4f53a38e",
      "metadata": {
        "id": "4f53a38e"
      },
      "source": [
        "## State space (Durum uzayı)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e809514b",
      "metadata": {
        "id": "e809514b"
      },
      "outputs": [],
      "source": [
        "print(\"State Space {}\".format(env.observation_space))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ödüller hakkında ne dersin?\n",
        "\n",
        "- -1, varsayılan adım başına ödül.\n",
        "Neden -1 ve sadece 0 değil? Çünkü her ekstra adımı cezalandırarak ajanı en kısa süreyi geçirmeye teşvik etmek istiyoruz. Bir taksi şoföründen beklediğiniz bu değil mi?\n",
        "    \n",
        "- +20 puan, yolcuyu doğru yere teslim etmek için verilen ödül.\n",
        "\n",
        "- -10 puan, yanlış yerde alma veya bırakma işlemi gerçekleştirmenin ödülü.\n",
        "\n",
        "Ödüller ve ortam geçişlerini (environment transitions) \n",
        "(state, action) → next_state \n",
        "`env.P` değerinden okuyabilirsiniz ."
      ],
      "metadata": {
        "id": "x7SIwPjbgUGW"
      },
      "id": "x7SIwPjbgUGW"
    },
    {
      "cell_type": "markdown",
      "id": "c8f6a690",
      "metadata": {
        "id": "c8f6a690"
      },
      "source": [
        "## Rewards (Ödüller)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0faad2a7",
      "metadata": {
        "id": "0faad2a7"
      },
      "outputs": [],
      "source": [
        "# env.P çift dictionary tipindedir.\n",
        "# - 1. anahtar, 0'dan 499'a kadar olan durumu (state) temsil eder\n",
        "# - 2. anahtar, ajan (agent) tarafından gerçekleştirilen eylemi (action) temsil eder,\n",
        "# 0'dan 5'e\n",
        "\n",
        "# example\n",
        "state = 123\n",
        "action = 0  # move south (güneye hareket)\n",
        "\n",
        "# env.P[state][action][0] 4 elemanlı bir listedir\n",
        "# (probability, next_state, reward, done)\n",
        "# (olasılık, sonraki_durum, ödül, tamamlandı)\n",
        "# \n",
        "#  - probability (olasılık)\n",
        "#    Bu ortamda (environment) her zaman 1'dir, yani\n",
        "#    belirleyen hiçbir dış/rastgele faktör yoktur.\n",
        "#    next_state\n",
        "#    ajanın eylemi dışında a.\n",
        "#\n",
        "#  - next_state: bu durumda 223\n",
        "# \n",
        "#  - reward: bu durumda -1\n",
        "#\n",
        "#  - done: boolean (True/False) \n",
        "#          bölüm sona erdi (yani sürücü yolcu doğru varış noktasında)\n",
        "print('env.P[state][action][0]: ', env.P[state][action][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu arada, bu `env.P` vektörlerinin anlamlı olup olmadığını iki kez kontrol etmek için ortamı her durum altında oluşturabilirsiniz:\n",
        "\n",
        "`state=123`"
      ],
      "metadata": {
        "id": "pl3kp5bZhZ8z"
      },
      "id": "pl3kp5bZhZ8z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "552caf92",
      "metadata": {
        "id": "552caf92"
      },
      "outputs": [],
      "source": [
        "# Need to call reset() at least once before render() will work\n",
        "# render() çalışması için en az bir kez reset() öğesini çağırmanız gerekiyor\n",
        "env.reset()\n",
        "\n",
        "env.s = 123\n",
        "env.render(mode='human')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ajan, state=223'e ulaşmak için action=0 güneye hareket eder."
      ],
      "metadata": {
        "id": "HW3UEF5ahmG2"
      },
      "id": "HW3UEF5ahmG2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ded2ba5",
      "metadata": {
        "id": "2ded2ba5"
      },
      "outputs": [],
      "source": [
        "env.s = 223\n",
        "env.render(mode='human')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N18lJg3tXeQP"
      },
      "id": "N18lJg3tXeQP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "00_environment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}