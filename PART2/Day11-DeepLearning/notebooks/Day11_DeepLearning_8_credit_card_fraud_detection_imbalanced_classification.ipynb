{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGeKEZXEgueM"
      },
      "source": [
        "# Veri Kümesi Hakkında\n",
        "Veri kümeleri, Avrupalı ​​kart sahipleri tarafından Eylül 2013'te kredi kartlarıyla yapılan işlemleri içerir. Bu veri kümesi, 284,807 işlemden 492'sinin dolandırıcılık olduğu iki gün içinde gerçekleşen işlemleri sunar. \n",
        "\n",
        "Veri kümesi oldukça dengesizdir, pozitif sınıf (dolandırıcılık) tüm işlemlerin %0,172'sini oluşturur.\n",
        "\n",
        "Yalnızca bir PCA dönüşümünün sonucu olan sayısal girdi değişkenlerini içerir.\n",
        "\n",
        "Ne yazık ki, gizlilik sorunları nedeniyle orijinal özellikleri ve verilerle ilgili daha fazla arka plan bilgisi sağlayamıyoruz. \n",
        "\n",
        "Özellikler V1, V2, ... V28, PCA ile elde edilen temel bileşenlerdir, PCA ile dönüştürülmeyen tek özellikler 'Time' ve 'Amount'dır. \n",
        "\n",
        "# 'Time' özelliği, her işlem ile veri kümesindeki ilk işlem arasında geçen saniyeleri içerir. \n",
        "\n",
        "**'Amount'** özelliği işlem Tutarı'dır, bu özellik örneğin maliyete duyarlı öğrenme için kullanılabilir. \n",
        "\n",
        "**'Class'** özelliği yanıt değişkenidir ve dolandırıcılık durumunda 1, aksi halde 0 değerini alır."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHjWRKT5V4Pg"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "np.random.seed(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-CrWOgHaIC3"
      },
      "outputs": [],
      "source": [
        "#ROOT_DIR = \"/content/drive/MyDrive/CASGEM-Egitim/Egitim-Part2/Day11-DeepLearning/notebooks/\"\n",
        "ROOT_DIR = \"https://media.githubusercontent.com/media/yapay-ogrenme/casgem-eu-project-training-on-data-mining/main/PART2/Day11-DeepLearning/notebooks/\"\n",
        "\n",
        "DATASET_PATH = ROOT_DIR + \"datasets/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(DATASET_PATH+'creditcard.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "x2EfTqCAby0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzhgwQTQV4Pl"
      },
      "source": [
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-RgpPqpV4Pm"
      },
      "outputs": [],
      "source": [
        "print(\"The DataSet has \",str(data.shape[0]),\"rows and\",data.shape[1],\"Columns\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIB_BoyMbTCN"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He75sVQqmGAD"
      },
      "source": [
        "#### Checking For Null Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WUuUyO1l7gb"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B9lFGDImRHM"
      },
      "source": [
        "#### Let's Check how the data is disperesed!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb4ZGOUVmPfM"
      },
      "outputs": [],
      "source": [
        "data.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btFf04dQfyV0"
      },
      "outputs": [],
      "source": [
        "fraud_transactions=data.where(data['Class']==1)\n",
        "regular_transactions=data.where(data['Class']==0)\n",
        "\n",
        "regular_amount=regular_transactions['Amount']\n",
        "fraud_amount=fraud_transactions['Amount']\n",
        "\n",
        "fraud_amount.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlsAjyebgDGV"
      },
      "source": [
        "### **Sahte İşlemlerin %50'si 10$'dan az !! **\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWzyzN9GcLqh"
      },
      "outputs": [],
      "source": [
        "fraud_amount.plot(kind='hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cb7Z4qSxfVS8"
      },
      "outputs": [],
      "source": [
        "fraud_transactions.boxplot(column='Amount')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHRZWWOVL_sf"
      },
      "outputs": [],
      "source": [
        "regular_amount.plot(kind='hist')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UyxFg_mnjtwh"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
        "\n",
        "amount_val = data['Amount'].values\n",
        "time_val = data['Time'].values\n",
        "\n",
        "sns.distplot(amount_val, ax=ax[0], color='r')\n",
        "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
        "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
        "\n",
        "sns.distplot(time_val, ax=ax[1], color='b')\n",
        "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
        "ax[1].set_xlim([min(time_val), max(time_val)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5rRqvqKqP3-"
      },
      "outputs": [],
      "source": [
        "V = data[[col for col in data.columns if 'V' in col]]\n",
        "\n",
        "f, ax = plt.subplots(ncols = 2, nrows = 14, figsize=(15,2*len(V.columns)))\n",
        "\n",
        "for i, c in zip(ax.flatten(), V.columns):\n",
        "    sns.distplot(V[c], ax = i)\n",
        "\n",
        "f.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_2ksMntjw86"
      },
      "source": [
        "## Çoğu Hileli ve Düzenli işlemler hangi saatte gerçekleşir?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3NUbM1XirGO"
      },
      "outputs": [],
      "source": [
        "def convert_totime(seconds):\n",
        "    return datetime.datetime.fromtimestamp(seconds);\n",
        "\n",
        "timeAnalysis = data[['Time', 'Amount', 'Class']].copy()\n",
        "timeAnalysis['datetime'] = timeAnalysis.Time.apply(convert_totime)\n",
        "timeDelta = datetime.datetime.utcnow() - datetime.datetime.now()\n",
        "\n",
        "# As the max time is 172792 seconds and 172792 / (60*60) is about 48 hrs so we only have data for 2 days so only \n",
        "# plotting data against hours make sense\n",
        "timeAnalysis['hour of the day'] = timeAnalysis.datetime + timeDelta\n",
        "timeAnalysis['hour of the day'] = timeAnalysis['hour of the day'].dt.hour\n",
        "timeAnalysisGrouped = timeAnalysis.groupby(['Class', 'hour of the day'])['Amount'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0Cs70MojjgX"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10, 6))\n",
        "validTransactions = timeAnalysisGrouped[0].copy()\n",
        "validTransactions.name = 'Number of transactions'\n",
        "validTransactions.plot.bar(title = 'No of legitimate credit card transactions per hour', legend = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmfXv8GAsMbH"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (10, 6))\n",
        "fraudTransactions = timeAnalysisGrouped[1].copy()\n",
        "fraudTransactions.name = 'Number of transactions'\n",
        "fraudTransactions.plot.bar(title = 'Number of fraud credit card transactions per hour', legend = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc0scobPtLmx"
      },
      "source": [
        "#### 2 AM ve 11.00'de gerçekleştirilen dolandırıcılık İşlemlerinin sayısında olağandışı bir artış var. Normal İşlemlerle karşılaştırıldığında Sahte İşlemler, iki tepe noktası göz ardı edilerek dağıtılır.\n",
        "\n",
        "#### Normal İşlemler, gündüz saatlerinde Yüksek İşlem Sayısı ile beklenen trendi gösteriyor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz1gWT-Ju8-r"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kJwEV9RV4Pp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "data['normalizedAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))\n",
        "data = data.drop(['Amount'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64jk33aXV4Pr"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxWRfAoCV4Pt"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['Time'],axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0DSiPdDV4Pw"
      },
      "outputs": [],
      "source": [
        "X = data.iloc[:, data.columns != 'Class']\n",
        "y = data.iloc[:, data.columns == 'Class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--y3GZjuV4Pz"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDOKQZBdV4P2"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPULI5BgV4P4"
      },
      "outputs": [],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gsiWKhBQV4P7"
      },
      "outputs": [],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "224W6fDHxrjk"
      },
      "source": [
        "## Building a Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvvH1Dmdxx-K"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(n_estimators=100)\n",
        "random_forest.fit(X_train,y_train.values.ravel())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvy5yeS2zm_0"
      },
      "outputs": [],
      "source": [
        "y_pred = random_forest.predict(X_test)\n",
        "random_forest.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rNzOJexz1eS"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiA5mJjxz_iE"
      },
      "outputs": [],
      "source": [
        "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
        "plot_confusion_matrix(cnf_matrix,classes=[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gln2wf55V4P9"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQAX5x7PV4P_"
      },
      "source": [
        "## Deep neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFPPbkMpV4P_"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQhHbIScV4QC"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(units=16, input_dim = 29,activation='relu'),\n",
        "    Dense(units=24,activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(20,activation='relu'),\n",
        "    Dense(24,activation='relu'),\n",
        "    Dense(1,activation='sigmoid'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBcByvT-V4QE"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_obwB3qV4QH"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWV8CMQPV4QI"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,batch_size=15,epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiDBc16hV4QM"
      },
      "outputs": [],
      "source": [
        "score = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SCYLCP5V4QO"
      },
      "outputs": [],
      "source": [
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPaiaM9_V4QR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re7jcteRV4QT"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_test = pd.DataFrame(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcixscW9V4QV"
      },
      "outputs": [],
      "source": [
        "cnf_matrix = confusion_matrix(y_test, y_pred.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c--J4JfFV4QY"
      },
      "outputs": [],
      "source": [
        "print(cnf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ennHdwl8V4Qa"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(cnf_matrix, classes=[0,1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "#Calculating and printing the f1 score \n",
        "f1_test = f1_score(y_test, y_pred.round())\n",
        "print('The f1 score for the testing data:', f1_test)"
      ],
      "metadata": {
        "id": "P56sjCB6q-yM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WsbsMGh1kYyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwQZnq-Y1dui"
      },
      "source": [
        "## Undersampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6FloZbEV4Qd"
      },
      "outputs": [],
      "source": [
        "fraud_indices = np.array(data[data.Class == 1].index)\n",
        "number_records_fraud = len(fraud_indices)\n",
        "print(number_records_fraud)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoHRJAFS1j3O"
      },
      "outputs": [],
      "source": [
        "normal_indices = data[data.Class == 0].index\n",
        "random_normal_indices = np.random.choice(normal_indices, number_records_fraud, replace=False)\n",
        "random_normal_indices = np.array(random_normal_indices)\n",
        "print(len(random_normal_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AltXY0oS1l-7"
      },
      "outputs": [],
      "source": [
        "under_sample_indices = np.concatenate([fraud_indices,random_normal_indices])\n",
        "print(len(under_sample_indices))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEOO6-yM1rUj"
      },
      "outputs": [],
      "source": [
        "under_sample_data = data.iloc[under_sample_indices,:]\n",
        "X_undersample = under_sample_data.iloc[:,under_sample_data.columns != 'Class']\n",
        "y_undersample = under_sample_data.iloc[:,under_sample_data.columns == 'Class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_undersample,y_undersample, test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yorFIoG1159D"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1RlzR8216nz"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLW6p08418mj"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,batch_size=15,epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "si7933OU1-99"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_expected = pd.DataFrame(y_test)\n",
        "cnf_matrix = confusion_matrix(y_expected, y_pred.round())\n",
        "plot_confusion_matrix(cnf_matrix, classes=[0,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFcf68hx2QKg"
      },
      "source": [
        "## SMOTE - oversampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZ9Z7GWC2BpT"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3dXASc92Tk1"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "oversample = SMOTE()\n",
        "\n",
        "X_resample, y_resample = oversample.fit_resample(X,y.values.ravel())\n",
        "y_resample = pd.DataFrame(y_resample)\n",
        "X_resample = pd.DataFrame(X_resample)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resample,y_resample,test_size=0.3)\n",
        "###########################################################################################\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rEghXqC2iNT"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "model.fit(X_train,y_train,batch_size=15,epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08LBJRLK2la7"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_expected = pd.DataFrame(y_test)\n",
        "cnf_matrix = confusion_matrix(y_expected, y_pred.round())\n",
        "plot_confusion_matrix(cnf_matrix, classes=[0,1])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MJmdv4Kmie8g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Day11_DeepLearning_8_credit_card_fraud_detection_imbalanced_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}